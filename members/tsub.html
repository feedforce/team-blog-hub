<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon shortcut" type="image/png" href="https://engineers.feedforce.jp/logo.png"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&amp;display=swap"/><title>tsub | Feedforce Engineers&#x27; Blogs</title><meta property="og:title" content="tsub"/><meta property="og:url" content="https://engineers.feedforce.jp/members/tsub"/><meta name="twitter:card" content="summary_large_image"/><meta property="og:site" content="Feedforce Engineers&#x27; Blogs"/><meta property="og:image" content="https://engineers.feedforce.jp/og.png"/><link rel="canonical" href="https://engineers.feedforce.jp/members/tsub"/><link rel="alternate" type="application/rss+xml" title="Feedforce Engineers&#x27; Blogs" href="https://engineers.feedforce.jp/rss.xml"/><link rel="alternate" type="application/atom+xml" title="Feedforce Engineers&#x27; Blogs" href="https://engineers.feedforce.jp/atom.xml"/><link rel="preload" href="/_next/static/css/d7faf1fdf25fe7d3262e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/d7faf1fdf25fe7d3262e.css" data-n-g=""/><noscript data-n-css="true"></noscript><link rel="preload" href="/_next/static/chunks/main-8a83f0fd99327c4684a8.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.1daf1ec1ecf144ee9147.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.9e003f150a446b53bdd9.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-99db904e083fc7f74e35.js" as="script"/><link rel="preload" href="/_next/static/chunks/588505f8033a39c9ef82bc46b1145ac9fd1db500.1b31e9b3d8ab8514c941.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/members/%5Bname%5D-42a7756adc6c0800b4dc.js" as="script"/></head><body><div id="__next"><header class="site-header"><div class="content-wrapper"><div class="site-header__inner"><a class="site-header__logo-link" href="/"><img src="https://engineers.feedforce.jp/logo.svg" alt="Feedforce Engineers&#x27; Blogs" class="site-header__logo-img"/></a><div class="site-header__links"><a href="https://feedforcegroup.jp" class="site-header__link">Company</a><a href="https://github.com/feedforce" class="site-header__link">GitHub</a><a href="https://engineers.recruit.feedforce.jp" class="site-header__link">Recruit</a></div></div></div></header><section class="member"><div class="content-wrapper"><header class="member-header"><div class="member-header__avatar"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" alt="tsub" width="100" height="100" class="member-header__avatar-img"/></div><h1 class="member-header__name">tsub</h1><p class="member-header__bio">コンテナが好きです</p><div class="member-header__links"><a href="https://twitter.com/_tsub_" class="member-header__link"><img src="https://engineers.feedforce.jp/icons/twitter.svg" alt="Twitterのユーザー@_tsub_" width="22" height="22"/></a><a href="https://github.com/tsub" class="member-header__link"><img src="https://engineers.feedforce.jp/icons/github.svg" alt="GitHubのユーザー@tsub" width="22" height="22"/></a><a href="https://tsub.me" class="member-header__link"><img src="https://engineers.feedforce.jp/icons/link.svg" alt="ウェブサイトのリンク" width="22" height="22"/></a></div></header><div class="member-posts-container"><div class="post-list"><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2021-06-19T08:41:36.000Z" class="post-link__date">a year ago</time></div></a><a href="https://blog.tsub.me/post/create-asdf-terraform-build/" class="post-link__main-link"><h2 class="post-link__title">Apple Silicon Mac で複数 Terraform バージョンを管理するために asdf-terraform-build を作った</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2021-06-16T03:00:00.000Z" class="post-link__date">a year ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/06/16/120000" class="post-link__main-link"><h2 class="post-link__title">一年間の育休から復帰しました</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2021-02-17T02:00:00.000Z" class="post-link__date">2 years ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/02/17/110000" class="post-link__main-link"><h2 class="post-link__title">CircleCI で docker build するときの Empty continuation lines will become errors in a future release. という warning への対処方法</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2021-02-16T02:00:00.000Z" class="post-link__date">2 years ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/02/16/110000" class="post-link__main-link"><h2 class="post-link__title">docker-compose での MySQL の疎通確認で telnet を使う時に自動でコネクションを切る</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2019-10-06T05:35:00.000Z" class="post-link__date">3 years ago</time></div></a><a href="https://blog.tsub.me/post/create-alfred-aws-vault-workflow/" class="post-link__main-link"><h2 class="post-link__title">「aws-vault loginでChromeのウィンドウをAWSアカウント毎に分離する」を Alfred 用に作った</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2019-08-13T09:31:30.000Z" class="post-link__date">3 years ago</time></div></a><a href="https://developer.feedforce.jp/entry/2019/08/13/183130" class="post-link__main-link"><h2 class="post-link__title"> Dynamoid のスレッドセーフではない実装を直しました</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2018-11-10T08:47:00.000Z" class="post-link__date">4 years ago</time></div></a><a href="https://blog.tsub.me/post/introducing-to-circleci-orbs/" class="post-link__main-link"><h2 class="post-link__title">CircleCI Orbs 入門</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2018-10-28T09:35:00.000Z" class="post-link__date">4 years ago</time></div></a><a href="https://blog.tsub.me/post/create-albert-github/" class="post-link__main-link"><h2 class="post-link__title">Albert で GitHub リポジトリを開ける拡張を作った</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2018-08-30T05:33:00.000Z" class="post-link__date">4 years ago</time></div></a><a href="https://blog.tsub.me/post/go111-modules-in-circleci/" class="post-link__main-link"><h2 class="post-link__title">Go 1.11 の Modules (vgo) を CircleCI で使う</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2018-07-23T05:01:33.000Z" class="post-link__date">4 years ago</time></div></a><a href="https://developer.feedforce.jp/entry/2018/07/23/140133" class="post-link__main-link"><h2 class="post-link__title">Kubernetes.rb に講師役として参加してきました</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2018-05-11T10:00:00.000Z" class="post-link__date">5 years ago</time></div></a><a href="https://developer.feedforce.jp/entry/2018/05/11/190000" class="post-link__main-link"><h2 class="post-link__title">Datadog で dd-agent に root 権限を与えずにプロセスがオープンしているファイルディスクリプタ数のメトリクスを取得する</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2018-03-17T06:16:55.000Z" class="post-link__date">5 years ago</time></div></a><a href="https://blog.tsub.me/post/jaws-days-2018/" class="post-link__main-link"><h2 class="post-link__title">JAWS DAYS 2018 に行ってきた</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2018-03-02T06:50:20.000Z" class="post-link__date">5 years ago</time></div></a><a href="https://developer.feedforce.jp/entry/2018/03/02/155020" class="post-link__main-link"><h2 class="post-link__title">m3.medium のインスタンスの CPU 負荷が高かったため t2.medium へ移行した</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2018-01-31T14:15:00.000Z" class="post-link__date">5 years ago</time></div></a><a href="https://blog.tsub.me/post/introduce-aws-lambda-with-golang-and-sam/" class="post-link__main-link"><h2 class="post-link__title">AWS Lambda with Golang と SAM に入門した</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2017-12-09T12:30:00.000Z" class="post-link__date">5 years ago</time></div></a><a href="https://blog.tsub.me/post/half-a-year-after-married/" class="post-link__main-link"><h2 class="post-link__title">結婚して半年が経ったので工夫していることとか</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2017-11-30T04:35:25.000Z" class="post-link__date">5 years ago</time></div></a><a href="https://developer.feedforce.jp/entry/2017/11/30/133525" class="post-link__main-link"><h2 class="post-link__title">AWS でコンテナを動かすためのサービスまとめ</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2017-11-26T07:00:00.000Z" class="post-link__date">5 years ago</time></div></a><a href="https://blog.tsub.me/post/create-alfred-workflow/" class="post-link__main-link"><h2 class="post-link__title">Go で Datadog の Alfred Workflow を作った</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2017-11-13T09:36:23.000Z" class="post-link__date">5 years ago</time></div></a><a href="https://developer.feedforce.jp/entry/2017/11/13/183623" class="post-link__main-link"><h2 class="post-link__title">【2017/11/16 に訂正を追記しました】 社内 LT 大会で「ここがつらいよ ECS」というタイトルで発表しました</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2017-09-05T13:30:00.000Z" class="post-link__date">5 years ago</time></div></a><a href="https://blog.tsub.me/post/create-s3-edit/" class="post-link__main-link"><h2 class="post-link__title">Go で s3-edit という CLI アプリケーションを作った</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2017-05-03T00:30:00.000Z" class="post-link__date">6 years ago</time></div></a><a href="https://blog.tsub.me/post/move-from-peco-to-fzf/" class="post-link__main-link"><h2 class="post-link__title">pecoからfzfに移行した</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2017-04-16T05:29:33.000Z" class="post-link__date">6 years ago</time></div></a><a href="https://blog.tsub.me/post/operate-blog-server-on-gke/" class="post-link__main-link"><h2 class="post-link__title">ブログをGKEでの運用に移行した</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2016-12-17T07:50:00.000Z" class="post-link__date">6 years ago</time></div></a><a href="https://blog.tsub.me/post/how-i-collect-information/" class="post-link__main-link"><h2 class="post-link__title">ぼくの情報収集方法</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2016-12-08T15:00:00.000Z" class="post-link__date">6 years ago</time></div></a><a href="https://blog.tsub.me/post/blox-introduction/" class="post-link__main-link"><h2 class="post-link__title">Blox Introduction</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2016-08-11T16:01:16.000Z" class="post-link__date">6 years ago</time></div></a><a href="https://blog.tsub.me/post/created-blog-by-hugo/" class="post-link__main-link"><h2 class="post-link__title">はてなブログからHugo on Github Pagesに移行しました</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2016-07-02T13:08:23.000Z" class="post-link__date">6 years ago</time></div></a><a href="https://blog.tsub.me/post/neovim-on-terminal-emulator/" class="post-link__main-link"><h2 class="post-link__title">neovimのterminal emulatorが便利すぎた</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2016-06-30T14:56:16.000Z" class="post-link__date">6 years ago</time></div></a><a href="https://blog.tsub.me/post/tokyo-ex-3-entry-report/" class="post-link__main-link"><h2 class="post-link__title">tokyo.ex #3 参加してきた</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2016-06-25T14:36:05.000Z" class="post-link__date">6 years ago</time></div></a><a href="https://blog.tsub.me/post/serverspec-for-several-container/" class="post-link__main-link"><h2 class="post-link__title">serverspecで複数のdocker containerに対してテストしたい</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article><article class="post-link"><a class="post-link__author" href="/members/tsub"><img src="https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">tsub</div><time dateTime="2016-06-25T13:25:08.000Z" class="post-link__date">6 years ago</time></div></a><a href="https://blog.tsub.me/post/serverspec-for-docker/" class="post-link__main-link"><h2 class="post-link__title">serverspecでdocker containerに対してテストしたい</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=blog.tsub.me" width="14" height="14" class="post-link__site-favicon"/>blog.tsub.me</div></a></article></div></div></div></section><footer class="site-footer"><div class="content-wrapper"><p>© <!-- -->Feedforce Group Inc.</p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"member":{"name":"tsub","bio":"コンテナが好きです","avatarSrc":"https://www.gravatar.com/avatar/cb16e623d2ac0c0d10440745d4525f04?size=256","sources":["https://developer.feedforce.jp/rss/author/tsub511","https://blog.tsub.me/index.xml"],"twitterUsername":"_tsub_","githubUsername":"tsub","websiteUrl":"https://tsub.me"},"postItems":[{"title":"Apple Silicon Mac で複数 Terraform バージョンを管理するために asdf-terraform-build を作った","content":"\u003cp\u003e\u003ca href=\"https://github.com/tsub/asdf-terraform-build\"\u003e\u003cimg src=\"https://gh-card.dev/repos/tsub/asdf-terraform-build.svg?fullname=\" alt=\"tsub/asdf-terraform-build - GitHub\" /\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"","link":"https://blog.tsub.me/post/create-asdf-terraform-build/","isoDate":"2021-06-19T08:41:36.000Z","dateMiliSeconds":1624092096000,"authorName":"tsub"},{"title":"一年間の育休から復帰しました","content":"\u003cp\u003eこんにちは、インフラエンジニアの \u003ca href=\"http://blog.hatena.ne.jp/tsub511/\" class=\"hatena-id-icon\"\u003e\u003cimg src=\"https://cdn.profile-image.st-hatena.com/users/tsub511/profile.png\" width=\"16\" height=\"16\" alt=\"\" class=\"hatena-id-icon\"\u003eid:tsub511\u003c/a\u003e です。実は去年の 1 月から 1 年間育休を取っており、今年の 1 月から復帰していました。\u003c/p\u003e\n\n\u003cp\u003e復帰してから記事を書くのが遅くなってしまいましたが、社内勉強会で話したスライドや育休から復帰してみてどうだったかをまとめてみました。\u003c/p\u003e\n\n\u003ch2\u003e社内勉強会で話した\u003c/h2\u003e\n\n\u003cp\u003e今年の 3 月頃に社内の技術勉強会 \u003ca href=\"https://developer.feedforce.jp/archive/category/FFTT\"\u003eFFTT\u003c/a\u003e で発表しました。\n(技術勉強会という立て付けですが、技術に限らず本人が話したいことを話して良い場です)\u003c/p\u003e\n\n\u003cscript async class=\"speakerdeck-embed\" data-id=\"e196f600db8d42c4841227d36b76f3b5\" data-ratio=\"1.77777777777778\" src=\"//speakerdeck.com/assets/embed.js\"\u003e\u003c/script\u003e\n\n\n\u003cp\u003eなぜ一年間の育休を取得したのか、育児の知見などがスライド内に書いてありますので気になる方はご覧ください！\u003c/p\u003e\n\n\u003cp\u003eちなみに当時のスライド内ではねんねトレーニング (ネントレ) をやっていると書いてありますが、実は現在はやってません。\u003c/p\u003e\n\n\u003cp\u003e理由はネントレの効果が見られなくなったためです。\u003c/p\u003e\n\n\u003cp\u003e今年の 4 月くらいから寝付きが悪くなり、胸や背中をトントンしないと寝てくれなくなってしまいました。\u003c/p\u003e\n\n\u003cp\u003eそれ以降夜通し寝てくれないことも増えてしまい、再度ネントレにチャレンジしましたが夜泣きは改善されなかったため、夜泣きの原因は寝かしつけ方法と直接関係ないのでは？と思いネントレをやめました。\u003c/p\u003e\n\n\u003cp\u003eちょうどその頃から奥歯が生え始めていたので、それが原因だったのではないかとは思っています。\u003c/p\u003e\n\n\u003cp\u003eここ最近は歯の痛みが落ち着いたのか、夜泣きが少し減ってきたような気がします。と思ってたらまた夜泣きが復活しました... 😭\u003c/p\u003e\n\n\u003cp\u003eやっぱりセルフねんねしてくれてた頃と比べて寝かしつけにかかる時間は増えましたが...\u003c/p\u003e\n\n\u003cp\u003e寝かしつけで悩んでいる方にとって少しでも参考になれば幸いです。\n(自分はめっちゃ悩んだ)\u003c/p\u003e\n\n\u003ch2\u003e育休から復帰した感想\u003c/h2\u003e\n\n\u003cp\u003eスライド内でも触れていましたが、やはり一番感じたことは一年間というそれなりに長い期間にも関わらず、普段有給を取るのとそこまで大きく変わらないくらいの感覚でした。\u003c/p\u003e\n\n\u003cp\u003eもちろん育休を取るという話をしてからチーム内での調整は行いましたが、取得する障壁は特にありませんでした。\nチームメンバーも育休は取得する前提で育休期間中はどう進めていくのか、という話にフォーカスしている印象でした。\u003c/p\u003e\n\n\u003cp\u003eそして、一年間の育休を終えて復帰する際にもすんなり業務に戻ることができました。\u003c/p\u003e\n\n\u003cp\u003e人事やチームメンバーが自分の育休中の変化を事前に記事にまとめてくれていたこともあり、キャッチアップも大体 2 週間くらいで完了しました。\u003c/p\u003e\n\n\u003cp\u003e復帰がスムーズにいった理由の 1 つにチーム体制や使用技術に大きな変化がなかったことも大きいと思います。\u003c/p\u003e\n\n\u003cp\u003e以下の記事でも軽く触れていますので良ければご覧ください。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fmedia.feedforce.jp%2Fn%2Fn98075add5154\" title=\"「謙虚な人が多い」「有休みたいに育休がとれる」エンジニアが語る、フィードフォースのぶっちゃけ裏話｜フィードフォースのnote\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003c/p\u003e\n\n\u003ch2\u003e働き方の変化\u003c/h2\u003e\n\n\u003cp\u003e育休取得前後 (子どもが生まれる前後) での大きな変化の 1 つとして、働き方がかなり変わりました。\u003c/p\u003e\n\n\u003cp\u003e子どもが生まれる前は 10:00 ~ 19:00 で働いており、モチベーションや体力がある日は少し長めに働いたり、反対に効率の悪い日は早めに退勤したりという働き方をしていました。\u003c/p\u003e\n\n\u003cp\u003e子どもが生まれた後は保育園や子どもの就寝時間の都合で 8:00 ~ 17:00 で働くこととなり、保育園の送り迎えや夕飯の支度などがあるので長めに働くということができなくなりました。\u003c/p\u003e\n\n\u003cp\u003eまた、プライベートの時間で技術的な勉強をやることもほとんどなくなってしまいました。\u003c/p\u003e\n\n\u003cp\u003eやる時間が全くないわけではないのですが、ゲームなどでリフレッシュしないと育児疲れが厳しいのと、まとまった時間が取りづらいのが理由です。\u003c/p\u003e\n\n\u003cp\u003e子どもが起きている間はなかなか PC を広げて作業しづらいですし、寝ている間も夜泣きなどでいつ泣くか分からないので集中して作業ができないです。\u003c/p\u003e\n\n\u003cp\u003eとはいえプライベートで開発する時間を取れなくても個人的にはそこまでストレスになっていなくて、今はそういう時期と割り切っています。\u003c/p\u003e\n\n\u003cp\u003eまた仕事で直接使えるような技術の検証であれば、チームの計画に入れて業務時間内で進められるのでなんとかなっています。\u003c/p\u003e\n\n\u003ch2\u003e終わりに\u003c/h2\u003e\n\n\u003cp\u003e育休から復帰してまだ半年程度なので育児もまだまだこれからという感じですが、仕事との両立を引き続き頑張っていきたいと思います 💪\u003c/p\u003e\n\n\u003cp\u003eちなみに自分が育休から復帰した前後で他のエンジニアも育休を取得していました。よければこちらの記事もぜひご覧ください！\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fmedia.feedforce.jp%2Fn%2Fn6cf3af35cb86\" title=\"「家庭あっての職業人」限られた時間で成果を出すためにパパエンジニアが取り組んでいること｜フィードフォースのnote\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003c/p\u003e\n","contentSnippet":"こんにちは、インフラエンジニアの id:tsub511 です。実は去年の 1 月から 1 年間育休を取っており、今年の 1 月から復帰していました。復帰してから記事を書くのが遅くなってしまいましたが、社内勉強会で話したスライドや育休から復帰してみてどうだったかをまとめてみました。社内勉強会で話した今年の 3 月頃に社内の技術勉強会 FFTT で発表しました。(技術勉強会という立て付けですが、技術に限らず本人が話したいことを話して良い場です)なぜ一年間の育休を取得したのか、育児の知見などがスライド内に書いてありますので気になる方はご覧ください！ちなみに当時のスライド内ではねんねトレーニング (ネントレ) をやっていると書いてありますが、実は現在はやってません。理由はネントレの効果が見られなくなったためです。今年の 4 月くらいから寝付きが悪くなり、胸や背中をトントンしないと寝てくれなくなってしまいました。それ以降夜通し寝てくれないことも増えてしまい、再度ネントレにチャレンジしましたが夜泣きは改善されなかったため、夜泣きの原因は寝かしつけ方法と直接関係ないのでは？と思いネントレをやめました。ちょうどその頃から奥歯が生え始めていたので、それが原因だったのではないかとは思っています。ここ最近は歯の痛みが落ち着いたのか、夜泣きが少し減ってきたような気がします。と思ってたらまた夜泣きが復活しました... 😭やっぱりセルフねんねしてくれてた頃と比べて寝かしつけにかかる時間は増えましたが...寝かしつけで悩んでいる方にとって少しでも参考になれば幸いです。(自分はめっちゃ悩んだ)育休から復帰した感想スライド内でも触れていましたが、やはり一番感じたことは一年間というそれなりに長い期間にも関わらず、普段有給を取るのとそこまで大きく変わらないくらいの感覚でした。もちろん育休を取るという話をしてからチーム内での調整は行いましたが、取得する障壁は特にありませんでした。チームメンバーも育休は取得する前提で育休期間中はどう進めていくのか、という話にフォーカスしている印象でした。そして、一年間の育休を終えて復帰する際にもすんなり業務に戻ることができました。人事やチームメンバーが自分の育休中の変化を事前に記事にまとめてくれていたこともあり、キャッチアップも大体 2 週間くらいで完了しました。復帰がスムーズにいった理由の 1 つにチーム体制や使用技術に大きな変化がなかったことも大きいと思います。以下の記事でも軽く触れていますので良ければご覧ください。働き方の変化育休取得前後 (子どもが生まれる前後) での大きな変化の 1 つとして、働き方がかなり変わりました。子どもが生まれる前は 10:00 ~ 19:00 で働いており、モチベーションや体力がある日は少し長めに働いたり、反対に効率の悪い日は早めに退勤したりという働き方をしていました。子どもが生まれた後は保育園や子どもの就寝時間の都合で 8:00 ~ 17:00 で働くこととなり、保育園の送り迎えや夕飯の支度などがあるので長めに働くということができなくなりました。また、プライベートの時間で技術的な勉強をやることもほとんどなくなってしまいました。やる時間が全くないわけではないのですが、ゲームなどでリフレッシュしないと育児疲れが厳しいのと、まとまった時間が取りづらいのが理由です。子どもが起きている間はなかなか PC を広げて作業しづらいですし、寝ている間も夜泣きなどでいつ泣くか分からないので集中して作業ができないです。とはいえプライベートで開発する時間を取れなくても個人的にはそこまでストレスになっていなくて、今はそういう時期と割り切っています。また仕事で直接使えるような技術の検証であれば、チームの計画に入れて業務時間内で進められるのでなんとかなっています。終わりに育休から復帰してまだ半年程度なので育児もまだまだこれからという感じですが、仕事との両立を引き続き頑張っていきたいと思います 💪ちなみに自分が育休から復帰した前後で他のエンジニアも育休を取得していました。よければこちらの記事もぜひご覧ください！","link":"https://developer.feedforce.jp/entry/2021/06/16/120000","isoDate":"2021-06-16T03:00:00.000Z","dateMiliSeconds":1623812400000,"imageUrl":"https://cdn.user.blog.st-hatena.com/default_entry_og_image/4268819/1588226000876991","authorName":"tsub"},{"title":"CircleCI で docker build するときの Empty continuation lines will become errors in a future release. という warning への対処方法","content":"\u003cp\u003eこんにちは、\u003ca href=\"http://blog.hatena.ne.jp/tsub511/\" class=\"hatena-id-icon\"\u003e\u003cimg src=\"https://cdn.profile-image.st-hatena.com/users/tsub511/profile.png\" width=\"16\" height=\"16\" alt=\"\" class=\"hatena-id-icon\"\u003eid:tsub511\u003c/a\u003e です。\u003c/p\u003e\n\n\u003cp\u003eDockerfile を読みやすくするために \u003ccode\u003e\\\u003c/code\u003e とコメントを駆使してみたら CircleCI で warning が出て一瞬焦ったので記事を書いてみました。\u003c/p\u003e\n\n\u003cul class=\"table-of-contents\"\u003e\n    \u003cli\u003e\u003ca href=\"#CircleCI-で-docker-build-する時の-warning\"\u003eCircleCI で docker build する時の warning\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#warning-が出たのは-Docker-のバグ\"\u003ewarning が出たのは Docker のバグ\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#CircleCI-の-Docker-のデフォルトバージョンは-17090-ce\"\u003eCircleCI の Docker のデフォルトバージョンは 17.09.0-ce\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#まとめ\"\u003eまとめ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"CircleCI-で-docker-build-する時の-warning\"\u003eCircleCI で docker build する時の warning\u003c/h2\u003e\n\n\u003cp\u003e例えば以下のような Dockerfile があったとします。\u003c/p\u003e\n\n\u003cpre class=\"code lang-dockerfile\" data-lang=\"dockerfile\" data-unlink\u003e\u003cspan class=\"synStatement\"\u003eFROM \u003c/span\u003eamazonlinux:2\n\n\u003cspan class=\"synStatement\"\u003eENV \u003c/span\u003eRUBY_VERSION=2.7.2 \\\n    BUNDLER_VERSION=2.2.9 \\\n    TZ=/usr/share/zoneinfo/Asia/Tokyo\n\n\u003cspan class=\"synStatement\"\u003eRUN \u003c/span\u003e\\\n\u003cspan class=\"synComment\"\u003e    # Install mysql-community-devel\u003c/span\u003e\n    yum install -y yum-utils \u0026amp;\u0026amp; \\\n    yum localinstall -y https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm \u0026amp;\u0026amp; \\\n    yum-config-manager --enable mysql57-community \u0026amp;\u0026amp; \\\n    yum-config-manager --disable mysql80-community \u0026amp;\u0026amp; \\\n    yum install -y mysql-community-devel \u0026amp;\u0026amp; \\\n    yum remove -y mysql80-community-release yum-utils \u0026amp;\u0026amp; \\\n    \\\n\u003cspan class=\"synComment\"\u003e    # Install ruby\u003c/span\u003e\n    yum install -y \u003cspan class=\"synConstant\"\u003e\u0026quot;https://github.com/feedforce/ruby-rpm/releases/download/${RUBY_VERSION}/ruby-${RUBY_VERSION}-1.el7.centos.x86_64.rpm\u0026quot;\u003c/span\u003e \u0026amp;\u0026amp; \\\n    printf \u003cspan class=\"synConstant\"\u003e\u0026quot;install: --no-document\\nupdate: --no-document\\n\u0026quot;\u003c/span\u003e \u0026gt; /etc/gemrc \u0026amp;\u0026amp; \\\n    gem install -v \u003cspan class=\"synConstant\"\u003e\u0026quot;$BUNDLER_VERSION\u0026quot;\u003c/span\u003e bundler\n\u003c/pre\u003e\n\n\n\u003cp\u003eこれを使って CircleCI で docker build すると、\u003ccode\u003eEmpty continuation lines will become errors in a future release.\u003c/code\u003e という warning が出てしまいます。\u003c/p\u003e\n\n\u003cp\u003e\u003cfigure class=\"figure-image figure-image-fotolife\" title=\"docker build 時の warning\"\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20210215/20210215173356.png\" alt=\"f:id:tsub511:20210215173356p:plain\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003cfigcaption\u003edocker build 時の warning\u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e\n\n\u003cp\u003e普通に読むと、何もコマンドを実行していない \u003ccode\u003e\\\u003c/code\u003e だけの行やコメントだけの行を消した方が良いのかな？と受け取ってしまいがちですが、これは実は Docker 側のバグでした。\u003c/p\u003e\n\n\u003ch2 id=\"warning-が出たのは-Docker-のバグ\"\u003ewarning が出たのは Docker のバグ\u003c/h2\u003e\n\n\u003cp\u003e本来はただの空行だけの場合に warning を出したかったようですが、コメントが書かれた行も warning が出てしまっているようです。\u003c/p\u003e\n\n\u003cp\u003e以下に書かれているように、Docker 17.10 で修正済みとのことです。\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003eThanks for reporting; this issue was resolved through #35004, which is included in Docker 17.10 and up.\u003c/p\u003e\n\n\u003cp\u003eI'll close this issue because this was resolved, but feel free to continue the conversation 👍\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fgithub.com%2Fmoby%2Fmoby%2Fissues%2F35387\" title=\"False positive \u0026quot;Empty continuation lines will become errors in a future release.\u0026quot; · Issue #35387 · moby/moby\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://github.com/moby/moby/issues/35387\"\u003egithub.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eただ、Docker 17.10 というと 2017/10 リリースのバージョンですので、2021/02 現在でまだバグが残っているのはおかしいです。\u003c/p\u003e\n\n\u003cp\u003eCircleCI の Docker のバージョンを確認してみましょう。\u003c/p\u003e\n\n\u003ch2 id=\"CircleCI-の-Docker-のデフォルトバージョンは-17090-ce\"\u003eCircleCI の Docker のデフォルトバージョンは 17.09.0-ce\u003c/h2\u003e\n\n\u003cp\u003eCircleCI 内で docker build を実行するためには \u003ccode\u003esetup_remote_docker\u003c/code\u003e が必要です。\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003esetup_remote_docker\u003c/code\u003e によって CircleCI のジョブのホスト VM で Docker Engine が起動しますが、そこで使われている Docker Engine のバージョンは 17.09.0-ce でした。\u003c/p\u003e\n\n\u003cp\u003e\u003cfigure class=\"figure-image figure-image-fotolife\" title=\"CircleCI の Docker Engine バージョン\"\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20210215/20210215175709.png\" alt=\"f:id:tsub511:20210215175709p:plain\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003cfigcaption\u003eCircleCI の Docker Engine バージョン\u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e\n\n\u003cp\u003eDocker のバグが修正されたのは 17.10 ですので、確かにまだバグが残っているバージョンです。\u003c/p\u003e\n\n\u003cp\u003eさて CircleCI の \u003ccode\u003esetup_remote_docker\u003c/code\u003e ですが、実はデフォルトでは 17.09.0-ce が使われるようです。\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20210215/20210215174427.png\" alt=\"f:id:tsub511:20210215174427p:plain\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://circleci.com/docs/2.0/building-docker-images/#docker-version\"\u003ehttps://circleci.com/docs/2.0/building-docker-images/#docker-version\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\n\u003cp\u003eDockerfile で \u003ccode\u003e\\\u003c/code\u003e だけの行やコメントだけの行がある時に CircleCI で docker build すると \u003ccode\u003eEmpty continuation lines will become errors in a future release.\u003c/code\u003e という warning が出るのは Docker のバグと CircleCI の \u003ccode\u003esetup_remote_docker\u003c/code\u003e のデフォルトバージョンが古い、という合わせ技によって起きていました。\u003c/p\u003e\n\n\u003cp\u003ewarning 自体は Docker のバグだったので無視で良いですが、古いバージョンを使い続けるのはあまり良くない気がします。\u003c/p\u003e\n\n\u003cp\u003e基本的にはデフォルトを使いたいところですが、17.09.0-ce だと色々な機能が使えないですし、上述したバグもあるので \u003ccode\u003esetup_remote_docker\u003c/code\u003e を使うときは version を指定することをおすすめします。\u003c/p\u003e\n","contentSnippet":"こんにちは、id:tsub511 です。Dockerfile を読みやすくするために \\ とコメントを駆使してみたら CircleCI で warning が出て一瞬焦ったので記事を書いてみました。CircleCI で docker build する時の warningwarning が出たのは Docker のバグCircleCI の Docker のデフォルトバージョンは 17.09.0-ceまとめCircleCI で docker build する時の warning例えば以下のような Dockerfile があったとします。FROM amazonlinux:2ENV RUBY_VERSION=2.7.2 \\    BUNDLER_VERSION=2.2.9 \\    TZ=/usr/share/zoneinfo/Asia/TokyoRUN \\    # Install mysql-community-devel    yum install -y yum-utils \u0026\u0026 \\    yum localinstall -y https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm \u0026\u0026 \\    yum-config-manager --enable mysql57-community \u0026\u0026 \\    yum-config-manager --disable mysql80-community \u0026\u0026 \\    yum install -y mysql-community-devel \u0026\u0026 \\    yum remove -y mysql80-community-release yum-utils \u0026\u0026 \\    \\    # Install ruby    yum install -y \"https://github.com/feedforce/ruby-rpm/releases/download/${RUBY_VERSION}/ruby-${RUBY_VERSION}-1.el7.centos.x86_64.rpm\" \u0026\u0026 \\    printf \"install: --no-document\\nupdate: --no-document\\n\" \u003e /etc/gemrc \u0026\u0026 \\    gem install -v \"$BUNDLER_VERSION\" bundlerこれを使って CircleCI で docker build すると、Empty continuation lines will become errors in a future release. という warning が出てしまいます。docker build 時の warning普通に読むと、何もコマンドを実行していない \\ だけの行やコメントだけの行を消した方が良いのかな？と受け取ってしまいがちですが、これは実は Docker 側のバグでした。warning が出たのは Docker のバグ本来はただの空行だけの場合に warning を出したかったようですが、コメントが書かれた行も warning が出てしまっているようです。以下に書かれているように、Docker 17.10 で修正済みとのことです。Thanks for reporting; this issue was resolved through #35004, which is included in Docker 17.10 and up.I'll close this issue because this was resolved, but feel free to continue the conversation 👍github.comただ、Docker 17.10 というと 2017/10 リリースのバージョンですので、2021/02 現在でまだバグが残っているのはおかしいです。CircleCI の Docker のバージョンを確認してみましょう。CircleCI の Docker のデフォルトバージョンは 17.09.0-ceCircleCI 内で docker build を実行するためには setup_remote_docker が必要です。setup_remote_docker によって CircleCI のジョブのホスト VM で Docker Engine が起動しますが、そこで使われている Docker Engine のバージョンは 17.09.0-ce でした。CircleCI の Docker Engine バージョンDocker のバグが修正されたのは 17.10 ですので、確かにまだバグが残っているバージョンです。さて CircleCI の setup_remote_docker ですが、実はデフォルトでは 17.09.0-ce が使われるようです。https://circleci.com/docs/2.0/building-docker-images/#docker-versionまとめDockerfile で \\ だけの行やコメントだけの行がある時に CircleCI で docker build すると Empty continuation lines will become errors in a future release. という warning が出るのは Docker のバグと CircleCI の setup_remote_docker のデフォルトバージョンが古い、という合わせ技によって起きていました。warning 自体は Docker のバグだったので無視で良いですが、古いバージョンを使い続けるのはあまり良くない気がします。基本的にはデフォルトを使いたいところですが、17.09.0-ce だと色々な機能が使えないですし、上述したバグもあるので setup_remote_docker を使うときは version を指定することをおすすめします。","link":"https://developer.feedforce.jp/entry/2021/02/17/110000","isoDate":"2021-02-17T02:00:00.000Z","dateMiliSeconds":1613527200000,"imageUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20210215/20210215173356.png","authorName":"tsub"},{"title":"docker-compose での MySQL の疎通確認で telnet を使う時に自動でコネクションを切る","content":"\u003cp\u003eこんにちは、\u003ca href=\"http://blog.hatena.ne.jp/tsub511/\" class=\"hatena-id-icon\"\u003e\u003cimg src=\"https://cdn.profile-image.st-hatena.com/users/tsub511/profile.png\" width=\"16\" height=\"16\" alt=\"\" class=\"hatena-id-icon\"\u003eid:tsub511\u003c/a\u003e です。\u003c/p\u003e\n\n\u003cp\u003eTELNET プロトコルには全く馴染みがないのですが、今回たまたま使う機会があり、かつ調べても割と見つけられない情報だったので記事を書いてみました。\u003c/p\u003e\n\n\u003cul class=\"table-of-contents\"\u003e\n    \u003cli\u003e\u003ca href=\"#curl-で-TELNET-プロトコルを使う\"\u003ecurl で TELNET プロトコルを使う\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#ユースケース\"\u003eユースケース\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#解説\"\u003e解説\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"curl-で-TELNET-プロトコルを使う\"\u003ecurl で TELNET プロトコルを使う\u003c/h2\u003e\n\n\u003cp\u003ecurl は HTTP/HTTPS 以外のプロトコルも使うことができます。\u003c/p\u003e\n\n\u003cp\u003ecurl のドキュメントを確認すると、サポートしているプロコトルは \u003ccode\u003eDICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET and TFTP\u003c/code\u003e のようです。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e$ man curl # in macOS\n\ncurl(1)                                                                                                                    Curl Manual                                                                                                                    curl(1)\n\n\n\nNAME\n       curl - transfer a URL\n\nSYNOPSIS\n       curl [options / URLs]\n\nDESCRIPTION\n       curl is a tool to transfer data from or to a server, using one of the supported protocols (DICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET and TFTP). The command\n       is designed to work without user interaction.\n\n       curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connections, cookies, file transfer resume, Metalink, and more. As you will see below, the number of features will make your head spin!\n\n       curl is powered by libcurl for all transfer-related features. See libcurl(3) for details.\n...\u003c/pre\u003e\n\n\n\u003cp\u003e例えば以下のように指定することで TELNET プロトコルで対象のサーバーに接続することが可能です。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e$ curl telnet://localhost:3306\u003c/pre\u003e\n\n\n\u003ch2 id=\"ユースケース\"\u003eユースケース\u003c/h2\u003e\n\n\u003cp\u003edocker-compose ではコンテナ間の依存関係を \u003ccode\u003edepends_on\u003c/code\u003e で定義できますが、コンテナ内でサーバーなどが立ち上がるまでは待ってくれません。\u003c/p\u003e\n\n\u003cp\u003eそこで、以下のドキュメントに書いてあるような方法でコンテナ間で依存しているサーバーに対するヘルスチェックを行うことで解決できます。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fdocs.docker.com%2Fcompose%2Fstartup-order%2F\" title=\"Control startup and shutdown order in Compose\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://docs.docker.com/compose/startup-order/\"\u003edocs.docker.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e実際には以下のスクリプトで MySQL サーバーの起動を待ってから別のコンテナを実行するような仕組みにしていました。\u003c/p\u003e\n\n\u003cpre class=\"code lang-sh\" data-lang=\"sh\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e#!/bin/bash\u003c/span\u003e\n\n\u003cspan class=\"synIdentifier\"\u003ehost\u003c/span\u003e=\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e$1\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003eshift\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003ecmd\u003c/span\u003e=\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e$@\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\n\n\u003cspan class=\"synStatement\"\u003euntil mysql -h \u0026quot;\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e$host\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot; -u root -e '\u003c/span\u003e\u003cspan class=\"synConstant\"\u003eshow databases\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e' \u0026gt; /dev/null \u003c/span\u003e\u003cspan class=\"synConstant\"\u003e2\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026gt;\u0026amp;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e; do\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003e\u0026gt;\u0026amp;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e2\u003c/span\u003e \u003cspan class=\"synStatement\"\u003eecho\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003eMySQL is unavailable - sleeping\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003esleep\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003edone\u003c/span\u003e\n\n\u003cspan class=\"synStatement\"\u003e\u0026gt;\u0026amp;2\u003c/span\u003e \u003cspan class=\"synStatement\"\u003eecho\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003eMySQL is up - executing\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003eexec\u003c/span\u003e \u003cspan class=\"synPreProc\"\u003e$cmd\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003eただ、この方法だと mysql コマンドがコンテナ内にインストールされている必要があります。\u003c/p\u003e\n\n\u003cp\u003e本番環境でのコンテナの実行を考慮すると、mysql のクライアントはインストールする必要がなかったので mysql コマンド以外の方法で MySQL サーバーの起動を確認する必要がありました。\u003c/p\u003e\n\n\u003cp\u003eそこで、ベースイメージの都合でたまたま curl がインストールされていたので curl の TELNET プロトコルを使うことにしました。\u003c/p\u003e\n\n\u003cp\u003e変更後のスクリプトが以下になります。\u003c/p\u003e\n\n\u003cpre class=\"code lang-sh\" data-lang=\"sh\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e#!/bin/bash\u003c/span\u003e\n\n\u003cspan class=\"synIdentifier\"\u003ehost\u003c/span\u003e=\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e$1\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003eshift\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003ecmd\u003c/span\u003e=\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e$@\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\n\n\u003cspan class=\"synStatement\"\u003euntil echo\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e'\u003c/span\u003e\u003cspan class=\"synConstant\"\u003equit\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e'\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e| curl telnet://\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e$host\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e:3306 \u0026gt; /dev/null \u003c/span\u003e\u003cspan class=\"synConstant\"\u003e2\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026gt;\u0026amp;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e; do\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003e\u0026gt;\u0026amp;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e2\u003c/span\u003e \u003cspan class=\"synStatement\"\u003eecho\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003eMySQL is unavailable - sleeping\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003esleep\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003edone\u003c/span\u003e\n\n\u003cspan class=\"synStatement\"\u003e\u0026gt;\u0026amp;2\u003c/span\u003e \u003cspan class=\"synStatement\"\u003eecho\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003eMySQL is up - executing\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003eexec\u003c/span\u003e \u003cspan class=\"synPreProc\"\u003e$cmd\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003e変更したのは 7 行目のみで、mysql コマンドを curl に置き換えています。\u003c/p\u003e\n\n\u003cp\u003eこうすることで mysql のクライアントをインストールせずに MySQL サーバーが起動するのを待ってから別のコンテナを実行することができるようになりました。\u003c/p\u003e\n\n\u003ch2 id=\"解説\"\u003e解説\u003c/h2\u003e\n\n\u003cp\u003e例えば以下のように実行すると、TELNET プロトコルを使って疎通確認ができます。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e$ docker run -d -p 3306:3306 -e MYSQL_ALLOW_EMPTY_PASSWORD=1 mysql\n$ curl -s -o /dev/null telnet://localhost:3306\n\u003c/pre\u003e\n\n\n\u003cp\u003eただしこのままだと Ctrl+C などでコネクションを切るまで curl が実行されたままになります。\u003c/p\u003e\n\n\u003cp\u003eTELNET プロトコルは対話型であるため、コネクションを張りっぱなしになるという認識です。\u003c/p\u003e\n\n\u003cp\u003eCtrl+C が必要ということは、上述したスクリプトでは使えません。\u003c/p\u003e\n\n\u003cp\u003eではどうすれば疎通確認後に自動でコネクションを切れるでしょうか。\u003c/p\u003e\n\n\u003cp\u003e実は以下のように \u003ccode\u003equit\u003c/code\u003e を curl に標準入力で渡すことで解決できます。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e$ docker run -d -p 3306:3306 -e MYSQL_ALLOW_EMPTY_PASSWORD=1 mysql\n$ echo \u0026#39;quit\u0026#39; | curl -s -o /dev/null telnet://localhost:3306\u003c/pre\u003e\n\n\n\u003cp\u003e\u003ccode\u003equit\u003c/code\u003e とは何かというと、telnet コマンドでは \u003ccode\u003equit\u003c/code\u003e というコマンドを指定することで telnet の接続を切ることができます。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e$ man telnet # in macOS with brew install telnet\n\nTELNET(1)                 BSD General Commands Manual                TELNET(1)\n\nNAME\n     telnet -- user interface to the TELNET protocol\n\nSYNOPSIS\n     telnet [-468EFKLNacdfruxy] [-S tos] [-X authtype] [-e escapechar] [-k realm] [-l user] [-n tracefile] [-s src_addr] [host [port]]\n\nDESCRIPTION\n     The telnet command is used to communicate with another host using the TELNET protocol.  If telnet is invoked without the host argument, it enters command mode, indicated by its prompt (``telnet\u0026gt;\u0026#39;\u0026#39;).  In this mode, it accepts and executes the commands\n     listed below.  If it is invoked with arguments, it performs an open command with those arguments.\n\n     Options:\n\n...\n\nquit       Close any open TELNET session and exit telnet.  An end of file (in command mode) will also close a session and exit.\u003c/pre\u003e\n\n\n\u003cp\u003eそして \u003ccode\u003equit\u003c/code\u003e を使った telnet コマンドを自動的に終了するための方法が以下の記事で紹介されていました。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fqiita.com%2Fgyoon%2Fitems%2Fdeb7ee62fbe4e9c1a907\" title=\"Telnetの自動化 - Qiita\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://qiita.com/gyoon/items/deb7ee62fbe4e9c1a907\"\u003eqiita.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e上記の記事を参考に、curl でも同様の方法を試してみたら動いた、ということになります。\u003c/p\u003e\n\n\u003cp\u003eただし、curl に標準入力を渡すことで TELNET プロトコルにコマンドを渡すことができる、という挙動自体は curl のドキュメントを確認しても見つけられませんでした。\u003c/p\u003e\n\n\u003cp\u003e公式の情報で裏が取れない限りは当記事の事例のように開発環境でのみ使った方が良いかもしれません。\u003c/p\u003e\n","contentSnippet":"こんにちは、id:tsub511 です。TELNET プロトコルには全く馴染みがないのですが、今回たまたま使う機会があり、かつ調べても割と見つけられない情報だったので記事を書いてみました。curl で TELNET プロトコルを使うユースケース解説curl で TELNET プロトコルを使うcurl は HTTP/HTTPS 以外のプロトコルも使うことができます。curl のドキュメントを確認すると、サポートしているプロコトルは DICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET and TFTP のようです。$ man curl # in macOScurl(1)                                                                                                                    Curl Manual                                                                                                                    curl(1)NAME       curl - transfer a URLSYNOPSIS       curl [options / URLs]DESCRIPTION       curl is a tool to transfer data from or to a server, using one of the supported protocols (DICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET and TFTP). The command       is designed to work without user interaction.       curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connections, cookies, file transfer resume, Metalink, and more. As you will see below, the number of features will make your head spin!       curl is powered by libcurl for all transfer-related features. See libcurl(3) for details....例えば以下のように指定することで TELNET プロトコルで対象のサーバーに接続することが可能です。$ curl telnet://localhost:3306ユースケースdocker-compose ではコンテナ間の依存関係を depends_on で定義できますが、コンテナ内でサーバーなどが立ち上がるまでは待ってくれません。そこで、以下のドキュメントに書いてあるような方法でコンテナ間で依存しているサーバーに対するヘルスチェックを行うことで解決できます。docs.docker.com実際には以下のスクリプトで MySQL サーバーの起動を待ってから別のコンテナを実行するような仕組みにしていました。#!/bin/bashhost=\"$1\"shiftcmd=\"$@\"until mysql -h \"$host\" -u root -e 'show databases' \u003e /dev/null 2\u003e\u00261; do  \u003e\u00262 echo \"MySQL is unavailable - sleeping\"  sleep 1done\u003e\u00262 echo \"MySQL is up - executing\"exec $cmdただ、この方法だと mysql コマンドがコンテナ内にインストールされている必要があります。本番環境でのコンテナの実行を考慮すると、mysql のクライアントはインストールする必要がなかったので mysql コマンド以外の方法で MySQL サーバーの起動を確認する必要がありました。そこで、ベースイメージの都合でたまたま curl がインストールされていたので curl の TELNET プロトコルを使うことにしました。変更後のスクリプトが以下になります。#!/bin/bashhost=\"$1\"shiftcmd=\"$@\"until echo 'quit' | curl telnet://$host:3306 \u003e /dev/null 2\u003e\u00261; do  \u003e\u00262 echo \"MySQL is unavailable - sleeping\"  sleep 1done\u003e\u00262 echo \"MySQL is up - executing\"exec $cmd変更したのは 7 行目のみで、mysql コマンドを curl に置き換えています。こうすることで mysql のクライアントをインストールせずに MySQL サーバーが起動するのを待ってから別のコンテナを実行することができるようになりました。解説例えば以下のように実行すると、TELNET プロトコルを使って疎通確認ができます。$ docker run -d -p 3306:3306 -e MYSQL_ALLOW_EMPTY_PASSWORD=1 mysql$ curl -s -o /dev/null telnet://localhost:3306ただしこのままだと Ctrl+C などでコネクションを切るまで curl が実行されたままになります。TELNET プロトコルは対話型であるため、コネクションを張りっぱなしになるという認識です。Ctrl+C が必要ということは、上述したスクリプトでは使えません。ではどうすれば疎通確認後に自動でコネクションを切れるでしょうか。実は以下のように quit を curl に標準入力で渡すことで解決できます。$ docker run -d -p 3306:3306 -e MYSQL_ALLOW_EMPTY_PASSWORD=1 mysql$ echo 'quit' | curl -s -o /dev/null telnet://localhost:3306quit とは何かというと、telnet コマンドでは quit というコマンドを指定することで telnet の接続を切ることができます。$ man telnet # in macOS with brew install telnetTELNET(1)                 BSD General Commands Manual                TELNET(1)NAME     telnet -- user interface to the TELNET protocolSYNOPSIS     telnet [-468EFKLNacdfruxy] [-S tos] [-X authtype] [-e escapechar] [-k realm] [-l user] [-n tracefile] [-s src_addr] [host [port]]DESCRIPTION     The telnet command is used to communicate with another host using the TELNET protocol.  If telnet is invoked without the host argument, it enters command mode, indicated by its prompt (``telnet\u003e'').  In this mode, it accepts and executes the commands     listed below.  If it is invoked with arguments, it performs an open command with those arguments.     Options:...quit       Close any open TELNET session and exit telnet.  An end of file (in command mode) will also close a session and exit.そして quit を使った telnet コマンドを自動的に終了するための方法が以下の記事で紹介されていました。qiita.com上記の記事を参考に、curl でも同様の方法を試してみたら動いた、ということになります。ただし、curl に標準入力を渡すことで TELNET プロトコルにコマンドを渡すことができる、という挙動自体は curl のドキュメントを確認しても見つけられませんでした。公式の情報で裏が取れない限りは当記事の事例のように開発環境でのみ使った方が良いかもしれません。","link":"https://developer.feedforce.jp/entry/2021/02/16/110000","isoDate":"2021-02-16T02:00:00.000Z","dateMiliSeconds":1613440800000,"imageUrl":"https://cdn.user.blog.st-hatena.com/default_entry_og_image/4268819/1588226000876991","authorName":"tsub"},{"title":"「aws-vault loginでChromeのウィンドウをAWSアカウント毎に分離する」を Alfred 用に作った","content":"\u003cp\u003e\u003ci class=\"fa fa-github\"\u003e\u003c/i\u003e \u003ca href=\"https://github.com/tsub/alfred-aws-vault-workflow\"\u003etsub/alfred-aws-vault-workflow: A Alfred workflow to open the AWS Management Console with aws-vault\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eChrome 版\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://i.gyazo.com/33341687e0419d3863f913a00997744c.gif\" alt=\"Features for Google Chrome\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eFirefox (\u003ca href=\"https://addons.mozilla.org/firefox/addon/multi-account-containers/\"\u003eMulti-Account Container\u003c/a\u003e extension) 版\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://i.gyazo.com/a68e0d4cd6f9a80b659cfc1694cd85dd.gif\" alt=\"Features for Firefox\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eaws-vault 自体今回初めて知ったのですが、以下の記事を読んで、複数の AWS アカウント使いには大変便利そうだったので Alfred 用のものをシュッと作りました。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://qiita.com/minamijoyo/items/f3cbb003a34954a32970\"\u003eaws-vault loginでChromeのウィンドウをAWSアカウント毎に分離する - Qiita\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"tsub/alfred-aws-vault-workflow: A Alfred workflow to open the AWS Management Console with aws-vaultChrome 版Firefox (Multi-Account Container extension) 版aws-vault 自体今回初めて知ったのですが、以下の記事を読んで、複数の AWS アカウント使いには大変便利そうだったので Alfred 用のものをシュッと作りました。aws-vault loginでChromeのウィンドウをAWSアカウント毎に分離する - Qiita","link":"https://blog.tsub.me/post/create-alfred-aws-vault-workflow/","isoDate":"2019-10-06T05:35:00.000Z","dateMiliSeconds":1570340100000,"authorName":"tsub"},{"title":" Dynamoid のスレッドセーフではない実装を直しました","content":"\u003cp\u003eこんにちは。インフラエンジニアの \u003ca href=\"http://blog.hatena.ne.jp/tsub511/\" class=\"hatena-id-icon\"\u003e\u003cimg src=\"https://cdn.profile-image.st-hatena.com/users/tsub511/profile.png\" width=\"16\" height=\"16\" alt=\"\" class=\"hatena-id-icon\"\u003eid:tsub511\u003c/a\u003e です。\u003c/p\u003e\n\n\u003cp\u003e私は Dynamoid のメンテナではないのですが、弊社内で今回それなりに大きい問題が起きて、得た知見も大きかったため記事にしました。\u003c/p\u003e\n\n\u003ch2\u003eTL;DR\u003c/h2\u003e\n\n\u003cp\u003eDynamoid にスレッドセーフではない実装があったが \u003ca href=\"https://github.com/Dynamoid/dynamoid/pull/373\"\u003ePR をマージしてもらって\u003c/a\u003e修正済み。\u003c/p\u003e\n\n\u003cp\u003e2019/08/13 時点ではまだリリースされていないようなので、エラーで困っている方は master ブランチをお使いください。\u003c/p\u003e\n\n\u003ch2\u003e今回起きた問題\u003c/h2\u003e\n\n\u003cp\u003e弊サービスでは Sidekiq 上で Dynamoid を使っています。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fgithub.com%2FDynamoid%2Fdynamoid\" title=\"Dynamoid/dynamoid\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://github.com/Dynamoid/dynamoid\"\u003egithub.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e基本的に問題なく稼働していたのですが、デプロイ時に Sidekiq を再起動した後、Bugsnag に以下のような二種類のエラーが継続的に飛んできました。\u003c/p\u003e\n\n\u003cp\u003e\u003cfigure class=\"figure-image figure-image-fotolife\" title=\"undefined method \u0026#x60;[]\u0026#x27; for nil:NilClass\"\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20190809/20190809182531.png\" alt=\"f:id:tsub511:20190809182531p:plain\" title=\"f:id:tsub511:20190809182531p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003cfigcaption\u003eundefined method \u0026#x60;\u0026#x5B;\u0026#x5D;\u0026#x27; for nil:NilClass\u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cfigure class=\"figure-image figure-image-fotolife\" title=\"undefined method \u0026#x60;query\u0026#x27; for #\u0026lt;Dynamoid::AdapterPlugin::AwsSdkV3:0x00000000078dc1b8\u0026gt; Did you mean? to_query\"\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20190809/20190809182800.png\" alt=\"f:id:tsub511:20190809182800p:plain\" title=\"f:id:tsub511:20190809182800p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003cfigcaption\u003eundefined method \u0026#x60;query\u0026#x27; for #\u0026lt;Dynamoid::AdapterPlugin::AwsSdkV3:0x00000000078dc1b8\u0026gt; Did you mean? to_query\u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e\n\n\u003cp\u003eこのエラーが起きると、自然には回復しないため、Sidekiq のワーカーを再起動する必要があります。\u003c/p\u003e\n\n\u003cp\u003eまた、\u003ccode\u003eNoMethodError\u003c/code\u003e という一般的な例外クラスのため ActiveJob の \u003ccode\u003eretry_on\u003c/code\u003e によるリトライ処理の考慮はしておらず、大事なジョブが実行されないままになってしまうのも問題です。\u003c/p\u003e\n\n\u003cp\u003eエラーをパッと見ただけでは、キャッシュの実装に考慮漏れがあるのかな？とか、インスタンスが生成されていて\u003ca href=\"https://github.com/Dynamoid/dynamoid/blob/v3.2.0/lib/dynamoid/adapter_plugin/aws_sdk_v3.rb\"\u003eコード上ではメソッドが実装されている\u003c/a\u003eのになんで undefined method エラーが起きるんだ？などと、不思議なエラーが出ていて調査が難航しそうな印象でした。\u003c/p\u003e\n\n\u003ch2\u003e何が原因だったのか\u003c/h2\u003e\n\n\u003cp\u003eSidekiq + Dynamoid でピンと来る方もいると思いますが、エラーの原因は Dynamoid にスレッドセーフではない実装があったことでした。\u003c/p\u003e\n\n\u003cp\u003eスレッドセーフではない実装がどこにあったのか探すために、ここで発生していたエラーをもう一度見てみます。\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003e\u003cfigure class=\"figure-image figure-image-fotolife\" title=\"undefined method \u0026#x60;\u003cspan data-unlink\u003e\u0026#x27; for nil:NilClass\"\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20190809/20190809182531.png\" alt=\"f:id:tsub511:20190809182531p:plain\" title=\"f:id:tsub511:20190809182531p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003cfigcaption\u003eundefined method \u0026#x60;\u003c/span\u003e\u0026#x27; for nil:NilClass\u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eまず 1 つ目のエラーは \u003ccode\u003enil\u003c/code\u003e に対して \u003ccode\u003e#[]\u003c/code\u003e を呼び出そうとしてエラーになっていますが、\u003ccode\u003enil\u003c/code\u003e になっている変数は \u003ccode\u003etable_cache\u003c/code\u003e です。\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003etable_cache\u003c/code\u003e は以下で初期化されています。\u003c/p\u003e\n\n\u003cpre class=\"code lang-ruby\" data-lang=\"ruby\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e# https://github.com/Dynamoid/dynamoid/blob/v3.2.0/lib/dynamoid/adapter_plugin/aws_sdk_v3.rb#L66-L69\u003c/span\u003e\n\u003cspan class=\"synPreProc\"\u003edef\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003econnect!\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e@client\u003c/span\u003e = \u003cspan class=\"synType\"\u003eAws\u003c/span\u003e::\u003cspan class=\"synType\"\u003eDynamoDB\u003c/span\u003e::\u003cspan class=\"synType\"\u003eClient\u003c/span\u003e.new(connection_config)\n  \u003cspan class=\"synIdentifier\"\u003e@table_cache\u003c/span\u003e = {}\n\u003cspan class=\"synPreProc\"\u003eend\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003eそして、この初期化のための \u003ccode\u003eDynamoid::AdapterPlugin::AwsSdkV3#connect!\u003c/code\u003e を呼び出しているのは \u003ccode\u003eDynamoid::Adapter#adapter\u003c/code\u003e です。\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003eadapter.connect!\u003c/code\u003e の部分に \u003ccode\u003eif adapter.respond_to?(:connect!)\u003c/code\u003e という条件がありますが、ここが \u003ccode\u003efalse\u003c/code\u003e になっていて \u003ccode\u003eadapter.connect!\u003c/code\u003e が実行されていないため、\u003ccode\u003etable_cache\u003c/code\u003e の初期化処理が動いていないようです。\u003c/p\u003e\n\n\u003cpre class=\"code lang-ruby\" data-lang=\"ruby\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e# https://github.com/Dynamoid/dynamoid/blob/v3.2.0/lib/dynamoid/adapter.rb#L29-L37\u003c/span\u003e\n\u003cspan class=\"synPreProc\"\u003edef\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003eadapter\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003eunless\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e@adapter_\u003c/span\u003e.value\n    adapter = \u003cspan class=\"synConstant\"\u003eself\u003c/span\u003e.class.adapter_plugin_class.new\n    adapter.connect! \u003cspan class=\"synStatement\"\u003eif\u003c/span\u003e adapter.respond_to?(\u003cspan class=\"synConstant\"\u003e:connect!\u003c/span\u003e)\n    \u003cspan class=\"synIdentifier\"\u003e@adapter_\u003c/span\u003e.compare_and_set(\u003cspan class=\"synConstant\"\u003enil\u003c/span\u003e, adapter)\n    clear_cache!\n  \u003cspan class=\"synStatement\"\u003eend\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e@adapter_\u003c/span\u003e.value\n\u003cspan class=\"synPreProc\"\u003eend\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003e2 つ目のエラーも見てみます。\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003e\u003cfigure class=\"figure-image figure-image-fotolife\" title=\"undefined method \u0026#x60;query\u0026#x27; for #\u0026lt;Dynamoid::AdapterPlugin::AwsSdkV3:0x00000000078dc1b8\u0026gt; Did you mean? to_query\"\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20190809/20190809182800.png\" alt=\"f:id:tsub511:20190809182800p:plain\" title=\"f:id:tsub511:20190809182800p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003cfigcaption\u003eundefined method \u0026#x60;query\u0026#x27; for #\u0026lt;Dynamoid::AdapterPlugin::AwsSdkV3:0x00000000078dc1b8\u0026gt; Did you mean? to_query\u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eこちらは \u003ccode\u003eDynamoid::AdapterPlugin::AwsSdkV3\u003c/code\u003e のインスタンス \u003ccode\u003eadapter\u003c/code\u003e に対して \u003ccode\u003equery\u003c/code\u003e を実行しようとしてメソッドが定義されていないというエラーです。\u003c/p\u003e\n\n\u003cp\u003eしかし、実際のコードにはメソッドが定義されています。\u003c/p\u003e\n\n\u003cpre class=\"code lang-ruby\" data-lang=\"ruby\" data-unlink\u003ehttps\u003cspan class=\"synConstant\"\u003e:/\u003c/span\u003e/github.com/\u003cspan class=\"synType\"\u003eDynamoid\u003c/span\u003e/dynamoid/blob/v3.\u003cspan class=\"synConstant\"\u003e2.0\u003c/span\u003e/lib/dynamoid/adapter_plugin/aws_sdk_v3.rb\u003cspan class=\"synComment\"\u003e#L489-L500\u003c/span\u003e\n \u003cspan class=\"synPreProc\"\u003edef\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003equery\u003c/span\u003e(table_name, options = {})\n  \u003cspan class=\"synType\"\u003eEnumerator\u003c/span\u003e.new \u003cspan class=\"synStatement\"\u003edo\u003c/span\u003e |\u003cspan class=\"synIdentifier\"\u003eyielder\u003c/span\u003e|\n    table = describe_table(table_name)\n\n    \u003cspan class=\"synType\"\u003eQuery\u003c/span\u003e.new(client, table, options).call.each \u003cspan class=\"synStatement\"\u003edo\u003c/span\u003e |\u003cspan class=\"synIdentifier\"\u003epage\u003c/span\u003e|\n      yielder.yield(\n        page.items.map { |\u003cspan class=\"synIdentifier\"\u003erow\u003c/span\u003e| result_item_to_hash(row) },\n        \u003cspan class=\"synConstant\"\u003elast_evaluated_key\u003c/span\u003e: page.last_evaluated_key\n      )\n    \u003cspan class=\"synStatement\"\u003eend\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003eend\u003c/span\u003e\n \u003cspan class=\"synPreProc\"\u003eend\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003e視点を変えて、\u003ccode\u003eadapter\u003c/code\u003e インスタンスを定義しているコードを見てみると、やはり \u003ccode\u003eDynamoid::Adapter#adapter\u003c/code\u003e に行き着きます。\u003c/p\u003e\n\n\u003cpre class=\"code lang-ruby\" data-lang=\"ruby\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e# https://github.com/Dynamoid/dynamoid/blob/v3.2.0/lib/dynamoid/adapter.rb#L29-L37\u003c/span\u003e\n\u003cspan class=\"synPreProc\"\u003edef\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003eadapter\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003eunless\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e@adapter_\u003c/span\u003e.value\n    adapter = \u003cspan class=\"synConstant\"\u003eself\u003c/span\u003e.class.adapter_plugin_class.new\n    adapter.connect! \u003cspan class=\"synStatement\"\u003eif\u003c/span\u003e adapter.respond_to?(\u003cspan class=\"synConstant\"\u003e:connect!\u003c/span\u003e)\n    \u003cspan class=\"synIdentifier\"\u003e@adapter_\u003c/span\u003e.compare_and_set(\u003cspan class=\"synConstant\"\u003enil\u003c/span\u003e, adapter)\n    clear_cache!\n  \u003cspan class=\"synStatement\"\u003eend\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e@adapter_\u003c/span\u003e.value\n\u003cspan class=\"synPreProc\"\u003eend\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003e\u003ccode\u003eself.class.adapter_plugin_class.new\u003c/code\u003e で生成したものをメモ化しています。\u003c/p\u003e\n\n\u003cp\u003eメモ化には \u003ca href=\"https://github.com/ruby-concurrency/concurrent-ruby\"\u003econcurrent-ruby\u003c/a\u003e を使っていて、\u003ca href=\"https://github.com/Dynamoid/dynamoid/commit/ed004b2d53c7500e10bca914ee844957939df2df\"\u003e過去に対策されたよう\u003c/a\u003eなのでそこは問題なさそうです。\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003eself.class.adapter_plugin_class.new\u003c/code\u003e の先が怪しそうなのでコードを見てみると、なにやら動的に \u003ccode\u003erequire\u003c/code\u003e しています。\u003c/p\u003e\n\n\u003cpre class=\"code lang-ruby\" data-lang=\"ruby\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e# https://github.com/Dynamoid/dynamoid/blob/v3.2.0/lib/dynamoid/adapter.rb#L181-L187\u003c/span\u003e\n\u003cspan class=\"synPreProc\"\u003edef\u003c/span\u003e \u003cspan class=\"synConstant\"\u003eself\u003c/span\u003e.\u003cspan class=\"synIdentifier\"\u003eadapter_plugin_class\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003eunless\u003c/span\u003e \u003cspan class=\"synType\"\u003eDynamoid\u003c/span\u003e.const_defined?(\u003cspan class=\"synConstant\"\u003e:AdapterPlugin\u003c/span\u003e) \u0026amp;\u0026amp; \u003cspan class=\"synType\"\u003eDynamoid\u003c/span\u003e::\u003cspan class=\"synType\"\u003eAdapterPlugin\u003c/span\u003e.const_defined?(\u003cspan class=\"synType\"\u003eDynamoid\u003c/span\u003e::\u003cspan class=\"synType\"\u003eConfig\u003c/span\u003e.adapter.camelcase)\n    \u003cspan class=\"synPreProc\"\u003erequire\u003c/span\u003e \u003cspan class=\"synSpecial\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003edynamoid/adapter_plugin/\u003c/span\u003e\u003cspan class=\"synSpecial\"\u003e#{\u003c/span\u003e\u003cspan class=\"synType\"\u003eDynamoid\u003c/span\u003e::\u003cspan class=\"synType\"\u003eConfig\u003c/span\u003e.adapter\u003cspan class=\"synSpecial\"\u003e}\u0026quot;\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003eend\u003c/span\u003e\n\n  \u003cspan class=\"synType\"\u003eDynamoid\u003c/span\u003e::\u003cspan class=\"synType\"\u003eAdapterPlugin\u003c/span\u003e.const_get(\u003cspan class=\"synType\"\u003eDynamoid\u003c/span\u003e::\u003cspan class=\"synType\"\u003eConfig\u003c/span\u003e.adapter.camelcase)\n\u003cspan class=\"synPreProc\"\u003eend\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003e実はスレッドセーフではない実装はこの \u003ccode\u003erequire\u003c/code\u003e する条件の \u003ccode\u003eDynamoid.const_defined?(:AdapterPlugin) \u0026amp;\u0026amp; Dynamoid::AdapterPlugin.const_defined?(Dynamoid::Config.adapter.camelcase)\u003c/code\u003e の部分です。\u003c/p\u003e\n\n\u003cp\u003eエラーを再現できるコードを Gist に用意しましたのでそちらを使って確認していきます。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://gist.github.com/tsub/72e60233ed82a8a453428ea7441e6017\"\u003eTest codes to reproduce not thread-safe errors of Dynamoid \u0026middot; GitHub\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eDynamoid に以下のような変更を加えて、\u003ccode\u003eunless\u003c/code\u003e の中に入らず \u003ccode\u003erequire\u003c/code\u003e が実行されなかった時の状態を見てみます。\u003c/p\u003e\n\n\u003cpre class=\"code lang-diff\" data-lang=\"diff\" data-unlink\u003e\u003cspan class=\"synType\"\u003ediff --git a/lib/dynamoid/adapter.rb b/lib/dynamoid/adapter.rb\u003c/span\u003e\n\u003cspan class=\"synPreProc\"\u003eindex f390ecf..df2a58c 100644\u003c/span\u003e\n\u003cspan class=\"synType\"\u003e--- a/lib/dynamoid/adapter.rb\u003c/span\u003e\n\u003cspan class=\"synType\"\u003e+++ b/lib/dynamoid/adapter.rb\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003e@@ -181,6 +181,13 @@\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e module Dynamoid\u003c/span\u003e\n     def self.adapter_plugin_class\n       unless Dynamoid.const_defined?(:AdapterPlugin) \u0026amp;\u0026amp; Dynamoid::AdapterPlugin.const_defined?(Dynamoid::Config.adapter.camelcase)\n         require \u0026quot;dynamoid/adapter_plugin/#{Dynamoid::Config.adapter}\u0026quot;\n\u003cspan class=\"synIdentifier\"\u003e+      else\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e+        tmp_adapter = Dynamoid::AdapterPlugin.const_get(Dynamoid::Config.adapter.camelcase).new\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e+        puts \u0026lt;\u0026lt;~EOS\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e+          respond_to?(:connect!): #{tmp_adapter.respond_to?(:connect!)},\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e+          respond_to?(:query): #{tmp_adapter.respond_to?(:query)},\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e+          require: #{require \u0026quot;dynamoid/adapter_plugin/#{Dynamoid::Config.adapter}\u0026quot;}\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e+        EOS\u003c/span\u003e\n       end\n \n       Dynamoid::AdapterPlugin.const_get(Dynamoid::Config.adapter.camelcase)\n\u003c/pre\u003e\n\n\n\u003cp\u003eすると、スレッドによっては \u003ccode\u003econst_defined?\u003c/code\u003e の結果が \u003ccode\u003etrue\u003c/code\u003e で、\u003ccode\u003erequire\u003c/code\u003e の結果も \u003ccode\u003efalse\u003c/code\u003e (コードがロード済み) なのに、実際のメソッドが存在しないという現象が起きていることが分かりました。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e$ bundle exec ruby main.rb\n...\nrespond_to?(:connect!): false,\nrespond_to?(:query): false,\nrequire: false\n...\u003c/pre\u003e\n\n\n\u003cp\u003eここからは Ruby の \u003ccode\u003erequire\u003c/code\u003e の実装を知らないため推測になります。\u003c/p\u003e\n\n\u003cp\u003eおそらくマルチスレッド環境下で \u003ccode\u003erequire\u003c/code\u003e を実行すると、\u003ccode\u003erequire\u003c/code\u003e を実行したスレッド内では全てのコードがロードされた状態になりますが、別のスレッドではクラス定義などの「ガワ」だけがロードされた状態になっているのではないかと思いました。\u003c/p\u003e\n\n\u003cp\u003eそのため、ロードが不十分なスレッドでインスタンスを生成できるが、メソッドが定義されていない、という状態になっているのかと思われます。\u003c/p\u003e\n\n\u003ch2\u003e解決方法\u003c/h2\u003e\n\n\u003cp\u003eよって、全てのスレッドで確実に \u003ccode\u003erequire\u003c/code\u003e を実行することで今回のエラーが解決するという結論に至りました。\u003c/p\u003e\n\n\u003cpre class=\"code lang-diff\" data-lang=\"diff\" data-unlink\u003e\u003cspan class=\"synType\"\u003ediff --git a/lib/dynamoid/adapter.rb b/lib/dynamoid/adapter.rb\u003c/span\u003e\n\u003cspan class=\"synPreProc\"\u003eindex f390ecf..8449e34 100644\u003c/span\u003e\n\u003cspan class=\"synType\"\u003e--- a/lib/dynamoid/adapter.rb\u003c/span\u003e\n\u003cspan class=\"synType\"\u003e+++ b/lib/dynamoid/adapter.rb\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003e@@ -179,9 +179,7 @@\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e module Dynamoid\u003c/span\u003e\n     end\n \n     def self.adapter_plugin_class\n\u003cspan class=\"synSpecial\"\u003e-      unless Dynamoid.const_defined?(:AdapterPlugin) \u0026amp;\u0026amp; Dynamoid::AdapterPlugin.const_defined?(Dynamoid::Config.adapter.camelcase)\u003c/span\u003e\n\u003cspan class=\"synSpecial\"\u003e-        require \u0026quot;dynamoid/adapter_plugin/#{Dynamoid::Config.adapter}\u0026quot;\u003c/span\u003e\n\u003cspan class=\"synSpecial\"\u003e-      end\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e+      require \u0026quot;dynamoid/adapter_plugin/#{Dynamoid::Config.adapter}\u0026quot;\u003c/span\u003e\n \n       Dynamoid::AdapterPlugin.const_get(Dynamoid::Config.adapter.camelcase)\n     end\n\u003c/pre\u003e\n\n\n\u003cp\u003eエラーの原因と解決方法が判明したため、既に Dynamoid に PR を作りマージまでしてもらいました。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fgithub.com%2FDynamoid%2Fdynamoid%2Fpull%2F373\" title=\"Fix threadsafety of Dynamoid::Adapter by tsub · Pull Request #373 · Dynamoid/dynamoid\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://github.com/Dynamoid/dynamoid/pull/373\"\u003egithub.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e2019/08/13 時点ではまだリリースされていないようなので、エラーで困っている方は master ブランチをお使いください。\u003c/p\u003e\n\n\u003ch2\u003e調査に苦労した点\u003c/h2\u003e\n\n\u003cp\u003eマルチスレッドプログラミングの経験が浅いため、まずスレッドセーフではない実装があるということに気づくまでに時間がかかりました。\u003c/p\u003e\n\n\u003cp\u003eそして、エラーを再現しようとした時になかなか再現出来なかったのもハマりポイントでした。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://gist.github.com/tsub/72e60233ed82a8a453428ea7441e6017\"\u003eエラーの再現コード\u003c/a\u003eを読むと分かりますが、Dynamoid のメソッドを呼ぶ直前に \u003ccode\u003eputs\u003c/code\u003e を実行しています。\u003c/p\u003e\n\n\u003cpre class=\"code lang-ruby\" data-lang=\"ruby\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e# https://gist.github.com/tsub/72e60233ed82a8a453428ea7441e6017#file-main-rb\u003c/span\u003e\n\u003cspan class=\"synConstant\"\u003e100\u003c/span\u003e.times \u003cspan class=\"synStatement\"\u003edo\u003c/span\u003e |\u003cspan class=\"synIdentifier\"\u003ei\u003c/span\u003e|\n  safe_thread(i.to_s) \u003cspan class=\"synStatement\"\u003edo\u003c/span\u003e\n    puts \u003cspan class=\"synSpecial\"\u003e'\u003c/span\u003e\u003cspan class=\"synConstant\"\u003edebug\u003c/span\u003e\u003cspan class=\"synSpecial\"\u003e'\u003c/span\u003e \u003cspan class=\"synComment\"\u003e# To unlock Ruby's GVL\u003c/span\u003e\n    \u003cspan class=\"synType\"\u003eDocument\u003c/span\u003e.where(\u003cspan class=\"synConstant\"\u003eidentifier\u003c/span\u003e: \u003cspan class=\"synSpecial\"\u003e'\u003c/span\u003e\u003cspan class=\"synConstant\"\u003ehoge\u003c/span\u003e\u003cspan class=\"synSpecial\"\u003e'\u003c/span\u003e).first\n  \u003cspan class=\"synStatement\"\u003eend\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003eend\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003eこの \u003ccode\u003eputs\u003c/code\u003e が重要で、Ruby は GVL (Giant VM Lock) という仕組みを使って、実行されるネイティブスレッドが 1 つになるように排他制御をしています。\u003c/p\u003e\n\n\u003cp\u003eただし、IO 関連のメソッドを実行する際は GVL が一時的に解放されてスレッドが同時に実行されます。\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003eネイティブスレッドを用いて実装されていますが、 現在の実装では Ruby VM は Giant VM lock (GVL) を有しており、同時に実行される ネイティブスレッドは常にひとつです。 ただし、IO 関連のブロックする可能性があるシステムコールを行う場合には GVL を解放します。その場合にはスレッドは同時に実行され得ます。 また拡張ライブラリから GVL を操作できるので、複数のスレッドを 同時に実行するような拡張ライブラリは作成可能です。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fdocs.ruby-lang.org%2Fja%2Flatest%2Fdoc%2Fspec%3D2fthread.html\" title=\"スレッド (Ruby 2.6.0)\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://docs.ruby-lang.org/ja/latest/doc/spec=2fthread.html\"\u003edocs.ruby-lang.org\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eつまりスレッドセーフではない実装があった場合に、それを再現させるためには単純にスレッドセーフではないコードを書くだけではダメで、IO 関連のメソッドを実行して GVL を解放しないといけません。\u003c/p\u003e\n\n\u003cp\u003e少し古い記事ではありますが、こちらが参考になりました。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=http%3A%2F%2Fmoyomot.hatenablog.com%2Fentry%2F2014%2F05%2F04%2F232538\" title=\"Rubyでスレッドセーフでないことを簡単に確認したい - もょもとの技術ノート\" class=\"embed-card embed-blogcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 190px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"http://moyomot.hatenablog.com/entry/2014/05/04/232538\"\u003emoyomot.hatenablog.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e実際の本番環境ではログ出力などにより、IO 関連のメソッドは普通に実行されていることが多いかと思いますので、エラーが起きるのも納得です。\u003c/p\u003e\n","contentSnippet":"こんにちは。インフラエンジニアの id:tsub511 です。私は Dynamoid のメンテナではないのですが、弊社内で今回それなりに大きい問題が起きて、得た知見も大きかったため記事にしました。TL;DRDynamoid にスレッドセーフではない実装があったが PR をマージしてもらって修正済み。2019/08/13 時点ではまだリリースされていないようなので、エラーで困っている方は master ブランチをお使いください。今回起きた問題弊サービスでは Sidekiq 上で Dynamoid を使っています。github.com基本的に問題なく稼働していたのですが、デプロイ時に Sidekiq を再起動した後、Bugsnag に以下のような二種類のエラーが継続的に飛んできました。undefined method `[]' for nil:NilClassundefined method `query' for #\u003cDynamoid::AdapterPlugin::AwsSdkV3:0x00000000078dc1b8\u003e Did you mean? to_queryこのエラーが起きると、自然には回復しないため、Sidekiq のワーカーを再起動する必要があります。また、NoMethodError という一般的な例外クラスのため ActiveJob の retry_on によるリトライ処理の考慮はしておらず、大事なジョブが実行されないままになってしまうのも問題です。エラーをパッと見ただけでは、キャッシュの実装に考慮漏れがあるのかな？とか、インスタンスが生成されていてコード上ではメソッドが実装されているのになんで undefined method エラーが起きるんだ？などと、不思議なエラーが出ていて調査が難航しそうな印象でした。何が原因だったのかSidekiq + Dynamoid でピンと来る方もいると思いますが、エラーの原因は Dynamoid にスレッドセーフではない実装があったことでした。スレッドセーフではない実装がどこにあったのか探すために、ここで発生していたエラーをもう一度見てみます。' for nil:NilClass\"\u003eundefined method `' for nil:NilClassまず 1 つ目のエラーは nil に対して #[] を呼び出そうとしてエラーになっていますが、nil になっている変数は table_cache です。table_cache は以下で初期化されています。# https://github.com/Dynamoid/dynamoid/blob/v3.2.0/lib/dynamoid/adapter_plugin/aws_sdk_v3.rb#L66-L69def connect!  @client = Aws::DynamoDB::Client.new(connection_config)  @table_cache = {}endそして、この初期化のための Dynamoid::AdapterPlugin::AwsSdkV3#connect! を呼び出しているのは Dynamoid::Adapter#adapter です。adapter.connect! の部分に if adapter.respond_to?(:connect!) という条件がありますが、ここが false になっていて adapter.connect! が実行されていないため、table_cache の初期化処理が動いていないようです。# https://github.com/Dynamoid/dynamoid/blob/v3.2.0/lib/dynamoid/adapter.rb#L29-L37def adapter  unless @adapter_.value    adapter = self.class.adapter_plugin_class.new    adapter.connect! if adapter.respond_to?(:connect!)    @adapter_.compare_and_set(nil, adapter)    clear_cache!  end  @adapter_.valueend2 つ目のエラーも見てみます。undefined method `query' for #\u003cDynamoid::AdapterPlugin::AwsSdkV3:0x00000000078dc1b8\u003e Did you mean? to_queryこちらは Dynamoid::AdapterPlugin::AwsSdkV3 のインスタンス adapter に対して query を実行しようとしてメソッドが定義されていないというエラーです。しかし、実際のコードにはメソッドが定義されています。https://github.com/Dynamoid/dynamoid/blob/v3.2.0/lib/dynamoid/adapter_plugin/aws_sdk_v3.rb#L489-L500 def query(table_name, options = {})  Enumerator.new do |yielder|    table = describe_table(table_name)    Query.new(client, table, options).call.each do |page|      yielder.yield(        page.items.map { |row| result_item_to_hash(row) },        last_evaluated_key: page.last_evaluated_key      )    end  end end視点を変えて、adapter インスタンスを定義しているコードを見てみると、やはり Dynamoid::Adapter#adapter に行き着きます。# https://github.com/Dynamoid/dynamoid/blob/v3.2.0/lib/dynamoid/adapter.rb#L29-L37def adapter  unless @adapter_.value    adapter = self.class.adapter_plugin_class.new    adapter.connect! if adapter.respond_to?(:connect!)    @adapter_.compare_and_set(nil, adapter)    clear_cache!  end  @adapter_.valueendself.class.adapter_plugin_class.new で生成したものをメモ化しています。メモ化には concurrent-ruby を使っていて、過去に対策されたようなのでそこは問題なさそうです。self.class.adapter_plugin_class.new の先が怪しそうなのでコードを見てみると、なにやら動的に require しています。# https://github.com/Dynamoid/dynamoid/blob/v3.2.0/lib/dynamoid/adapter.rb#L181-L187def self.adapter_plugin_class  unless Dynamoid.const_defined?(:AdapterPlugin) \u0026\u0026 Dynamoid::AdapterPlugin.const_defined?(Dynamoid::Config.adapter.camelcase)    require \"dynamoid/adapter_plugin/#{Dynamoid::Config.adapter}\"  end  Dynamoid::AdapterPlugin.const_get(Dynamoid::Config.adapter.camelcase)end実はスレッドセーフではない実装はこの require する条件の Dynamoid.const_defined?(:AdapterPlugin) \u0026\u0026 Dynamoid::AdapterPlugin.const_defined?(Dynamoid::Config.adapter.camelcase) の部分です。エラーを再現できるコードを Gist に用意しましたのでそちらを使って確認していきます。Test codes to reproduce not thread-safe errors of Dynamoid · GitHubDynamoid に以下のような変更を加えて、unless の中に入らず require が実行されなかった時の状態を見てみます。diff --git a/lib/dynamoid/adapter.rb b/lib/dynamoid/adapter.rbindex f390ecf..df2a58c 100644--- a/lib/dynamoid/adapter.rb+++ b/lib/dynamoid/adapter.rb@@ -181,6 +181,13 @@ module Dynamoid     def self.adapter_plugin_class       unless Dynamoid.const_defined?(:AdapterPlugin) \u0026\u0026 Dynamoid::AdapterPlugin.const_defined?(Dynamoid::Config.adapter.camelcase)         require \"dynamoid/adapter_plugin/#{Dynamoid::Config.adapter}\"+      else+        tmp_adapter = Dynamoid::AdapterPlugin.const_get(Dynamoid::Config.adapter.camelcase).new+        puts \u003c\u003c~EOS+          respond_to?(:connect!): #{tmp_adapter.respond_to?(:connect!)},+          respond_to?(:query): #{tmp_adapter.respond_to?(:query)},+          require: #{require \"dynamoid/adapter_plugin/#{Dynamoid::Config.adapter}\"}+        EOS       end        Dynamoid::AdapterPlugin.const_get(Dynamoid::Config.adapter.camelcase)すると、スレッドによっては const_defined? の結果が true で、require の結果も false (コードがロード済み) なのに、実際のメソッドが存在しないという現象が起きていることが分かりました。$ bundle exec ruby main.rb...respond_to?(:connect!): false,respond_to?(:query): false,require: false...ここからは Ruby の require の実装を知らないため推測になります。おそらくマルチスレッド環境下で require を実行すると、require を実行したスレッド内では全てのコードがロードされた状態になりますが、別のスレッドではクラス定義などの「ガワ」だけがロードされた状態になっているのではないかと思いました。そのため、ロードが不十分なスレッドでインスタンスを生成できるが、メソッドが定義されていない、という状態になっているのかと思われます。解決方法よって、全てのスレッドで確実に require を実行することで今回のエラーが解決するという結論に至りました。diff --git a/lib/dynamoid/adapter.rb b/lib/dynamoid/adapter.rbindex f390ecf..8449e34 100644--- a/lib/dynamoid/adapter.rb+++ b/lib/dynamoid/adapter.rb@@ -179,9 +179,7 @@ module Dynamoid     end      def self.adapter_plugin_class-      unless Dynamoid.const_defined?(:AdapterPlugin) \u0026\u0026 Dynamoid::AdapterPlugin.const_defined?(Dynamoid::Config.adapter.camelcase)-        require \"dynamoid/adapter_plugin/#{Dynamoid::Config.adapter}\"-      end+      require \"dynamoid/adapter_plugin/#{Dynamoid::Config.adapter}\"        Dynamoid::AdapterPlugin.const_get(Dynamoid::Config.adapter.camelcase)     endエラーの原因と解決方法が判明したため、既に Dynamoid に PR を作りマージまでしてもらいました。github.com2019/08/13 時点ではまだリリースされていないようなので、エラーで困っている方は master ブランチをお使いください。調査に苦労した点マルチスレッドプログラミングの経験が浅いため、まずスレッドセーフではない実装があるということに気づくまでに時間がかかりました。そして、エラーを再現しようとした時になかなか再現出来なかったのもハマりポイントでした。エラーの再現コードを読むと分かりますが、Dynamoid のメソッドを呼ぶ直前に puts を実行しています。# https://gist.github.com/tsub/72e60233ed82a8a453428ea7441e6017#file-main-rb100.times do |i|  safe_thread(i.to_s) do    puts 'debug' # To unlock Ruby's GVL    Document.where(identifier: 'hoge').first  endendこの puts が重要で、Ruby は GVL (Giant VM Lock) という仕組みを使って、実行されるネイティブスレッドが 1 つになるように排他制御をしています。ただし、IO 関連のメソッドを実行する際は GVL が一時的に解放されてスレッドが同時に実行されます。ネイティブスレッドを用いて実装されていますが、 現在の実装では Ruby VM は Giant VM lock (GVL) を有しており、同時に実行される ネイティブスレッドは常にひとつです。 ただし、IO 関連のブロックする可能性があるシステムコールを行う場合には GVL を解放します。その場合にはスレッドは同時に実行され得ます。 また拡張ライブラリから GVL を操作できるので、複数のスレッドを 同時に実行するような拡張ライブラリは作成可能です。docs.ruby-lang.orgつまりスレッドセーフではない実装があった場合に、それを再現させるためには単純にスレッドセーフではないコードを書くだけではダメで、IO 関連のメソッドを実行して GVL を解放しないといけません。少し古い記事ではありますが、こちらが参考になりました。moyomot.hatenablog.com実際の本番環境ではログ出力などにより、IO 関連のメソッドは普通に実行されていることが多いかと思いますので、エラーが起きるのも納得です。","link":"https://developer.feedforce.jp/entry/2019/08/13/183130","isoDate":"2019-08-13T09:31:30.000Z","dateMiliSeconds":1565688690000,"imageUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20190809/20190809182531.png","authorName":"tsub"},{"title":"CircleCI Orbs 入門","content":"\u003cp\u003eとうとう待望の CircleCI Orbs がリリースされたので一通り触ってみました。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://circleci.com/blog/announcing-orbs-technology-partner-program/\"\u003eAnnouncing CircleCI Orbs and our new Technology Partner Program\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e今回作ったサンプルは以下のリポジトリにありますので手っ取り早く知りたい人は以下のコードを見ると良いかと思います。\u003c/p\u003e\n\n\u003cp\u003e\u003ci class=\"fa fa-github\"\u003e\u003c/i\u003e \u003ca href=\"https://github.com/tsub/circleci-orbs-sandbox\"\u003etsub/circleci-orbs-sandbox\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"とうとう待望の CircleCI Orbs がリリースされたので一通り触ってみました。Announcing CircleCI Orbs and our new Technology Partner Program今回作ったサンプルは以下のリポジトリにありますので手っ取り早く知りたい人は以下のコードを見ると良いかと思います。 tsub/circleci-orbs-sandbox","link":"https://blog.tsub.me/post/introducing-to-circleci-orbs/","isoDate":"2018-11-10T08:47:00.000Z","dateMiliSeconds":1541839620000,"authorName":"tsub"},{"title":"Albert で GitHub リポジトリを開ける拡張を作った","content":"\u003cp\u003e先日プライベートの開発マシンを Linux にしたのですが、macOS の時に一番重宝していたものがなにかというと、実は \u003ca href=\"https://www.alfredapp.com/\"\u003eAlfred\u003c/a\u003e だったことに気づきました。\u003c/p\u003e\n\n\u003cp\u003eAlfred がないとストレスフルです。\u003c/p\u003e\n\n\u003cp\u003eただ Linux には Alternative Alfred がいくつかあり、その中でも Albert が比較的良さそうだったので Albert を使っていますが、Alfred で言う Workflow にあたるものが全然充実していませんでした。\u003c/p\u003e\n\n\u003cp\u003e特に Alfred から GitHub を開く操作が一番多い気がするので、まずはそれを Albert でもできるようにするために、今回拡張を作りました。\u003c/p\u003e\n\n\u003cp\u003e\u003ci class=\"fa fa-github\"\u003e\u003c/i\u003e \u003ca href=\"https://github.com/tsub/albert-github\"\u003etsub/albert-github: Open GitHub repository in browser with Albert\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://gyazo.com/fff7125ea22e33c863f6fd535d7f2b8b.png\" alt=\"image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"先日プライベートの開発マシンを Linux にしたのですが、macOS の時に一番重宝していたものがなにかというと、実は Alfred だったことに気づきました。Alfred がないとストレスフルです。ただ Linux には Alternative Alfred がいくつかあり、その中でも Albert が比較的良さそうだったので Albert を使っていますが、Alfred で言う Workflow にあたるものが全然充実していませんでした。特に Alfred から GitHub を開く操作が一番多い気がするので、まずはそれを Albert でもできるようにするために、今回拡張を作りました。 tsub/albert-github: Open GitHub repository in browser with Albert","link":"https://blog.tsub.me/post/create-albert-github/","isoDate":"2018-10-28T09:35:00.000Z","dateMiliSeconds":1540719300000,"authorName":"tsub"},{"title":"Go 1.11 の Modules (vgo) を CircleCI で使う","content":"\u003cp\u003e\u003ca href=\"https://github.com/tsub/s3-edit\"\u003e個人プロジェクト\u003c/a\u003eにて、先日リリースされた Go 1.11 の Modules (vgo) を使ってみました。\u003c/p\u003e\n\n\u003cp\u003e移行自体はスムーズにできたのですが、CircleCI でのキャッシュのやり方がそこそこ重要かも？と思ったので記事を書きました。\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"個人プロジェクトにて、先日リリースされた Go 1.11 の Modules (vgo) を使ってみました。移行自体はスムーズにできたのですが、CircleCI でのキャッシュのやり方がそこそこ重要かも？と思ったので記事を書きました。","link":"https://blog.tsub.me/post/go111-modules-in-circleci/","isoDate":"2018-08-30T05:33:00.000Z","dateMiliSeconds":1535607180000,"authorName":"tsub"},{"title":"Kubernetes.rb に講師役として参加してきました","content":"\u003cp\u003eこんにちは、エンジニアの \u003ca href=\"http://blog.hatena.ne.jp/tsub511/\" class=\"hatena-id-icon\"\u003e\u003cimg src=\"https://cdn.profile-image.st-hatena.com/users/tsub511/profile.png\" width=\"16\" height=\"16\" alt=\"\" class=\"hatena-id-icon\"\u003eid:tsub511\u003c/a\u003e です。\u003c/p\u003e\n\n\u003cp\u003e先日 Kubernetes.rb という勉強会があり、そちらの講師役として参加してきました。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Flocalhost.connpass.com%2Fevent%2F90340%2F\" title=\"Kubernetes.rb (2018/07/21 13:00〜)\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://localhost.connpass.com/event/90340/\"\u003elocalhost.connpass.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003e.rb\u003c/code\u003e と言いつつ Ruby の話は一切ありませんでした。タイトルの伏線は回収されず 😁\u003c/p\u003e\n\n\u003ch2\u003e参加の経緯\u003c/h2\u003e\n\n\u003cp\u003eさて、今回自分としては初の勉強会の主催側 (?) としてお手伝いすることとなったのですが、その経緯について軽くご紹介します。\u003c/p\u003e\n\n\u003cp\u003eもともと一からイベントを企画したわけではなく、主催の \u003ca href=\"https://twitter.com/yoshi_hirano\"\u003e@yoshi_hirano\u003c/a\u003e さんが講師役を募集していたところに応募した形になります。\u003c/p\u003e\n\n\u003cp\u003eただ、応募の経緯としては先日ご退職された元フィードフォースの \u003ca href=\"https://twitter.com/284km\"\u003e@284km\u003c/a\u003e さんから、「講師役やってくれる人を1名探しているんですが、tsub 氏どうですか？」というお誘いを貰い、やってみたいと思ったので繋いでいただいた感じです。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20180723/20180723125903.png\" alt=\"f:id:tsub511:20180723125903p:plain\" title=\"f:id:tsub511:20180723125903p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\n\u003cem\u003eちなみに社内で Kubernetes について勉強していくぞ！！的なチャンネルが最近できました。\u003c/em\u003e\u003c/p\u003e\n\n\u003ch2\u003e実際の準備\u003c/h2\u003e\n\n\u003cp\u003eやると決まってからは当日まで 1 ヶ月半ぐらいあったのですが、そこからは Twitter でグループ DM しながら準備を進めていきました。\u003c/p\u003e\n\n\u003cp\u003eとはいえ、お互い顔も分からず会ったことのない中で Twitter の DM オンリーで準備を進めていったので少々不安を感じながらも、\u003ca href=\"https://twitter.com/yoshi_hirano\"\u003e@yoshi_hirano\u003c/a\u003e さんやサポート役の \u003ca href=\"https://twitter.com/katsuhisa__\"\u003e@katsuhisa__\u003c/a\u003e さんから優しくして頂けたので問題なく進められました。\u003c/p\u003e\n\n\u003cp\u003e準備に際しては以下のリポジトリのコミット権を貰い、そこにサンプルを自分が足していきました。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fgithub.com%2Flocalhost9292%2Fkubernetes.rb\" title=\"localhost9292/kubernetes.rb\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://github.com/localhost9292/kubernetes.rb\"\u003egithub.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eまた、Rails のサンプルアプリについては以下のリポジトリも用意してもらいました。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fgithub.com%2Fyhirano55%2Freact-redux-jwt-authentication-example\" title=\"yhirano55/react-redux-jwt-authentication-example\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://github.com/yhirano55/react-redux-jwt-authentication-example\"\u003egithub.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eあとは当日までひたすら YAML を書く... 😇 という感じになります。\u003c/p\u003e\n\n\u003cp\u003e最初に作った Rails 用の YAML には結構時間がかかったものの、残りのアプリはほとんどコピペでサクサク進んでいきました。\u003c/p\u003e\n\n\u003cp\u003eただ、Sentry などは自分で動かしたことがなかったので、Kubernetes で動かすというよりはアプリそのもののセットアップ手順や構成などを理解するのに時間がかかったように思います。\u003c/p\u003e\n\n\u003cp\u003eまた、Discourse と GitLab については Docker イメージの使い方が独特で、\u003ca href=\"https://github.com/discourse/discourse_docker\"\u003eDiscourse\u003c/a\u003e の方は独自のシェルスクリプトを使っていて読み解くのがが大変そうで、\u003ca href=\"https://hub.docker.com/r/gitlab/gitlab-ce/\"\u003eGitLab\u003c/a\u003e の方はコンテナを動かしたら Chef が動き始めて色々インストールしだしたので諦めました。\u003c/p\u003e\n\n\u003cp\u003e代わりに Mastodon を動かすことになりました。動かし始めたらいけそうだったので、勢いで当日の朝も準備をしてました..\u003c/p\u003e\n\n\u003ch2\u003e勉強会当日の様子\u003c/h2\u003e\n\n\u003cp\u003e会場は\u003ca href=\"https://everyleaf.com/\"\u003e株式会社万葉\u003c/a\u003eさんのオフィスをお借りしました (自分がその辺りを手配したわけではないです)。\u003c/p\u003e\n\n\u003cp\u003eとても快適でした。万葉さんありがとうございました 🤗\u003c/p\u003e\n\n\u003cp\u003e特に、Chrome Cast に繋がったプロジェクターが設置してあり、各自何か言いたいことがある時にサクッと画面共有できて良かったかと思います。\u003c/p\u003e\n\n\u003cp\u003e全体としては 12:30 ぐらいからゆるっと始まり、17:30 ぐらいに解散しました。\u003c/p\u003e\n\n\u003cp\u003e最初に \u003ca href=\"https://twitter.com/yoshi_hirano\"\u003e@yoshi_hirano\u003c/a\u003e さんから流れの説明があり、各自簡単に自己紹介をした後はそれぞれ\u003ca href=\"https://github.com/localhost9292/kubernetes.rb\"\u003e資料\u003c/a\u003eを見ながらもくもくやっていました。\u003c/p\u003e\n\n\u003cp\u003eただ、最初に Minikube で躓く人が多かったようです。\u003c/p\u003e\n\n\u003cp\u003e以下の Issue を参考に、最終的に \u003ccode\u003e$ minikube start --vm-driver=hyperkit --bootstrapper=localkube\u003c/code\u003e で動いたようです。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fgithub.com%2Fkubernetes%2Fminikube%2Fissues%2F2765\" title=\"minikube start hangs forever on mac · Issue #2765 · kubernetes/minikube\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://github.com/kubernetes/minikube/issues/2765\"\u003egithub.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eちなみに自分は \u003ccode\u003e$ minikube start --vm-driver=hyperkit\u003c/code\u003e だけで動きました。\u003c/p\u003e\n\n\u003cp\u003eMinikube が動かないので GKE で進める方も多かったようです (サンプルは Minikube と GKE 両方の手順を用意していました)。\u003c/p\u003e\n\n\u003cp\u003e後は、イメージの Pull や DB のマイグレーションジョブの実行など、待ち時間が多かったためか、それなりにわいわい話しながら皆で進めてました。\u003c/p\u003e\n\n\u003cp\u003e自分は講師役という立ち位置でしたが、感覚的にはどちらかというと大学の講義で手伝いをしていた感じです。\u003c/p\u003e\n\n\u003cp\u003e質問があったら近くに行って答えるのを繰り返しつつ、何もない時は Mastodon の GKE 版のサンプル資料を作っていました。\u003c/p\u003e\n\n\u003cp\u003e最終的には Mastodon まで動かせた方も多く、サンプルを用意した自分としては非常に嬉しかったです ✨\u003c/p\u003e\n\n\u003cp\u003eまた、最後に KPT 方式の振り返りをやったのですが、Trello を使ったやり方が個人的にはすごく良かったです。\u003c/p\u003e\n\n\u003cp\u003e会社でもやってみたいなと思いました。\u003c/p\u003e\n\n\u003cp\u003e振り返りの様子。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20180723/20180723125937.png\" alt=\"f:id:tsub511:20180723125937p:plain\" title=\"f:id:tsub511:20180723125937p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003eなお、どうやら弊社で月一でやっているもくもく会がたまたま同日開催で場所も\u003ca href=\"https://basispoint.tokyo/coworking/jimbocho/\"\u003e神保町\u003c/a\u003eと、会場のすぐ側でやっていたようです。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"http://blog.hatena.ne.jp/masutaka26/\" class=\"hatena-id-icon\"\u003e\u003cimg src=\"https://cdn.profile-image.st-hatena.com/users/masutaka26/profile.png\" width=\"16\" height=\"16\" alt=\"\" class=\"hatena-id-icon\"\u003eid:masutaka26\u003c/a\u003e がひっそりとリモートで参加していました 😎\u003c/p\u003e\n\n\u003cblockquote class=\"twitter-tweet\" data-lang=\"ja\"\u003e\u003cp lang=\"ja\" dir=\"ltr\"\u003e02_nginx でこんなエラーが出た \u003ca href=\"https://twitter.com/hashtag/localhost9292?src=hash\u0026amp;ref_src=twsrc%5Etfw\"\u003e#localhost9292\u003c/a\u003e\u003cbr\u003e\u003cbr\u003e$ kubectl apply -f k8s/deployment.yaml\u003cbr\u003eError from server (BadRequest): error when creating \u0026quot;k8s/deployment.yaml\u0026quot;: Deployment in version \u0026quot;v1\u0026quot; cannot be handled as a Deployment: no kind \u0026quot;Deployment\u0026quot; is registered for version \u0026quot;apps/v1\u0026quot;\u003c/p\u003e\u0026mdash; Takashi Masuda (@masutaka) \u003ca href=\"https://twitter.com/masutaka/status/1020547692378783744?ref_src=twsrc%5Etfw\"\u003e2018年7月21日\u003c/a\u003e\u003c/blockquote\u003e\n\n\n\u003cscript async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"\u003e\u003c/script\u003e\n\n\n\n\n\u003cblockquote class=\"twitter-tweet\" data-conversation=\"none\" data-lang=\"ja\"\u003e\u003cp lang=\"ja\" dir=\"ltr\"\u003eminikube のアップデートで直った！\u003c/p\u003e\u0026mdash; Takashi Masuda (@masutaka) \u003ca href=\"https://twitter.com/masutaka/status/1020553958337605634?ref_src=twsrc%5Etfw\"\u003e2018年7月21日\u003c/a\u003e\u003c/blockquote\u003e\n\n\n\u003cscript async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"\u003e\u003c/script\u003e\n\n\n\u003ch2\u003e資料の補足\u003c/h2\u003e\n\n\u003cp\u003eKPT の P にも上がっていましたが、途中実行待ちが長いときに「これは上手くいっていて単純に時間のかかる処理なのか、そもそも上手く動いていないのか」というお声を頂きました。\u003c/p\u003e\n\n\u003cp\u003eそれについてはログを見る方法についても明示しておけば良かったと思っています。\u003c/p\u003e\n\n\u003cp\u003eKubernetes でログを見るには \u003ccode\u003e$ kubectl logs\u003c/code\u003e コマンドを使います。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e$ kubectl logs -f \u0026lt;Pod Name\u0026gt;\u003c/pre\u003e\n\n\n\u003cp\u003e(\u003ccode\u003etail\u003c/code\u003e と同じように \u003ccode\u003e-f\u003c/code\u003e でストリーミングができます)\u003c/p\u003e\n\n\u003cp\u003eJob の実行時などにはログを見ながら今何が動いているのかを見るとより分かりやすかったと思います。\u003c/p\u003e\n\n\u003cp\u003eまた、今回は Pod, Deployment, Service などの概念についての説明をせずにとりあえず手を動かしてみるという会でしたが、その辺りについては Kubernetes.rb #2 が開催されるようなので、興味のある方はぜひご参加ください！ (自分は次回は参加しないですが 🙇)\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Flocalhost.connpass.com%2Fevent%2F95578%2F\" title=\"Kubernetes.rb #2 (2018/09/01 11:00〜)\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://localhost.connpass.com/event/95578/\"\u003elocalhost.connpass.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003ch2\u003eやってみた感想など\u003c/h2\u003e\n\n\u003cp\u003e今回初めて勉強会の主催側として参加したわけですが、感想としてはやって良かった！！と思っています。\u003c/p\u003e\n\n\u003cp\u003eそもそも Kubernetes についてはまだ仕事で使っているわけでもなく導入の検討段階ですし、個人で趣味レベルで動かした程度だったので今回の資料作成の中でかなり理解が深まったと思っています。\u003c/p\u003e\n\n\u003cp\u003eまた、メンタル的にも成長できた気がします。\u003c/p\u003e\n\n\u003cp\u003e会ったことのない社外の人たちがいる場に飛び込むのは個人的にはなかなかハードルが高く、今まで勉強会に参加する際は懇親会にはあまり出ないタイプだったのですが、今回の体験で「あ、なんだ。こんな感じなのか」みたいな感覚を得られたので今後は懇親会などに参加して社外の人とも交流する勇気が少し出ました。\u003c/p\u003e\n\n\u003cp\u003eそれでは最後に改めて、\u003ca href=\"https://twitter.com/yoshi_hirano\"\u003e@yoshi_hirano\u003c/a\u003e さんや \u003ca href=\"https://twitter.com/katsuhisa__\"\u003e@katsuhisa__\u003c/a\u003e さん、会場を提供してくださった万葉さん、参加してくださった皆様、ありがとうございました  👋\u003c/p\u003e\n","contentSnippet":"こんにちは、エンジニアの id:tsub511 です。先日 Kubernetes.rb という勉強会があり、そちらの講師役として参加してきました。localhost.connpass.com.rb と言いつつ Ruby の話は一切ありませんでした。タイトルの伏線は回収されず 😁参加の経緯さて、今回自分としては初の勉強会の主催側 (?) としてお手伝いすることとなったのですが、その経緯について軽くご紹介します。もともと一からイベントを企画したわけではなく、主催の @yoshi_hirano さんが講師役を募集していたところに応募した形になります。ただ、応募の経緯としては先日ご退職された元フィードフォースの @284km さんから、「講師役やってくれる人を1名探しているんですが、tsub 氏どうですか？」というお誘いを貰い、やってみたいと思ったので繋いでいただいた感じです。ちなみに社内で Kubernetes について勉強していくぞ！！的なチャンネルが最近できました。実際の準備やると決まってからは当日まで 1 ヶ月半ぐらいあったのですが、そこからは Twitter でグループ DM しながら準備を進めていきました。とはいえ、お互い顔も分からず会ったことのない中で Twitter の DM オンリーで準備を進めていったので少々不安を感じながらも、@yoshi_hirano さんやサポート役の @katsuhisa__ さんから優しくして頂けたので問題なく進められました。準備に際しては以下のリポジトリのコミット権を貰い、そこにサンプルを自分が足していきました。github.comまた、Rails のサンプルアプリについては以下のリポジトリも用意してもらいました。github.comあとは当日までひたすら YAML を書く... 😇 という感じになります。最初に作った Rails 用の YAML には結構時間がかかったものの、残りのアプリはほとんどコピペでサクサク進んでいきました。ただ、Sentry などは自分で動かしたことがなかったので、Kubernetes で動かすというよりはアプリそのもののセットアップ手順や構成などを理解するのに時間がかかったように思います。また、Discourse と GitLab については Docker イメージの使い方が独特で、Discourse の方は独自のシェルスクリプトを使っていて読み解くのがが大変そうで、GitLab の方はコンテナを動かしたら Chef が動き始めて色々インストールしだしたので諦めました。代わりに Mastodon を動かすことになりました。動かし始めたらいけそうだったので、勢いで当日の朝も準備をしてました..勉強会当日の様子会場は株式会社万葉さんのオフィスをお借りしました (自分がその辺りを手配したわけではないです)。とても快適でした。万葉さんありがとうございました 🤗特に、Chrome Cast に繋がったプロジェクターが設置してあり、各自何か言いたいことがある時にサクッと画面共有できて良かったかと思います。全体としては 12:30 ぐらいからゆるっと始まり、17:30 ぐらいに解散しました。最初に @yoshi_hirano さんから流れの説明があり、各自簡単に自己紹介をした後はそれぞれ資料を見ながらもくもくやっていました。ただ、最初に Minikube で躓く人が多かったようです。以下の Issue を参考に、最終的に $ minikube start --vm-driver=hyperkit --bootstrapper=localkube で動いたようです。github.comちなみに自分は $ minikube start --vm-driver=hyperkit だけで動きました。Minikube が動かないので GKE で進める方も多かったようです (サンプルは Minikube と GKE 両方の手順を用意していました)。後は、イメージの Pull や DB のマイグレーションジョブの実行など、待ち時間が多かったためか、それなりにわいわい話しながら皆で進めてました。自分は講師役という立ち位置でしたが、感覚的にはどちらかというと大学の講義で手伝いをしていた感じです。質問があったら近くに行って答えるのを繰り返しつつ、何もない時は Mastodon の GKE 版のサンプル資料を作っていました。最終的には Mastodon まで動かせた方も多く、サンプルを用意した自分としては非常に嬉しかったです ✨また、最後に KPT 方式の振り返りをやったのですが、Trello を使ったやり方が個人的にはすごく良かったです。会社でもやってみたいなと思いました。振り返りの様子。なお、どうやら弊社で月一でやっているもくもく会がたまたま同日開催で場所も神保町と、会場のすぐ側でやっていたようです。id:masutaka26 がひっそりとリモートで参加していました 😎02_nginx でこんなエラーが出た #localhost9292$ kubectl apply -f k8s/deployment.yamlError from server (BadRequest): error when creating \"k8s/deployment.yaml\": Deployment in version \"v1\" cannot be handled as a Deployment: no kind \"Deployment\" is registered for version \"apps/v1\"— Takashi Masuda (@masutaka) 2018年7月21日minikube のアップデートで直った！— Takashi Masuda (@masutaka) 2018年7月21日資料の補足KPT の P にも上がっていましたが、途中実行待ちが長いときに「これは上手くいっていて単純に時間のかかる処理なのか、そもそも上手く動いていないのか」というお声を頂きました。それについてはログを見る方法についても明示しておけば良かったと思っています。Kubernetes でログを見るには $ kubectl logs コマンドを使います。$ kubectl logs -f \u003cPod Name\u003e(tail と同じように -f でストリーミングができます)Job の実行時などにはログを見ながら今何が動いているのかを見るとより分かりやすかったと思います。また、今回は Pod, Deployment, Service などの概念についての説明をせずにとりあえず手を動かしてみるという会でしたが、その辺りについては Kubernetes.rb #2 が開催されるようなので、興味のある方はぜひご参加ください！ (自分は次回は参加しないですが 🙇)localhost.connpass.comやってみた感想など今回初めて勉強会の主催側として参加したわけですが、感想としてはやって良かった！！と思っています。そもそも Kubernetes についてはまだ仕事で使っているわけでもなく導入の検討段階ですし、個人で趣味レベルで動かした程度だったので今回の資料作成の中でかなり理解が深まったと思っています。また、メンタル的にも成長できた気がします。会ったことのない社外の人たちがいる場に飛び込むのは個人的にはなかなかハードルが高く、今まで勉強会に参加する際は懇親会にはあまり出ないタイプだったのですが、今回の体験で「あ、なんだ。こんな感じなのか」みたいな感覚を得られたので今後は懇親会などに参加して社外の人とも交流する勇気が少し出ました。それでは最後に改めて、@yoshi_hirano さんや @katsuhisa__ さん、会場を提供してくださった万葉さん、参加してくださった皆様、ありがとうございました  👋","link":"https://developer.feedforce.jp/entry/2018/07/23/140133","isoDate":"2018-07-23T05:01:33.000Z","dateMiliSeconds":1532322093000,"imageUrl":"https://cdn.user.blog.st-hatena.com/default_entry_og_image/116461321/1514251518718655","authorName":"tsub"},{"title":"Datadog で dd-agent に root 権限を与えずにプロセスがオープンしているファイルディスクリプタ数のメトリクスを取得する","content":"\u003cp\u003eこんにちは、エンジニアの \u003ca href=\"http://blog.hatena.ne.jp/tsub511/\" class=\"hatena-id-icon\"\u003e\u003cimg src=\"https://cdn.profile-image.st-hatena.com/users/tsub511/profile.png\" width=\"16\" height=\"16\" alt=\"\" class=\"hatena-id-icon\"\u003eid:tsub511\u003c/a\u003e です。\nここ数日気温の寒暖差が凄いですね。昨日あまりにも寒すぎて一度しまった冬用の布団を引っ張りだしたら、また気温が上がってきたので片付けることになりそうです。\u003c/p\u003e\n\n\u003cp\u003e最近、Datadog でプロセスがオープンしているファイルディスクリプタ数のメトリクスを取る必要があり、色々と考えた結果良い方法を思いついたため、今回ご紹介します。\u003c/p\u003e\n\n\u003ch2\u003eDatadog 標準の \u003ccode\u003esystem.processes.open_file_descriptors\u003c/code\u003e メトリクスを取るには root 権限が必要\u003c/h2\u003e\n\n\u003cp\u003eDatadog では標準で、Process Check という機能を使うことで \u003ccode\u003esystem.processes.open_file_descriptors\u003c/code\u003e メトリクスを取ることができます。\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20180511/20180511150551.png\" alt=\"f:id:tsub511:20180511150551p:plain\" title=\"f:id:tsub511:20180511150551p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://docs.datadoghq.com/integrations/process/#metrics\"\u003ehttps://docs.datadoghq.com/integrations/process/#metrics\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eただし、説明文にも書いてある通り \u003ccode\u003edd-agent\u003c/code\u003e ユーザーが実行したプロセスしかこのメトリクスを取得することが出来ません。\u003c/p\u003e\n\n\u003cp\u003eそのため、例えば Rails アプリケーションを動かすために \u003ccode\u003epuma\u003c/code\u003e プロセスを \u003ccode\u003edev\u003c/code\u003e ユーザーで動かしていた場合、以下のような設定を書いても \u003ccode\u003esystem.processes.open_file_descriptors\u003c/code\u003e メトリクスを取得することが出来ません。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003einit_config:\n\ninstances:\n  - name: puma_worker\n    search_string: [\u0026#34;puma: cluster worker\u0026#34;]\n    exact_match: False\u003c/pre\u003e\n\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20180511/20180511151024.png\" alt=\"f:id:tsub511:20180511151024p:plain\" title=\"f:id:tsub511:20180511151024p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003eこれは何故かというと、プロセスがオープンしているファイルディスクリプタ数を取得するためには \u003ccode\u003e/proc/\u0026lt;PID\u0026gt;/fd\u003c/code\u003e 以下にアクセスする必要があるためです。\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003e/proc/\u0026lt;PID\u0026gt;/fd\u003c/code\u003e ディレクトリはそのプロセスを実行したユーザーにしか read 権限がありません。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e$ ls -al /proc/1/fd\nls: cannot open directory /proc/1/fd: Permission denied\n\n$ sudo ls -al /proc/1 | grep fd\ndr-x------.   2 root root 0 Apr 18 06:58 fd\ndr-x------.   2 root root 0 May 11 06:12 fdinfo\u003c/pre\u003e\n\n\n\u003cp\u003eそのため、\u003ccode\u003edd-agent\u003c/code\u003e はそのメトリクスを取得できないというわけです。\u003c/p\u003e\n\n\u003cp\u003eただし、\u003ccode\u003edd-agent\u003c/code\u003e に root 権限を与えることで、閲覧は可能になります。\n公式ドキュメントではそのやり方が提示されていますが、セキュリティ的にリスクがあるため、推奨はされていません。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fdocs.datadoghq.com%2Fagent%2Ffaq%2Fwhy-don-t-i-see-the-system-processes-open-file-descriptors-metric\" title=\"Why don\u0026#39;t I see the \u0026#39;system.processes.open_file_descriptors\u0026#39; metric?\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://docs.datadoghq.com/agent/faq/why-don-t-i-see-the-system-processes-open-file-descriptors-metric\"\u003edocs.datadoghq.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eさて、この記事の内容は \u003ccode\u003edd-agent\u003c/code\u003e に root 権限を与えずに \u003ccode\u003esystem.processes.open_file_descriptors\u003c/code\u003e メトリクスを取得するということでしたが、どうやれば良いのでしょう？\u003c/p\u003e\n\n\u003ch2\u003eDogStatsD を使う\u003c/h2\u003e\n\n\u003cp\u003eDatadog には DogStatsD という仕組みがあります。\u003c/p\u003e\n\n\u003cp\u003eDogStatsD は任意のカスタムメトリクスを Datadog に送る方法の一つです。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fdocs.datadoghq.com%2Fdevelopers%2Fdogstatsd%2F\" title=\"DogStatsD\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://docs.datadoghq.com/developers/dogstatsd/\"\u003edocs.datadoghq.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e通常は以下のような言語毎のライブラリを公式が提供してくれているため、こちらを使うことで任意のカスタムメトリクスを送ることができます。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fgithub.com%2FDataDog%2Fdatadog-go\" title=\"DataDog/datadog-go\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://github.com/DataDog/datadog-go\"\u003egithub.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eDogStatsD を通してメトリクスを送る際は、その送り側のプロセスは任意のユーザーで実行できます。\u003c/p\u003e\n\n\u003cp\u003eそのため、上記の例にあったように \u003ccode\u003edev\u003c/code\u003e ユーザーが \u003ccode\u003epuma\u003c/code\u003e プロセスを実行している場合は \u003ccode\u003edev\u003c/code\u003e ユーザーで DogStatsD にメトリクスを送るプロセスを実行すれば、\n同じ \u003ccode\u003edev\u003c/code\u003e ユーザーのため \u003ccode\u003e/proc/\u0026lt;PID\u0026gt;/fd\u003c/code\u003e への read 権限があります。\u003c/p\u003e\n\n\u003cp\u003e思いついてみれば簡単なことでしたね。\u003c/p\u003e\n\n\u003ch2\u003eでもプログラミング言語で実装するのは面倒じゃない？\u003c/h2\u003e\n\n\u003cp\u003e少し本題とは反れますが、もう少しお手軽に DogStatsD にカスタムメトリクスを送りたいな、とも思います。\u003c/p\u003e\n\n\u003cp\u003eそこで、調べてみたところ「DogStatsD には単純に専用のフォーマットで UDP パケットを送るだけで良い」ということを知りました。\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003eOn Linux:\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003e\nvagrant@vagrant-ubuntu-14-04:~$ echo -n \"custom_metric:60|g|#shell\" \u0026gt;/dev/udp/localhost/8125\n\u003c/code\u003e\u003c/p\u003e\n\n\u003cp\u003eor\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003e\nvagrant@vagrant-ubuntu-14-04:~$ echo -n \"custom_metric:60|g|#shell\" | nc -4u -w0 127.0.0.1 8125\n\u003c/code\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://docs.datadoghq.com/developers/dogstatsd/#sending-metrics\"\u003ehttps://docs.datadoghq.com/developers/dogstatsd/#sending-metrics\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003e上記のように、DogStatsD のエンドポイントである \u003ccode\u003elocalhost:8125\u003c/code\u003e に \u003ccode\u003ecustom_metric:60|g|#shell\u003c/code\u003e のようなフォーマットで UDP パケットを送ってやれば良いです。\u003c/p\u003e\n\n\u003cp\u003eそのため、プロセスがオープンしているファイルディスクリプタ数のカスタムメトリクスを送るには、以下のコマンドを実行すれば良いです。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e$ echo -n \u0026#34;open_file_descriptors.puma_worker:$(ls /proc/$(pgrep -f -u dev \u0026#39;puma: cluster worker\u0026#39; | head -1)/fd/ | wc -l):g\u0026#34; | nc -u -4 localhost 8125\u003c/pre\u003e\n\n\n\u003cp\u003e上記のコマンドを \u003ccode\u003ecrontab\u003c/code\u003e などで毎分実行してやれば \u003ccode\u003eopen_file_descriptors.puma_worker\u003c/code\u003e メトリクスを送ることができます。\u003c/p\u003e\n\n\u003cp\u003eただし、実際に本番で利用しているコマンドはそこまで単純ではなく、以下のようなシェルスクリプトを書いて実行しています。\u003c/p\u003e\n\n\u003cpre class=\"code lang-sh\" data-lang=\"sh\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e#!/bin/sh\u003c/span\u003e\n\n\u003cspan class=\"synStatement\"\u003eif [\u003c/span\u003e \u003cspan class=\"synPreProc\"\u003e$#\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e-ne\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e2\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e]\u003c/span\u003e; \u003cspan class=\"synStatement\"\u003ethen\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003eecho\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003eRequire 2 arguments\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e 1\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026gt;\u003c/span\u003e\u0026amp;\u003cspan class=\"synConstant\"\u003e2\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003eexit\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003efi\u003c/span\u003e\n\n\u003cspan class=\"synIdentifier\"\u003ePROCESS_NAME\u003c/span\u003e=\u003cspan class=\"synPreProc\"\u003e$1\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003eUSER\u003c/span\u003e=\u003cspan class=\"synPreProc\"\u003e$2\u003c/span\u003e\n\n\u003cspan class=\"synComment\"\u003e# pgrep でシェルスクリプト自身のプロセスがマッチしてしまうため `grep -v` で除外する\u003c/span\u003e\n\u003cspan class=\"synComment\"\u003e# CentOS 6 では pgrep に -a オプションがないため注意\u003c/span\u003e\n\u003cspan class=\"synComment\"\u003e#\u003c/span\u003e\n\u003cspan class=\"synComment\"\u003e# 複数のプロセスが見つかっても無視する\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003ePROCESS\u003c/span\u003e=\u003cspan class=\"synPreProc\"\u003e$(\u003c/span\u003e\u003cspan class=\"synSpecial\"\u003epgrep -f -a -u \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e${USER}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synSpecial\"\u003e \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e${PROCESS_NAME}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synSpecial\"\u003e | \u003c/span\u003e\u003cspan class=\"synStatement\"\u003egrep\u003c/span\u003e\u003cspan class=\"synSpecial\"\u003e -v \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e$0\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synSpecial\"\u003e | head \u003c/span\u003e\u003cspan class=\"synConstant\"\u003e-1\u003c/span\u003e\u003cspan class=\"synSpecial\"\u003e | cut -f \u003c/span\u003e\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e\u003cspan class=\"synSpecial\"\u003e -d \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e'\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e'\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"synStatement\"\u003eif [\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e-z\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e${PROCESS}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e]\u003c/span\u003e; \u003cspan class=\"synStatement\"\u003ethen\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003eecho\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e${PROCESS_NAME}\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e does not exists\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e 1\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026gt;\u003c/span\u003e\u0026amp;\u003cspan class=\"synConstant\"\u003e2\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003eexit\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003efi\u003c/span\u003e\n\n\u003cspan class=\"synStatement\"\u003els\u003c/span\u003e /proc/\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e${PROCESS}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e/fd/ | wc \u003cspan class=\"synSpecial\"\u003e-l\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\n\n\u003cpre class=\"code lang-sh\" data-lang=\"sh\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e#!/bin/bash\u003c/span\u003e\n\n\u003cspan class=\"synStatement\"\u003eif [\u003c/span\u003e \u003cspan class=\"synPreProc\"\u003e$#\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e-ne\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e3\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e]\u003c/span\u003e; \u003cspan class=\"synStatement\"\u003ethen\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003eecho\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003eRequire 3 arguments\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e 1\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026gt;\u003c/span\u003e\u0026amp;\u003cspan class=\"synConstant\"\u003e2\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003eexit\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003efi\u003c/span\u003e\n\n\u003cspan class=\"synIdentifier\"\u003eMETRIC_NAME\u003c/span\u003e=\u003cspan class=\"synPreProc\"\u003e$1\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003eVARUE\u003c/span\u003e=\u003cspan class=\"synPreProc\"\u003e$2\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003eMETRIC_TYPE\u003c/span\u003e=\u003cspan class=\"synPreProc\"\u003e$3\u003c/span\u003e\n\n\u003cspan class=\"synStatement\"\u003eecho\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e -n \u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e${METRIC_NAME}\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e:\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e${VARUE}\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e|\u003c/span\u003e\u003cspan class=\"synPreProc\"\u003e${METRIC_TYPE}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e\u0026quot;\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e \u003c/span\u003e| nc \u003cspan class=\"synSpecial\"\u003e-u\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e-4\u003c/span\u003e localhost \u003cspan class=\"synConstant\"\u003e8125\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e$ crontab -l\n* * * * * /path/to/send-to-dogstatsd.sh open_file_descriptors.puma_cluster_worker $(/path/to/get-open-fd.sh \u0026#34;puma: cluster worker\u0026#34; dev) g \u0026gt; /dev/null\u003c/pre\u003e\n\n","contentSnippet":"こんにちは、エンジニアの id:tsub511 です。ここ数日気温の寒暖差が凄いですね。昨日あまりにも寒すぎて一度しまった冬用の布団を引っ張りだしたら、また気温が上がってきたので片付けることになりそうです。最近、Datadog でプロセスがオープンしているファイルディスクリプタ数のメトリクスを取る必要があり、色々と考えた結果良い方法を思いついたため、今回ご紹介します。Datadog 標準の system.processes.open_file_descriptors メトリクスを取るには root 権限が必要Datadog では標準で、Process Check という機能を使うことで system.processes.open_file_descriptors メトリクスを取ることができます。https://docs.datadoghq.com/integrations/process/#metricsただし、説明文にも書いてある通り dd-agent ユーザーが実行したプロセスしかこのメトリクスを取得することが出来ません。そのため、例えば Rails アプリケーションを動かすために puma プロセスを dev ユーザーで動かしていた場合、以下のような設定を書いても system.processes.open_file_descriptors メトリクスを取得することが出来ません。init_config:instances:  - name: puma_worker    search_string: [\"puma: cluster worker\"]    exact_match: Falseこれは何故かというと、プロセスがオープンしているファイルディスクリプタ数を取得するためには /proc/\u003cPID\u003e/fd 以下にアクセスする必要があるためです。/proc/\u003cPID\u003e/fd ディレクトリはそのプロセスを実行したユーザーにしか read 権限がありません。$ ls -al /proc/1/fdls: cannot open directory /proc/1/fd: Permission denied$ sudo ls -al /proc/1 | grep fddr-x------.   2 root root 0 Apr 18 06:58 fddr-x------.   2 root root 0 May 11 06:12 fdinfoそのため、dd-agent はそのメトリクスを取得できないというわけです。ただし、dd-agent に root 権限を与えることで、閲覧は可能になります。公式ドキュメントではそのやり方が提示されていますが、セキュリティ的にリスクがあるため、推奨はされていません。docs.datadoghq.comさて、この記事の内容は dd-agent に root 権限を与えずに system.processes.open_file_descriptors メトリクスを取得するということでしたが、どうやれば良いのでしょう？DogStatsD を使うDatadog には DogStatsD という仕組みがあります。DogStatsD は任意のカスタムメトリクスを Datadog に送る方法の一つです。docs.datadoghq.com通常は以下のような言語毎のライブラリを公式が提供してくれているため、こちらを使うことで任意のカスタムメトリクスを送ることができます。github.comDogStatsD を通してメトリクスを送る際は、その送り側のプロセスは任意のユーザーで実行できます。そのため、上記の例にあったように dev ユーザーが puma プロセスを実行している場合は dev ユーザーで DogStatsD にメトリクスを送るプロセスを実行すれば、同じ dev ユーザーのため /proc/\u003cPID\u003e/fd への read 権限があります。思いついてみれば簡単なことでしたね。でもプログラミング言語で実装するのは面倒じゃない？少し本題とは反れますが、もう少しお手軽に DogStatsD にカスタムメトリクスを送りたいな、とも思います。そこで、調べてみたところ「DogStatsD には単純に専用のフォーマットで UDP パケットを送るだけで良い」ということを知りました。On Linux:vagrant@vagrant-ubuntu-14-04:~$ echo -n \"custom_metric:60|g|#shell\" \u003e/dev/udp/localhost/8125orvagrant@vagrant-ubuntu-14-04:~$ echo -n \"custom_metric:60|g|#shell\" | nc -4u -w0 127.0.0.1 8125https://docs.datadoghq.com/developers/dogstatsd/#sending-metrics上記のように、DogStatsD のエンドポイントである localhost:8125 に custom_metric:60|g|#shell のようなフォーマットで UDP パケットを送ってやれば良いです。そのため、プロセスがオープンしているファイルディスクリプタ数のカスタムメトリクスを送るには、以下のコマンドを実行すれば良いです。$ echo -n \"open_file_descriptors.puma_worker:$(ls /proc/$(pgrep -f -u dev 'puma: cluster worker' | head -1)/fd/ | wc -l):g\" | nc -u -4 localhost 8125上記のコマンドを crontab などで毎分実行してやれば open_file_descriptors.puma_worker メトリクスを送ることができます。ただし、実際に本番で利用しているコマンドはそこまで単純ではなく、以下のようなシェルスクリプトを書いて実行しています。#!/bin/shif [ $# -ne 2 ]; then  echo \"Require 2 arguments\" 1\u003e\u00262  exit 1fiPROCESS_NAME=$1USER=$2# pgrep でシェルスクリプト自身のプロセスがマッチしてしまうため `grep -v` で除外する# CentOS 6 では pgrep に -a オプションがないため注意## 複数のプロセスが見つかっても無視するPROCESS=$(pgrep -f -a -u \"${USER}\" \"${PROCESS_NAME}\" | grep -v \"$0\" | head -1 | cut -f 1 -d ' ')if [ -z \"${PROCESS}\" ]; then  echo \"${PROCESS_NAME} does not exists\" 1\u003e\u00262  exit 1fils /proc/\"${PROCESS}\"/fd/ | wc -l#!/bin/bashif [ $# -ne 3 ]; then  echo \"Require 3 arguments\" 1\u003e\u00262  exit 1fiMETRIC_NAME=$1VARUE=$2METRIC_TYPE=$3echo -n \"${METRIC_NAME}:${VARUE}|${METRIC_TYPE}\" | nc -u -4 localhost 8125$ crontab -l* * * * * /path/to/send-to-dogstatsd.sh open_file_descriptors.puma_cluster_worker $(/path/to/get-open-fd.sh \"puma: cluster worker\" dev) g \u003e /dev/null","link":"https://developer.feedforce.jp/entry/2018/05/11/190000","isoDate":"2018-05-11T10:00:00.000Z","dateMiliSeconds":1526032800000,"imageUrl":"https://cdn.user.blog.st-hatena.com/default_entry_og_image/116461321/1514251518718655","authorName":"tsub"},{"title":"JAWS DAYS 2018 に行ってきた","content":"\u003cp\u003e社内勉強会の準備などで忙しく、レポートを書くのが遅れてしまいましたが、先週の 03/10 (土) に \u003ca href=\"https://jawsdays2018.jaws-ug.jp/\"\u003eJAWS DAYS 2018\u003c/a\u003e へ行ってきました。\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://gyazo.com/5dafdbb66c5c6fd5a78aafeb83bd49c8.png\" alt=\"image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003e今回が初参加でしたが、AWS ユーザーグループのお祭りという感じですごく盛り上がっていて楽しいイベントでした。\u003c/p\u003e\n\n\u003cp\u003e会社の同僚も 4 人ぐらい参加してました。\u003c/p\u003e\n\n\u003cp\u003e自分が参加したセッションと聞いた感想やメモをつらつら書いていきます。\u003c/p\u003e\n\n\u003cp\u003e(ただし Keynote は省きます)\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"社内勉強会の準備などで忙しく、レポートを書くのが遅れてしまいましたが、先週の 03/10 (土) に JAWS DAYS 2018 へ行ってきました。今回が初参加でしたが、AWS ユーザーグループのお祭りという感じですごく盛り上がっていて楽しいイベントでした。会社の同僚も 4 人ぐらい参加してました。自分が参加したセッションと聞いた感想やメモをつらつら書いていきます。(ただし Keynote は省きます)","link":"https://blog.tsub.me/post/jaws-days-2018/","isoDate":"2018-03-17T06:16:55.000Z","dateMiliSeconds":1521267415000,"authorName":"tsub"},{"title":"m3.medium のインスタンスの CPU 負荷が高かったため t2.medium へ移行した","content":"\u003cp\u003eこんにちは、エンジニアの \u003ca href=\"http://blog.hatena.ne.jp/tsub511/\" class=\"hatena-id-icon\"\u003e\u003cimg src=\"https://cdn.profile-image.st-hatena.com/users/tsub511/profile.png\" width=\"16\" height=\"16\" alt=\"\" class=\"hatena-id-icon\"\u003eid:tsub511\u003c/a\u003e です。\n最近頭痛がするのでヨガを始めましたが、効果が出ているのかよく分かりません。\u003c/p\u003e\n\n\u003cp\u003e今回は m3.medium のインスタンスの CPU 負荷が高かったため t2.medium へ移行したら解決した話をします。\u003c/p\u003e\n\n\u003ch2\u003em3.medium のインスタンスの CPU 負荷が高かった\u003c/h2\u003e\n\n\u003cp\u003e年始あたりから、週に数回ほど決まった時間に Mackerel でアラートが出ていました。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20180302/20180302143106.png\" alt=\"f:id:tsub511:20180302143106p:plain\" title=\"f:id:tsub511:20180302143106p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003eCPU の Steal 値が異常に高く、全体としての使用率が 90 % を超えていました。\u003c/p\u003e\n\n\u003cp\u003eずっと原因が分からず、最初は Meltdown と Spectre のパッチを適用した関係で性能が低下したんじゃないか、などを疑っていました。\u003c/p\u003e\n\n\u003cp\u003eしかし、ある時全く別の作業をしていたときに別のロールのインスタンスで同様に CPU 負荷が上がり、どちらも \u003ccode\u003em3.medium\u003c/code\u003e というインスタンスタイプが共通していたことからなんとなくググってみたところ、以下の記事に辿り着きました。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=http%3A%2F%2Ftoritori0318.hatenadiary.jp%2Fentry%2F20140312%2F1394634304\" title=\"microインスタンスはlimitかけると大きくパフォーマンスが向上する（※再追記あり） - アルパカDiary Pro\" class=\"embed-card embed-blogcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 190px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"http://toritori0318.hatenadiary.jp/entry/20140312/1394634304\"\u003etoritori0318.hatenadiary.jp\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eどうやら、\u003ccode\u003em3.medium\u003c/code\u003e というインスタンスタイプのみ CPU の Steal が発生しやすいようです。\u003c/p\u003e\n\n\u003cp\u003e他にも同様の報告をしている記事をいくつか見つけました。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://forums.aws.amazon.com/thread.jspa?threadID=146585\"\u003ehttps://forums.aws.amazon.com/thread.jspa?threadID=146585\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://techblog.bonobos.com/ec2/sysadmin/devops/2014/10/02/the-m3.medium-is-terrible.html\"\u003eHigh CPU steal on EC2 m3.medium \u0026ndash; Bonobos Tech Blog\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003e情報が 2014 年と古いですが、現に同様の事象が発生しているため、当時と変わっていない可能性が高いです。\u003c/p\u003e\n\n\u003cp\u003eそのため、インスタンスタイプを変更することを検討しました。\u003c/p\u003e\n\n\u003ch2\u003e他のインスタンスタイプを検討\u003c/h2\u003e\n\n\u003cp\u003e\u003ccode\u003em3.medium\u003c/code\u003e から別のインスタンスタイプに変更するに辺り、どのインスタンスタイプを選択するか、まずはコスト面で比較しました。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20180302/20180302145249.png\" alt=\"f:id:tsub511:20180302145249p:plain\" title=\"f:id:tsub511:20180302145249p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fcalculator.s3.amazonaws.com%2Findex.html\" title=\"Amazon Web Services Simple Monthly Calculator\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://calculator.s3.amazonaws.com/index.html\"\u003ecalculator.s3.amazonaws.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e順当に行けば \u003ccode\u003em4\u003c/code\u003e ファミリーが妥当なところですが、\u003ccode\u003em4\u003c/code\u003e ファミリーは medium サイズは提供していないため、費用がそれなりに増えてしまいます。\u003c/p\u003e\n\n\u003cp\u003eこの中で、\u003ccode\u003em3.medium\u003c/code\u003e よりも安い \u003ccode\u003et2.medium\u003c/code\u003e に目を付けました。\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003et2.medium\u003c/code\u003e は \u003ccode\u003em3.medium\u003c/code\u003e に比べると、 vCPU が 1 コア増え、メモリも 0.25 GB 増える上に料金が安くなるというかなりお得なインスタンスタイプです。\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003ccode\u003em3.medium\u003c/code\u003e\u003c/strong\u003e\u003c/p\u003e\n\n\u003cblockquote\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eインスタンスファミリー \u003c/th\u003e\n\u003cth\u003e インスタンスタイプ \u003c/th\u003e\n\u003cth\u003e プロセッサアーキテクチャ \u003c/th\u003e\n\u003cth\u003e vCPU \u003c/th\u003e\n\u003cth\u003e メモリ (GiB) \u003c/th\u003e\n\u003cth\u003e インスタンスストレージ（GB） \u003c/th\u003e\n\u003cth\u003e EBS 最適化利用 \u003c/th\u003e\n\u003cth\u003e ネットワークパフォーマンス\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e汎用 \u003c/td\u003e\n\u003ctd\u003e m3.medium \u003c/td\u003e\n\u003ctd\u003e 64 ビット \u003c/td\u003e\n\u003ctd\u003e 1 \u003c/td\u003e\n\u003ctd\u003e 3.75 \u003c/td\u003e\n\u003ctd\u003e 1 x 4 \u003c/td\u003e\n\u003ctd\u003e - \u003c/td\u003e\n\u003ctd\u003e 中\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\n\n\u003cp\u003e\u003ca href=\"https://aws.amazon.com/jp/ec2/previous-generation/\"\u003ehttps://aws.amazon.com/jp/ec2/previous-generation/\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003ccode\u003et2.medium\u003c/code\u003e\u003c/strong\u003e\u003c/p\u003e\n\n\u003cblockquote\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eモデル \u003c/th\u003e\n\u003cth\u003e vCPU \u003c/th\u003e\n\u003cth\u003e CPU クレジット/時 \u003c/th\u003e\n\u003cth\u003e メモリ (GiB) \u003c/th\u003e\n\u003cth\u003e ストレージ\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003et2.medium \u003c/td\u003e\n\u003ctd\u003e 2 \u003c/td\u003e\n\u003ctd\u003e 24 \u003c/td\u003e\n\u003ctd\u003e 4 \u003c/td\u003e\n\u003ctd\u003e EBS のみ\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\n\n\u003cp\u003e\u003ca href=\"https://aws.amazon.com/jp/ec2/instance-types/\"\u003ehttps://aws.amazon.com/jp/ec2/instance-types/\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eただ、ここで安易に \u003ccode\u003et2.medium\u003c/code\u003e を選択してはいけません。\n\u003ccode\u003et2\u003c/code\u003e ファミリーは「バースト可能パフォーマンスインスタンス」という特別な性質があります。\u003c/p\u003e\n\n\u003ch2\u003eT2 インスタンスについて\u003c/h2\u003e\n\n\u003cp\u003eT2 インスタンスについて、今までふわっとした理解しかなかったため、この機会に AWS のドキュメントをちゃんと読んでみました。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fdocs.aws.amazon.com%2Fja_jp%2FAWSEC2%2Flatest%2FUserGuide%2Ft2-instances.html\" title=\"T2 インスタンス - Amazon Elastic Compute Cloud\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/t2-instances.html\"\u003edocs.aws.amazon.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e結論から言うと、弊社のサービスの性質上、決まった時間に Sidekiq のジョブがまとまって大量に実行されるため、普段は CPU 使用率は低く、ある時間だけ CPU 使用率が高くなるというまさに T2 インスタンスがピッタリなケースでした。\u003c/p\u003e\n\n\u003ch4\u003eCPU クレジット\u003c/h4\u003e\n\n\u003cp\u003eT2 インスタンスには \u003ca href=\"https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/t2-credits-baseline-concepts.html\"\u003eCPU クレジット\u003c/a\u003eという概念があります。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fdocs.aws.amazon.com%2Fja_jp%2FAWSEC2%2Flatest%2FUserGuide%2Ft2-credits-baseline-concepts.html\" title=\"CPU クレジットおよびベースラインパフォーマンス - Amazon Elastic Compute Cloud\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/t2-credits-baseline-concepts.html\"\u003edocs.aws.amazon.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e1 CPU クレジットは 100 % の CPU 使用率を 1 分間稼働させることができます。\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003et2.medium\u003c/code\u003e は CPU クレジットが 1 時間あたり 24 なので、100 % の CPU 使用率を 24 分間、あるいは 50 % の CPU 使用率を 48 分間、40 % の CPU 使用率なら 60 分間稼稼働させることができることになります。(ただし、\u003ccode\u003et2.medium\u003c/code\u003e は vCPU が 2 コアなので、実際には 20 % の CPU 使用率で 60 分間の稼働)\u003c/p\u003e\n\n\u003cp\u003e実際の CPU 使用率は平均で 20 % 以下に収まっていることが多い (たまにスパイクはする) ので、CPU クレジットが 24 ならまず問題ないです。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20180302/20180302150357.png\" alt=\"f:id:tsub511:20180302150357p:plain\" title=\"f:id:tsub511:20180302150357p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003eこの 40 % (20 %) という値を\u003ca href=\"https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/t2-credits-baseline-concepts.html#baseline_performance\"\u003eベースラインパフォーマンス\u003c/a\u003eと呼び、これを超えて CPU を使用することを「バースト」と呼びます。\u003c/p\u003e\n\n\u003cp\u003eまた、ベースラインパフォーマンスよりも CPU 使用率が下回っていた場合、クレジットバランスというものに余分な CPU クレジットが保存されます。\nクレジットバランスに保存された CPU クレジットは、CPU 負荷がベースラインパフォーマンスを上回った時に消費されます。\u003c/p\u003e\n\n\u003cp\u003eつまり、余分な CPU クレジットは蓄積されて後で使うことができるということになります (ただし \u003ccode\u003et2.medium\u003c/code\u003e の最大クレジットバランスは 576)。\u003c/p\u003e\n\n\u003cp\u003e注意点としてはインスタンスを停止するとクレジットバランスに貯まった CPU クレジットは破棄されるというところでしょうか。\u003c/p\u003e\n\n\u003ch4\u003eT2 Unlimited\u003c/h4\u003e\n\n\u003cp\u003eただ、T2 インスタンスを使う以上、気にしなければいけないのは CPU クレジットがなくなった場合は CPU のバーストができなくなるということです。\u003c/p\u003e\n\n\u003cp\u003eCPU のバーストができないということはつまり、ベースラインパフォーマンス (\u003ccode\u003et2.medium\u003c/code\u003e の場合は 20 %) 以上の CPU が使えなくなるということになります。\u003c/p\u003e\n\n\u003cp\u003eただし、去年の Re:Invent にて発表された \u003ca href=\"https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/t2-unlimited.html\"\u003eT2 Unlimited\u003c/a\u003e という機能を有効にすることで CPU クレジットがなくなった場合でも自動的に CPU クレジットを追加され、CPU 使用に制限がかからなくなります。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fdocs.aws.amazon.com%2Fja_jp%2FAWSEC2%2Flatest%2FUserGuide%2Ft2-unlimited.html\" title=\"T2 無制限 - Amazon Elastic Compute Cloud\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/t2-unlimited.html\"\u003edocs.aws.amazon.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e具体的には、T2 Unlimited を有効にすると、CPU クレジット及びクレジットバランスがなくなった場合、余剰クレジットというものから消費されるようになります。\u003c/p\u003e\n\n\u003cp\u003e最初の余剰クレジットは 24 時間で獲得できるクレジットの合計値となります。\u003c/p\u003e\n\n\u003cp\u003e例えば \u003ccode\u003et2.medium\u003c/code\u003e の場合、1 時間辺りの獲得クレジットは 24 なので 24 時間で 576 のクレジットが余剰クレジットになります。\u003c/p\u003e\n\n\u003cp\u003eこの 24 時間分の余剰クレジットは前借りのようなもので、消費した分だけ次のクレジット獲得時に余剰クレジットの支払いに使用されます。\u003c/p\u003e\n\n\u003cp\u003e24 時間分の余剰クレジットまで全て使い切ってしまった場合でも、その後に消費した余剰クレジット分は追加で課金され、CPU のバーストは継続することが可能です。\u003c/p\u003e\n\n\u003cp\u003eつまり、T2 Unlimited を有効にすれば T2 インスタンス特有の CPU クレジットの枯渇による CPU 使用制限の問題が解決されることになります。\u003c/p\u003e\n\n\u003cp\u003eただし、常にバーストし続けて追加でお金が発生し続けるような場合は、T2 インスタンスでなく普通にインスタンスタイプを利用したほうが懸命ですね。\u003c/p\u003e\n\n\u003ch4\u003eCPU クレジットの監視\u003c/h4\u003e\n\n\u003cp\u003eT2 Standard (非 T2 Unlimited) であっても、T2 Unlimited であっても、普段からどの程度 CPU がバーストしているかは監視しておいたほうが良いです。\u003c/p\u003e\n\n\u003cp\u003eそのために、CloudWatch で \u003ccode\u003eCPUCreditUsage\u003c/code\u003e, \u003ccode\u003eCPUCreditBalance\u003c/code\u003e, \u003ccode\u003eCPUSurplusCreditBalance\u003c/code\u003e, \u003ccode\u003eCPUSurplusCreditsCharged\u003c/code\u003e という 4 つのメトリクスが提供されています。\u003c/p\u003e\n\n\u003cp\u003e個人的には T2 Unlimited の場合、基本的には \u003ccode\u003eCPUSurplusCreditBalance\u003c/code\u003e と \u003ccode\u003eCPUSurplusCreditsCharged\u003c/code\u003e を監視しておけば良いと思います。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eCPUSurplusCreditBalance\u003c/code\u003e は消費された 24 時間分の余剰クレジット数\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eCPUSurplusCreditsCharged\u003c/code\u003e は 24 時間分の余剰クレジットを使い切った後で更に消費される余剰クレジット数\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003e実際の監視には Datadog を利用しました (現在監視ツールを Datadog へ移行途中なため)。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20180302/20180302153003.png\" alt=\"f:id:tsub511:20180302153003p:plain\" title=\"f:id:tsub511:20180302153003p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003e閾値はまだ感覚を掴めていないため、とりあえず厳しめにしてあります。\u003c/p\u003e\n\n\u003ch2\u003e\u003ccode\u003em3.medium\u003c/code\u003e から \u003ccode\u003et2.medium\u003c/code\u003e へインスタンスタイプを変更する\u003c/h2\u003e\n\n\u003cp\u003e弊社のサービスのインフラでは、Blue Green Deployment が可能な体制が整っているため、インスタンスタイプの変更は非常に簡単です。\u003c/p\u003e\n\n\u003cp\u003e新しい環境のインスタンスは \u003ccode\u003et2.medium\u003c/code\u003e で作成し、ELB からコネクションが流れるようになったら、古い環境のインスタンスを削除するだけです。\u003c/p\u003e\n\n\u003cp\u003eただ、EC2 の Launch Configuration + Auto Scaling Group を使っていたため、少し工夫が必要でした。\u003c/p\u003e\n\n\u003cp\u003eT2 Unlimited の有効化は Launch Configuration ではサポートされていませんでした。\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003eAuto Scaling グループで T2 インスタンスを無制限に設定して起動するには起動テンプレートを使用する必要があります。起動設定では、T2 インスタンスを無制限として起動することがサポートされていません。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/t2-unlimited.html#t2-auto-scaling-grp\"\u003ehttps://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/t2-unlimited.html#t2-auto-scaling-grp\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eLaunch Template ならサポートされているものの、今から移行するのも大変ですし、何より Terraform がまだ Launch Template をサポートしていませんでした (2018/03/02 時点)。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fgithub.com%2Fterraform-providers%2Fterraform-provider-aws%2Fissues%2F2505\" title=\"Add support for EC2 Launch Templates · Issue #2505 · terraform-providers/terraform-provider-aws\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://github.com/terraform-providers/terraform-provider-aws/issues/2505\"\u003egithub.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eどうしようと困っていたところ、以下の記事に助けられました。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fdev.classmethod.jp%2Fcloud%2Faws%2Fautoscale-t2-unlimited%2F\" title=\"T2 Unlimited(T2無制限)オプションをオートスケール環境で利用してみた | Developers.IO\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://dev.classmethod.jp/cloud/aws/autoscale-t2-unlimited/\"\u003edev.classmethod.jp\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eEC2 User Data を使って、インスタンス起動時に自身に対して T2 Unlimited を有効化する、という方法です。\u003c/p\u003e\n\n\u003cp\u003e自分では全く思いつきませんでしたが、User Data も Terraform を使って管理できるのでかなりシンプルに実現できました。\u003c/p\u003e\n\n\u003cp\u003e実際には以下の User Data を利用しました (CentOS を使っているため \u003ccode\u003e$ yum install aws-cli\u003c/code\u003e ができない)。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e#!/bin/bash\n\nset -x\n\n# Install aws-cli\n\ncurl -L https://bootstrap.pypa.io/get-pip.py | python\npip install awscli --upgrade\n\n# Enable T2 Unlimited\n\nINSTANCE_ID=$(curl http://169.254.169.254/latest/meta-data/instance-id)\nREGION=$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone | sed -e \u0026#39;s/.$//\u0026#39;)\n\naws --region \u0026#34;${REGION}\u0026#34; ec2 describe-instance-credit-specifications --instance-id \u0026#34;${INSTANCE_ID}\u0026#34;\naws --region \u0026#34;${REGION}\u0026#34; ec2 modify-instance-credit-specification --instance-credit-specification InstanceId=\u0026#34;${INSTANCE_ID}\u0026#34;,CpuCredits=unlimited\naws --region \u0026#34;${REGION}\u0026#34; ec2 describe-instance-credit-specifications --instance-id \u0026#34;${INSTANCE_ID}\u0026#34;\u003c/pre\u003e\n\n\n\u003cp\u003eこれで、Auto Scaling Group によって起動したインスタンスに対して自動的に T2 Unlimited が有効になりました。\u003c/p\u003e\n\n\u003ch2\u003eインスタンスタイプを \u003ccode\u003et2.medium\u003c/code\u003e に変更した結果\u003c/h2\u003e\n\n\u003cp\u003e実際に \u003ccode\u003et2.medium\u003c/code\u003e のインスタンスを稼働させた結果、同程度の負荷がかかった際の CPU の Steal 値はほぼ 0 になりました。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20180302/20180302152028.png\" alt=\"f:id:tsub511:20180302152028p:plain\" title=\"f:id:tsub511:20180302152028p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003eちなみに \u003ccode\u003et2.medium\u003c/code\u003e は vCPU が 2 つあるため、グラフの最大値は 200 % になっています。\u003c/p\u003e\n\n\u003cp\u003euser 値が 90 % 程度なので、実質 CPU 使用率は 45 % 程度で、\u003ccode\u003em3.medium\u003c/code\u003e の頃とほとんど性能は変わっていません。\u003c/p\u003e\n\n\u003cp\u003eまた、その他にも 5 分間のロードアベレージも全体的に下がっていました。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20180302/20180302153619.png\" alt=\"f:id:tsub511:20180302153619p:plain\" title=\"f:id:tsub511:20180302153619p:plain\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003em3.medium\u003c/code\u003e のインスタンスを使っていて CPU 負荷に悩まされている場合はインスタンスタイプを変更すると解決するかも\u003c/li\u003e\n\u003cli\u003eT2 インスタンスは適材適所で使えば費用を安く抑えられて非常に良い\u003c/li\u003e\n\u003cli\u003eT2 Unlimited によって CPU クレジットがなくなる問題が解決されて安心して T2 インスタンスを使用できるようになった\u003c/li\u003e\n\u003cli\u003eT2 Unlimited を Launch Configuration で有効化したい場合は User Data を使うと良い\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003e\u003ccode\u003em3.medium\u003c/code\u003e が原因だったようで、解決して良かったです。日々のアラートに悩まされなくて良くなりました。\u003c/p\u003e\n","contentSnippet":"こんにちは、エンジニアの id:tsub511 です。最近頭痛がするのでヨガを始めましたが、効果が出ているのかよく分かりません。今回は m3.medium のインスタンスの CPU 負荷が高かったため t2.medium へ移行したら解決した話をします。m3.medium のインスタンスの CPU 負荷が高かった年始あたりから、週に数回ほど決まった時間に Mackerel でアラートが出ていました。CPU の Steal 値が異常に高く、全体としての使用率が 90 % を超えていました。ずっと原因が分からず、最初は Meltdown と Spectre のパッチを適用した関係で性能が低下したんじゃないか、などを疑っていました。しかし、ある時全く別の作業をしていたときに別のロールのインスタンスで同様に CPU 負荷が上がり、どちらも m3.medium というインスタンスタイプが共通していたことからなんとなくググってみたところ、以下の記事に辿り着きました。toritori0318.hatenadiary.jpどうやら、m3.medium というインスタンスタイプのみ CPU の Steal が発生しやすいようです。他にも同様の報告をしている記事をいくつか見つけました。https://forums.aws.amazon.com/thread.jspa?threadID=146585High CPU steal on EC2 m3.medium – Bonobos Tech Blog情報が 2014 年と古いですが、現に同様の事象が発生しているため、当時と変わっていない可能性が高いです。そのため、インスタンスタイプを変更することを検討しました。他のインスタンスタイプを検討m3.medium から別のインスタンスタイプに変更するに辺り、どのインスタンスタイプを選択するか、まずはコスト面で比較しました。calculator.s3.amazonaws.com順当に行けば m4 ファミリーが妥当なところですが、m4 ファミリーは medium サイズは提供していないため、費用がそれなりに増えてしまいます。この中で、m3.medium よりも安い t2.medium に目を付けました。t2.medium は m3.medium に比べると、 vCPU が 1 コア増え、メモリも 0.25 GB 増える上に料金が安くなるというかなりお得なインスタンスタイプです。m3.mediumインスタンスファミリー  インスタンスタイプ  プロセッサアーキテクチャ  vCPU  メモリ (GiB)  インスタンスストレージ（GB）  EBS 最適化利用  ネットワークパフォーマンス汎用  m3.medium  64 ビット  1  3.75  1 x 4  -  中https://aws.amazon.com/jp/ec2/previous-generation/t2.mediumモデル  vCPU  CPU クレジット/時  メモリ (GiB)  ストレージt2.medium  2  24  4  EBS のみhttps://aws.amazon.com/jp/ec2/instance-types/ただ、ここで安易に t2.medium を選択してはいけません。t2 ファミリーは「バースト可能パフォーマンスインスタンス」という特別な性質があります。T2 インスタンスについてT2 インスタンスについて、今までふわっとした理解しかなかったため、この機会に AWS のドキュメントをちゃんと読んでみました。docs.aws.amazon.com結論から言うと、弊社のサービスの性質上、決まった時間に Sidekiq のジョブがまとまって大量に実行されるため、普段は CPU 使用率は低く、ある時間だけ CPU 使用率が高くなるというまさに T2 インスタンスがピッタリなケースでした。CPU クレジットT2 インスタンスには CPU クレジットという概念があります。docs.aws.amazon.com1 CPU クレジットは 100 % の CPU 使用率を 1 分間稼働させることができます。t2.medium は CPU クレジットが 1 時間あたり 24 なので、100 % の CPU 使用率を 24 分間、あるいは 50 % の CPU 使用率を 48 分間、40 % の CPU 使用率なら 60 分間稼稼働させることができることになります。(ただし、t2.medium は vCPU が 2 コアなので、実際には 20 % の CPU 使用率で 60 分間の稼働)実際の CPU 使用率は平均で 20 % 以下に収まっていることが多い (たまにスパイクはする) ので、CPU クレジットが 24 ならまず問題ないです。この 40 % (20 %) という値をベースラインパフォーマンスと呼び、これを超えて CPU を使用することを「バースト」と呼びます。また、ベースラインパフォーマンスよりも CPU 使用率が下回っていた場合、クレジットバランスというものに余分な CPU クレジットが保存されます。クレジットバランスに保存された CPU クレジットは、CPU 負荷がベースラインパフォーマンスを上回った時に消費されます。つまり、余分な CPU クレジットは蓄積されて後で使うことができるということになります (ただし t2.medium の最大クレジットバランスは 576)。注意点としてはインスタンスを停止するとクレジットバランスに貯まった CPU クレジットは破棄されるというところでしょうか。T2 Unlimitedただ、T2 インスタンスを使う以上、気にしなければいけないのは CPU クレジットがなくなった場合は CPU のバーストができなくなるということです。CPU のバーストができないということはつまり、ベースラインパフォーマンス (t2.medium の場合は 20 %) 以上の CPU が使えなくなるということになります。ただし、去年の Re:Invent にて発表された T2 Unlimited という機能を有効にすることで CPU クレジットがなくなった場合でも自動的に CPU クレジットを追加され、CPU 使用に制限がかからなくなります。docs.aws.amazon.com具体的には、T2 Unlimited を有効にすると、CPU クレジット及びクレジットバランスがなくなった場合、余剰クレジットというものから消費されるようになります。最初の余剰クレジットは 24 時間で獲得できるクレジットの合計値となります。例えば t2.medium の場合、1 時間辺りの獲得クレジットは 24 なので 24 時間で 576 のクレジットが余剰クレジットになります。この 24 時間分の余剰クレジットは前借りのようなもので、消費した分だけ次のクレジット獲得時に余剰クレジットの支払いに使用されます。24 時間分の余剰クレジットまで全て使い切ってしまった場合でも、その後に消費した余剰クレジット分は追加で課金され、CPU のバーストは継続することが可能です。つまり、T2 Unlimited を有効にすれば T2 インスタンス特有の CPU クレジットの枯渇による CPU 使用制限の問題が解決されることになります。ただし、常にバーストし続けて追加でお金が発生し続けるような場合は、T2 インスタンスでなく普通にインスタンスタイプを利用したほうが懸命ですね。CPU クレジットの監視T2 Standard (非 T2 Unlimited) であっても、T2 Unlimited であっても、普段からどの程度 CPU がバーストしているかは監視しておいたほうが良いです。そのために、CloudWatch で CPUCreditUsage, CPUCreditBalance, CPUSurplusCreditBalance, CPUSurplusCreditsCharged という 4 つのメトリクスが提供されています。個人的には T2 Unlimited の場合、基本的には CPUSurplusCreditBalance と CPUSurplusCreditsCharged を監視しておけば良いと思います。CPUSurplusCreditBalance は消費された 24 時間分の余剰クレジット数CPUSurplusCreditsCharged は 24 時間分の余剰クレジットを使い切った後で更に消費される余剰クレジット数実際の監視には Datadog を利用しました (現在監視ツールを Datadog へ移行途中なため)。閾値はまだ感覚を掴めていないため、とりあえず厳しめにしてあります。m3.medium から t2.medium へインスタンスタイプを変更する弊社のサービスのインフラでは、Blue Green Deployment が可能な体制が整っているため、インスタンスタイプの変更は非常に簡単です。新しい環境のインスタンスは t2.medium で作成し、ELB からコネクションが流れるようになったら、古い環境のインスタンスを削除するだけです。ただ、EC2 の Launch Configuration + Auto Scaling Group を使っていたため、少し工夫が必要でした。T2 Unlimited の有効化は Launch Configuration ではサポートされていませんでした。Auto Scaling グループで T2 インスタンスを無制限に設定して起動するには起動テンプレートを使用する必要があります。起動設定では、T2 インスタンスを無制限として起動することがサポートされていません。https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/t2-unlimited.html#t2-auto-scaling-grpLaunch Template ならサポートされているものの、今から移行するのも大変ですし、何より Terraform がまだ Launch Template をサポートしていませんでした (2018/03/02 時点)。github.comどうしようと困っていたところ、以下の記事に助けられました。dev.classmethod.jpEC2 User Data を使って、インスタンス起動時に自身に対して T2 Unlimited を有効化する、という方法です。自分では全く思いつきませんでしたが、User Data も Terraform を使って管理できるのでかなりシンプルに実現できました。実際には以下の User Data を利用しました (CentOS を使っているため $ yum install aws-cli ができない)。#!/bin/bashset -x# Install aws-clicurl -L https://bootstrap.pypa.io/get-pip.py | pythonpip install awscli --upgrade# Enable T2 UnlimitedINSTANCE_ID=$(curl http://169.254.169.254/latest/meta-data/instance-id)REGION=$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone | sed -e 's/.$//')aws --region \"${REGION}\" ec2 describe-instance-credit-specifications --instance-id \"${INSTANCE_ID}\"aws --region \"${REGION}\" ec2 modify-instance-credit-specification --instance-credit-specification InstanceId=\"${INSTANCE_ID}\",CpuCredits=unlimitedaws --region \"${REGION}\" ec2 describe-instance-credit-specifications --instance-id \"${INSTANCE_ID}\"これで、Auto Scaling Group によって起動したインスタンスに対して自動的に T2 Unlimited が有効になりました。インスタンスタイプを t2.medium に変更した結果実際に t2.medium のインスタンスを稼働させた結果、同程度の負荷がかかった際の CPU の Steal 値はほぼ 0 になりました。ちなみに t2.medium は vCPU が 2 つあるため、グラフの最大値は 200 % になっています。user 値が 90 % 程度なので、実質 CPU 使用率は 45 % 程度で、m3.medium の頃とほとんど性能は変わっていません。また、その他にも 5 分間のロードアベレージも全体的に下がっていました。まとめm3.medium のインスタンスを使っていて CPU 負荷に悩まされている場合はインスタンスタイプを変更すると解決するかもT2 インスタンスは適材適所で使えば費用を安く抑えられて非常に良いT2 Unlimited によって CPU クレジットがなくなる問題が解決されて安心して T2 インスタンスを使用できるようになったT2 Unlimited を Launch Configuration で有効化したい場合は User Data を使うと良いm3.medium が原因だったようで、解決して良かったです。日々のアラートに悩まされなくて良くなりました。","link":"https://developer.feedforce.jp/entry/2018/03/02/155020","isoDate":"2018-03-02T06:50:20.000Z","dateMiliSeconds":1519973420000,"imageUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20180302/20180302143106.png","authorName":"tsub"},{"title":"AWS Lambda with Golang と SAM に入門した","content":"\u003cp\u003e先日 AWS Lambda の Golang サポートがリリースされました。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://aws.amazon.com/jp/blogs/compute/announcing-go-support-for-aws-lambda/\"\u003eAnnouncing Go Support for AWS Lambda | AWS Compute Blog\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e今回は AWS Lambda を Golang で書きつつ、\u003ca href=\"https://github.com/awslabs/serverless-application-model\"\u003eSAM\u003c/a\u003e へも入門したのでその辺りの知見とか作ったものについて紹介します。\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"先日 AWS Lambda の Golang サポートがリリースされました。Announcing Go Support for AWS Lambda | AWS Compute Blog今回は AWS Lambda を Golang で書きつつ、SAM へも入門したのでその辺りの知見とか作ったものについて紹介します。","link":"https://blog.tsub.me/post/introduce-aws-lambda-with-golang-and-sam/","isoDate":"2018-01-31T14:15:00.000Z","dateMiliSeconds":1517408100000,"authorName":"tsub"},{"title":"結婚して半年が経ったので工夫していることとか","content":"\u003cp\u003eこの記事は \u003ca href=\"https://adventar.org/calendars/2155\"\u003efeedforce Advent Calendar 2017\u003c/a\u003e の 9 日目の記事です。\u003c/p\u003e\n\n\u003cp\u003e昨日の記事は tmd45 さんの \u003ca href=\"http://developer.feedforce.jp/entry/2017/12/08/090000\"\u003eTypeScript 社内勉強会 完遂報告 - Feedforce Developer Blog\u003c/a\u003e でした。\u003cbr /\u003e\nTypeScript 社内勉強会には自分も参加していましたが、プロダクションのコードを書いているフロントエンドエンジニアの方から色々とアドバイスを頂いたり、他の言語の観点で議論が出来たりとても有意義な会でした！\u003c/p\u003e\n\n\u003cp\u003eさて、本題ですがワタクシ今年の 4 月に結婚をしました。\u003c/p\u003e\n\n\u003cp\u003e妻は Web コーダーで、割と Web サービスなどにも抵抗がなく普段から Slack や Kibela などを夫婦間で活用しています。\u003c/p\u003e\n\n\u003cp\u003e今回はその辺りで色々と工夫している部分を紹介できればと思います。\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"この記事は feedforce Advent Calendar 2017 の 9 日目の記事です。昨日の記事は tmd45 さんの TypeScript 社内勉強会 完遂報告 - Feedforce Developer Blog でした。さて、本題ですがワタクシ今年の 4 月に結婚をしました。妻は Web コーダーで、割と Web サービスなどにも抵抗がなく普段から Slack や Kibela などを夫婦間で活用しています。今回はその辺りで色々と工夫している部分を紹介できればと思います。","link":"https://blog.tsub.me/post/half-a-year-after-married/","isoDate":"2017-12-09T12:30:00.000Z","dateMiliSeconds":1512822600000,"authorName":"tsub"},{"title":"AWS でコンテナを動かすためのサービスまとめ","content":"\u003cp\u003eこんにちは、バックエンドエンジニアの tsub (\u003ca href=\"http://blog.hatena.ne.jp/tsub511/\"\u003eid:tsub511\u003c/a\u003e) です。\u003c/p\u003e\n\n\u003cp\u003e本日 AWS Re:Invent 2017 でコンテナ実行環境として新たに AWS Fargate と Amazon Elastic Container Service for Kubernetes (EKS) が発表されました。\u003c/p\u003e\n\n\u003cp\u003e昨日は発表が待ち遠しくて気が気じゃなかったですが、無事に予想通りマネージド Kubernetes サービスが発表されて大喜びです。\u003c/p\u003e\n\n\u003cp\u003e今回は AWS でコンテナを扱う上で、今までのサービスと合わせて選択肢がいくつかあって混乱すると思うので簡単にまとめました。\u003c/p\u003e\n\n\u003ch2\u003eAWS でコンテナを動かすためのサービス\u003c/h2\u003e\n\n\u003cp\u003e新しく 2 つのサービスが追加されたことで、これだけあります。\n(見落としがなければ)\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eAmazon Elastic Beanstalk (EB)\u003c/li\u003e\n\u003cli\u003eAmazon Elastic Container Service (ECS)\u003c/li\u003e\n\u003cli\u003eAWS Batch\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/eks/\"\u003eAmazon Elastic Container Service for Kubernetes (EKS)\u003c/a\u003e \u003cstrong\u003e\u003cfont color=\"red\"\u003enew!\u003c/font\u003e\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/fargate/\"\u003eAWS Fargate\u003c/a\u003e \u003cstrong\u003e\u003cfont color=\"red\"\u003enew!\u003c/font\u003e\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eそれぞれの特徴について説明していきます。\u003c/p\u003e\n\n\u003ch2\u003eAmazon Elastic Beanstalk (EB)\u003c/h2\u003e\n\n\u003cp\u003e※ EB については自分は全く触ったことがないので分からないままで書きます。\u003c/p\u003e\n\n\u003cp\u003eEB は Heroku のような PaaS です。\n本来は Heroku と同じようにアプリケーションのコードをそのままデプロイして動かしますが、Docker もサポートしていて、コンテナとしてデプロイして動かすことができます。\u003c/p\u003e\n\n\u003cp\u003e小規模なサービス、チームなどでインフラの管理をしたくないというユースケースで使うことが多いと思います。\u003c/p\u003e\n\n\u003ch2\u003eAmazon Elastic Container Service (ECS)\u003c/h2\u003e\n\n\u003cp\u003eECS は AWS が独自に開発しているマネージドなコンテナのオーケストレーションサービスです。\n(コンテナのオーケストレーションについては \u003ca href=\"#%E3%81%8A%E3%81%BE%E3%81%91:%20%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E3%81%AE%E3%82%AA%E3%83%BC%E3%82%B1%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6\"\u003eおまけ: コンテナのオーケストレーションについて\u003c/a\u003e を参照)\u003c/p\u003e\n\n\u003cp\u003eEC2 の上で ecs-agent を動かすことで、ECS のクラスタとして認識させることができるため、非常にシンプルです。\necs-agent が動いていれば、ECS を通して EC2 の上でコンテナを簡単に動かすことができます。\u003c/p\u003e\n\n\u003cp\u003eECS 向けに awslogs という Docker 用の logging driver を提供していて、CloudWatch Logs との連携も簡単に行えます。\u003c/p\u003e\n\n\u003cp\u003eECS 上でのコンテナは、ECS Task や ECS Service として動かします。\nECS Task には IAM Role を使った権限管理や VPC ネットワーク上で直接 Task を動かすことができ、セキュリティグループなどを利用することもできます。\u003c/p\u003e\n\n\u003cp\u003eECS Service は ELB との連携があり、コンテナが起動したら自動的に ELB に紐付けたり、コンテナが終了したら ELB から外したり、といったことをやってくれます。\u003c/p\u003e\n\n\u003cp\u003e上記のように、他の AWS サービスとの連携がスムーズにできる点は非常に魅力的です。\u003c/p\u003e\n\n\u003ch2\u003eAWS Batch\u003c/h2\u003e\n\n\u003cp\u003eBatch はコンテナを使ったバッチコンピューティングに特化したサービスです。\u003c/p\u003e\n\n\u003cp\u003eバッチコンピューティングと言っても、決まった時間に決まった処理をするという cron のようなものではなく、\n機械学習やスーパーコンピュータなどで利用するような大量の計算処理を必要とする場合に利用されるような基盤となります。\u003c/p\u003e\n\n\u003cp\u003eそういう背景もあり、主に CPU ベースでのコンテナの割り振り、ホストのオートスケーリングなどに強いです。\u003c/p\u003e\n\n\u003cp\u003eまた、Batch はバックエンドで ECS を使っており、ジョブを動かすと実際に ECS Cluster が作られその上で Task が動いている様子を見ることもできます。\nECS を使っていることもあり、ログは自動的に awslogs logging driver によって CloudWatch Logs に送られたり、CloudWatch による ECS のメトリクスを見ることが可能です。\u003c/p\u003e\n\n\u003cp\u003eまた、ECS と違って Job Queue も提供されていて、ジョブの状態管理なども可能となっています。\nCloudWatch Events によりジョブの状態変化によるイベントドリブンな処理も可能です。\u003c/p\u003e\n\n\u003ch2\u003e\u003ca href=\"https://aws.amazon.com/jp/eks/\"\u003eAmazon Elastic Container Service for Kubernetes (EKS)\u003c/a\u003e \u003cstrong\u003e\u003cfont color=\"red\"\u003enew!\u003c/font\u003e\u003c/strong\u003e\u003c/h2\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Faws.amazon.com%2Fjp%2Feks%2F\" title=\"Amazon EKS – マネージド型 Kubernetes サービス\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://aws.amazon.com/jp/eks/\"\u003eaws.amazon.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eEKS はマネージドな Kubernetes を提供してくれるサービスです。\n(現在はプレビュー版のみの提供)\u003c/p\u003e\n\n\u003cp\u003eECS は AWS が独自に開発しているコンテナのオーケストレーションサービスでしたが、Kubernetes は Google が開発している OSS プロジェクトのコンテナのオーケストレーションツールです。\n(コンテナのオーケストレーションについては \u003ca href=\"#%E3%81%8A%E3%81%BE%E3%81%91:%20%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E3%81%AE%E3%82%AA%E3%83%BC%E3%82%B1%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6\"\u003eおまけ: コンテナのオーケストレーションについて\u003c/a\u003e を参照)\u003c/p\u003e\n\n\u003cp\u003eKubernetes は OSS ということもあり、コミュニティが非常に活発で多くの開発者・企業が開発に協力しています。\u003c/p\u003e\n\n\u003cp\u003eKubernetes を動かすための基盤はかなりたくさんの選択肢があり、あくまで EKS はそのうちの一つです。\u003c/p\u003e\n\n\u003cp\u003e特に、今まで AWS 上で Kubernetes 環境を構築するために様々なツールがありました (私が知っている範囲で)。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/kubernetes-incubator/kubespray\"\u003ekubespray\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/kubernetes-incubator/kube-aws\"\u003ekube-aws\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/kubernetes/kops\"\u003ekops\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/docs/reference/generated/kubeadm/\"\u003ekubeadm\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://coreos.com/tectonic/\"\u003eTectonic\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://rancher.com/rancher-os/\"\u003eRancher\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003e実際、今まで AWS 上で Kubernetes を利用していた人が多いようで、おそらくその方々は何らかのツールを用いて自前で構築していたと思います。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://aws.amazon.com/jp/blogs/news/amazon-elastic-container-service-for-kubernetes/\"\u003ehttps://aws.amazon.com/jp/blogs/news/amazon-elastic-container-service-for-kubernetes/\u003c/a\u003e\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003eAWS 上で Kubernetes を利用している多くのお客様がいます。実際、Cloud Native Computing Foundationによると、Kubernetes のワークロードの63％が AWS 上で動作しています。AWS は Kubernetes を実行するうえで人気の場所\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eこれらのツールを使って、Kubernetes クラスタの構築・管理を簡単にすることができますが、やはりマスターノードを管理する必要はでてくると思います。\u003c/p\u003e\n\n\u003cp\u003eそこを AWS 側で管理・提供してくれるのが EKS となります。\u003c/p\u003e\n\n\u003cp\u003eEKS としては Kubernetes クラスタの管理だけでなく、ELB や IAM、VPC、Private Link、CloudTrail などとの連携も提供してくれているため、自前で Kubernetes クラスタを構築するよりも便利になっています。\n後述の Fargate との連携も今後できるようになるとのことです。\u003c/p\u003e\n\n\u003cp\u003eまた、既存の Kubernetes 用ツール群を使えるのも大きな強みです。\u003c/p\u003e\n\n\u003ch2\u003e\u003ca href=\"https://aws.amazon.com/jp/fargate/\"\u003eAWS Fargate\u003c/a\u003e \u003cstrong\u003e\u003cfont color=\"red\"\u003enew!\u003c/font\u003e\u003c/strong\u003e\u003c/h2\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Faws.amazon.com%2Fjp%2Ffargate%2F\" title=\"AWS Fargate – サーバーやクラスターの管理が不要なコンテナの実行\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://aws.amazon.com/jp/fargate/\"\u003eaws.amazon.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eFargate は単体のサービスではなく ECS や EKS の上で使うことのできるサービスです。\n(現在は北部バージニアリージョンのみの提供)\u003c/p\u003e\n\n\u003cp\u003e前述した ECS や EKS と違い、コンテナを動かすホストについて意識せず、コンテナそのものを動かすことだけに集中することができます。\u003c/p\u003e\n\n\u003cp\u003eどういうことかと言うと、Fargate では事前にホストを動かしておく必要はありません。\u003c/p\u003e\n\n\u003cp\u003eAWS VPC 環境と ECS のクラスター (名前空間的な意味で) を作っておけば、後はコンテナを起動するだけで自動的にホストを用意し、コンテナを実行してくれます。\u003c/p\u003e\n\n\u003cp\u003eまた、ECS の上に乗っかっているので、使い方は簡単で ECS Task として起動する時に launch type として Fargate を指定するだけです。\nその他、ECS Service でも使うことができます。\n(EKS との連携についてはまだ情報が公開されていないため不明です)\u003c/p\u003e\n\n\u003cp\u003eホストをこちら側で管理しないため、ホストの監視の方法などは気になるところですが、CloudWatch を通してホストのメトリクスは取れるようです。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://aws.amazon.com/jp/blogs/news/aws-fargate-a-product-overview\"\u003ehttps://aws.amazon.com/jp/blogs/news/aws-fargate-a-product-overview\u003c/a\u003e\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003eFargateではアプリケーションのログをCloudWatch Logsに送ることができます。サービスのメトリクス(CPUとメモリの利用率)もCloudWatchメトリクスとして利用可能です。可視化や監視、アプリケーションパフォーマンスの領域での我々のパートナーである、DataDog、Aquasec、Splunk、Twistlock、そしてNew RelicもFargateタスクをサポートしています。\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eまた、Fargate に似たサービスとして \u003ca href=\"https://azure.microsoft.com/ja-jp/services/container-instances/\"\u003eAzure Container Instances (ACI)\u003c/a\u003e や \u003ca href=\"https://hyper.sh/\"\u003eHyper.sh\u003c/a\u003e といったサービスも AWS 以外で提供されています。\u003c/p\u003e\n\n\u003ch2\u003eおまけ: コンテナのオーケストレーションについて\u003c/h2\u003e\n\n\u003cp\u003eコンテナを本番環境で動かそうとした時、コンテナをどのインスタンスで動かすか、どのインスタンスでコンテナが動いているのか、などコンテナの管理方法でいくつか問題が出てきます (あくまで一例です)。\u003c/p\u003e\n\n\u003cp\u003eそういった問題を解決するため、コンテナのスケジューリングやマネージングをするツールを用意する必要がありますが、それらを解決するためのツールが ECS や Kubernetes, Docker Swarm などと言ったオーケストレーションツールとなります。\u003c/p\u003e\n\n\u003cp\u003eただし、どこにコンテナのスケジューリングやマネージングをする人が必要になってきます。\nその人をマスターノードなどと呼び、次はこれを管理・冗長化などしなければいけないという問題がでてきます。\u003c/p\u003e\n\n\u003cp\u003eそのマスターノードの管理までマネージドで提供してくれているのが、ECS や EKS, \u003ca href=\"https://cloud.google.com/kubernetes-engine/?hl=ja\"\u003eGKE (Google Kubernetes Engine)\u003c/a\u003e, \u003ca href=\"https://azure.microsoft.com/ja-jp/services/container-service/\"\u003eAKS (Azure Container Service)\u003c/a\u003e などになります。\u003c/p\u003e\n\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eEB\n\n\u003cul\u003e\n\u003cli\u003e小規模なサービス・チームで使うと良さそう\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eECS\n\n\u003cul\u003e\n\u003cli\u003eAWS 独自のコンテナのオーケストレーションサービス\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eBatch\n\n\u003cul\u003e\n\u003cli\u003eバッチコンピューティング基盤として使う\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eEKS\n\n\u003cul\u003e\n\u003cli\u003eKubernetes を使ったコンテナのオーケストレーションサービス\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eFargate\n\n\u003cul\u003e\n\u003cli\u003e検証環境・本番環境・ちょっとした処理など幅広く使える\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003e機能的に ECS と EKS の使い分けは難しいですが、学習コスト・導入コストの面で ECS に軍配は上がると思います。\nただ、コンテナを使う以上コミュニティが巨大な Kubernetes を使うことも大きなメリットです。\u003c/p\u003e\n\n\u003cp\u003e個人的には EKS を推していきたいです。\u003c/p\u003e\n","contentSnippet":"こんにちは、バックエンドエンジニアの tsub (id:tsub511) です。本日 AWS Re:Invent 2017 でコンテナ実行環境として新たに AWS Fargate と Amazon Elastic Container Service for Kubernetes (EKS) が発表されました。昨日は発表が待ち遠しくて気が気じゃなかったですが、無事に予想通りマネージド Kubernetes サービスが発表されて大喜びです。今回は AWS でコンテナを扱う上で、今までのサービスと合わせて選択肢がいくつかあって混乱すると思うので簡単にまとめました。AWS でコンテナを動かすためのサービス新しく 2 つのサービスが追加されたことで、これだけあります。(見落としがなければ)Amazon Elastic Beanstalk (EB)Amazon Elastic Container Service (ECS)AWS BatchAmazon Elastic Container Service for Kubernetes (EKS) new!AWS Fargate new!それぞれの特徴について説明していきます。Amazon Elastic Beanstalk (EB)※ EB については自分は全く触ったことがないので分からないままで書きます。EB は Heroku のような PaaS です。本来は Heroku と同じようにアプリケーションのコードをそのままデプロイして動かしますが、Docker もサポートしていて、コンテナとしてデプロイして動かすことができます。小規模なサービス、チームなどでインフラの管理をしたくないというユースケースで使うことが多いと思います。Amazon Elastic Container Service (ECS)ECS は AWS が独自に開発しているマネージドなコンテナのオーケストレーションサービスです。(コンテナのオーケストレーションについては おまけ: コンテナのオーケストレーションについて を参照)EC2 の上で ecs-agent を動かすことで、ECS のクラスタとして認識させることができるため、非常にシンプルです。ecs-agent が動いていれば、ECS を通して EC2 の上でコンテナを簡単に動かすことができます。ECS 向けに awslogs という Docker 用の logging driver を提供していて、CloudWatch Logs との連携も簡単に行えます。ECS 上でのコンテナは、ECS Task や ECS Service として動かします。ECS Task には IAM Role を使った権限管理や VPC ネットワーク上で直接 Task を動かすことができ、セキュリティグループなどを利用することもできます。ECS Service は ELB との連携があり、コンテナが起動したら自動的に ELB に紐付けたり、コンテナが終了したら ELB から外したり、といったことをやってくれます。上記のように、他の AWS サービスとの連携がスムーズにできる点は非常に魅力的です。AWS BatchBatch はコンテナを使ったバッチコンピューティングに特化したサービスです。バッチコンピューティングと言っても、決まった時間に決まった処理をするという cron のようなものではなく、機械学習やスーパーコンピュータなどで利用するような大量の計算処理を必要とする場合に利用されるような基盤となります。そういう背景もあり、主に CPU ベースでのコンテナの割り振り、ホストのオートスケーリングなどに強いです。また、Batch はバックエンドで ECS を使っており、ジョブを動かすと実際に ECS Cluster が作られその上で Task が動いている様子を見ることもできます。ECS を使っていることもあり、ログは自動的に awslogs logging driver によって CloudWatch Logs に送られたり、CloudWatch による ECS のメトリクスを見ることが可能です。また、ECS と違って Job Queue も提供されていて、ジョブの状態管理なども可能となっています。CloudWatch Events によりジョブの状態変化によるイベントドリブンな処理も可能です。Amazon Elastic Container Service for Kubernetes (EKS) new!aws.amazon.comEKS はマネージドな Kubernetes を提供してくれるサービスです。(現在はプレビュー版のみの提供)ECS は AWS が独自に開発しているコンテナのオーケストレーションサービスでしたが、Kubernetes は Google が開発している OSS プロジェクトのコンテナのオーケストレーションツールです。(コンテナのオーケストレーションについては おまけ: コンテナのオーケストレーションについて を参照)Kubernetes は OSS ということもあり、コミュニティが非常に活発で多くの開発者・企業が開発に協力しています。Kubernetes を動かすための基盤はかなりたくさんの選択肢があり、あくまで EKS はそのうちの一つです。特に、今まで AWS 上で Kubernetes 環境を構築するために様々なツールがありました (私が知っている範囲で)。kubespraykube-awskopskubeadmTectonicRancher実際、今まで AWS 上で Kubernetes を利用していた人が多いようで、おそらくその方々は何らかのツールを用いて自前で構築していたと思います。https://aws.amazon.com/jp/blogs/news/amazon-elastic-container-service-for-kubernetes/AWS 上で Kubernetes を利用している多くのお客様がいます。実際、Cloud Native Computing Foundationによると、Kubernetes のワークロードの63％が AWS 上で動作しています。AWS は Kubernetes を実行するうえで人気の場所これらのツールを使って、Kubernetes クラスタの構築・管理を簡単にすることができますが、やはりマスターノードを管理する必要はでてくると思います。そこを AWS 側で管理・提供してくれるのが EKS となります。EKS としては Kubernetes クラスタの管理だけでなく、ELB や IAM、VPC、Private Link、CloudTrail などとの連携も提供してくれているため、自前で Kubernetes クラスタを構築するよりも便利になっています。後述の Fargate との連携も今後できるようになるとのことです。また、既存の Kubernetes 用ツール群を使えるのも大きな強みです。AWS Fargate new!aws.amazon.comFargate は単体のサービスではなく ECS や EKS の上で使うことのできるサービスです。(現在は北部バージニアリージョンのみの提供)前述した ECS や EKS と違い、コンテナを動かすホストについて意識せず、コンテナそのものを動かすことだけに集中することができます。どういうことかと言うと、Fargate では事前にホストを動かしておく必要はありません。AWS VPC 環境と ECS のクラスター (名前空間的な意味で) を作っておけば、後はコンテナを起動するだけで自動的にホストを用意し、コンテナを実行してくれます。また、ECS の上に乗っかっているので、使い方は簡単で ECS Task として起動する時に launch type として Fargate を指定するだけです。その他、ECS Service でも使うことができます。(EKS との連携についてはまだ情報が公開されていないため不明です)ホストをこちら側で管理しないため、ホストの監視の方法などは気になるところですが、CloudWatch を通してホストのメトリクスは取れるようです。https://aws.amazon.com/jp/blogs/news/aws-fargate-a-product-overviewFargateではアプリケーションのログをCloudWatch Logsに送ることができます。サービスのメトリクス(CPUとメモリの利用率)もCloudWatchメトリクスとして利用可能です。可視化や監視、アプリケーションパフォーマンスの領域での我々のパートナーである、DataDog、Aquasec、Splunk、Twistlock、そしてNew RelicもFargateタスクをサポートしています。また、Fargate に似たサービスとして Azure Container Instances (ACI) や Hyper.sh といったサービスも AWS 以外で提供されています。おまけ: コンテナのオーケストレーションについてコンテナを本番環境で動かそうとした時、コンテナをどのインスタンスで動かすか、どのインスタンスでコンテナが動いているのか、などコンテナの管理方法でいくつか問題が出てきます (あくまで一例です)。そういった問題を解決するため、コンテナのスケジューリングやマネージングをするツールを用意する必要がありますが、それらを解決するためのツールが ECS や Kubernetes, Docker Swarm などと言ったオーケストレーションツールとなります。ただし、どこにコンテナのスケジューリングやマネージングをする人が必要になってきます。その人をマスターノードなどと呼び、次はこれを管理・冗長化などしなければいけないという問題がでてきます。そのマスターノードの管理までマネージドで提供してくれているのが、ECS や EKS, GKE (Google Kubernetes Engine), AKS (Azure Container Service) などになります。まとめEB小規模なサービス・チームで使うと良さそうECSAWS 独自のコンテナのオーケストレーションサービスBatchバッチコンピューティング基盤として使うEKSKubernetes を使ったコンテナのオーケストレーションサービスFargate検証環境・本番環境・ちょっとした処理など幅広く使える機能的に ECS と EKS の使い分けは難しいですが、学習コスト・導入コストの面で ECS に軍配は上がると思います。ただ、コンテナを使う以上コミュニティが巨大な Kubernetes を使うことも大きなメリットです。個人的には EKS を推していきたいです。","link":"https://developer.feedforce.jp/entry/2017/11/30/133525","isoDate":"2017-11-30T04:35:25.000Z","dateMiliSeconds":1512016525000,"imageUrl":"https://cdn.user.blog.st-hatena.com/default_entry_og_image/116461321/1514251518718655","authorName":"tsub"},{"title":"Go で Datadog の Alfred Workflow を作った","content":"\u003cp\u003e最近会社の同僚が \u003ca href=\"http://developer.feedforce.jp/entry/2017/11/13/085404\"\u003eAlfred Workflow を Go で書いたという LT を発表していて\u003c/a\u003e面白そうだったので、自分も書いてみました。\u003c/p\u003e\n\n\u003cp\u003e以下のリポジトリで配布しています。\u003c/p\u003e\n\n\u003cp\u003e\u003ci class=\"fa fa-github\"\u003e\u003c/i\u003e \u003ca href=\"https://github.com/tsub/alfred-datadog-workflow\"\u003etsub/alfred-datadog-workflow: A Alfred workflow to open Datadog pages\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eWorkflow のダウンロードリンクは\u003ca href=\"https://github.com/tsub/alfred-datadog-workflow/releases\"\u003eこちら\u003c/a\u003eから最新バージョンのものをどうぞ。\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://gyazo.com/378dfd74e772c2d48776c5edd8ce6833.png\" alt=\"image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"最近会社の同僚が Alfred Workflow を Go で書いたという LT を発表していて面白そうだったので、自分も書いてみました。以下のリポジトリで配布しています。 tsub/alfred-datadog-workflow: A Alfred workflow to open Datadog pagesWorkflow のダウンロードリンクはこちらから最新バージョンのものをどうぞ。","link":"https://blog.tsub.me/post/create-alfred-workflow/","isoDate":"2017-11-26T07:00:00.000Z","dateMiliSeconds":1511679600000,"authorName":"tsub"},{"title":"【2017/11/16 に訂正を追記しました】 社内 LT 大会で「ここがつらいよ ECS」というタイトルで発表しました","content":"\u003ch2\u003e[追記] この記事の内容について訂正\u003c/h2\u003e\n\n\u003cp\u003eこの記事内、及び Speaker Deck に投稿したスライドの中で誤っていた箇所があったため、訂正致します。\u003c/p\u003e\n\n\u003cp\u003e「ECS Optimized AMI では ecs-agent のバージョンが固定されない」という内容ですが、そういった問題はありませんでした。\u003c/p\u003e\n\n\u003cp\u003eAWS の方から直接アドバイスを頂いたところ、弊社が使用していた User Data のスクリプト内で \u003ccode\u003e$ yum update\u003c/code\u003e を実行していたことが原因となっていました。\n\u003ccode\u003e$ yum update\u003c/code\u003e によりインスタンスを新規に立てた際に常に最新の ecs-agent や Docker がインストールされていました。\u003c/p\u003e\n\n\u003cp\u003eそのため、ECS Optimized AMI によってインストールされる ecs-agent と Docker のバージョンは以下のドキュメントで提示されているバージョンが常にインストールされることになります。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=http%3A%2F%2Fdocs.aws.amazon.com%2FAmazonECS%2Flatest%2Fdeveloperguide%2Fcontainer_agent_versions.html\" title=\"Amazon ECS Container Agent Versions - Amazon EC2 Container Service\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"http://docs.aws.amazon.com/AmazonECS/latest/developerguide/container_agent_versions.html\"\u003edocs.aws.amazon.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eスライド中でも紹介しているように、一番困っていた問題が解消されたため AWS のサポートの方には非常に感謝をしております。\u003c/p\u003e\n\n\u003cp\u003e誤った情報を公開してしまい、申し訳ありませんでした。\u003c/p\u003e\n\n\u003chr /\u003e\n\n\u003cp\u003eこんにちは、バックエンドエンジニアの tsub (\u003ca href=\"http://blog.hatena.ne.jp/tsub511/\" class=\"hatena-id-icon\"\u003e\u003cimg src=\"https://cdn1.www.st-hatena.com/users/ts/tsub511/profile.gif\" width=\"16\" height=\"16\" alt=\"\" class=\"hatena-id-icon\"\u003eid:tsub511\u003c/a\u003e) です。\u003c/p\u003e\n\n\u003cp\u003e先日の社内 LT 大会にて、「ここがつらいよ ECS」というタイトルで発表してきました。\u003c/p\u003e\n\n\u003cp\u003e社内 LT 大会の記事についてはこちらをご覧ください。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=http%3A%2F%2Fdeveloper.feedforce.jp%2Fentry%2F2017%2F11%2F11%2F205600\" title=\"FFLT開催しました！ - Feedforce Developer Blog\" class=\"embed-card embed-blogcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 190px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"http://developer.feedforce.jp/entry/2017/11/11/205600\"\u003edeveloper.feedforce.jp\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e私が発表したスライドはこちらです。\u003c/p\u003e\n\n\u003cscript async class=\"speakerdeck-embed\" data-id=\"4b214465b598443dbb55cfa35cd56aa3\" data-ratio=\"1.33333333333333\" src=\"//speakerdeck.com/assets/embed.js\"\u003e\u003c/script\u003e\n\n\n\u003cp\u003eせっかくですので、スライドにて紹介している「第一位 ecs-agent と Docker のバージョンが勝手に上がる」についてもう少し詳しく解説をしたいと思います。\u003c/p\u003e\n\n\u003ch2\u003eECS を用いたバッチシステムの運用について\u003c/h2\u003e\n\n\u003cp\u003e弊社では Amazon ECS を用いたバッチシステムを運用しています。\u003c/p\u003e\n\n\u003cp\u003eAmazon ECS を用いたバッチシステムについての詳細は以前弊社の新卒エンジニアが書いてくれたので、こちらの記事をご覧ください。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fwww.wantedly.com%2Fcompanies%2Ffeedforce%2Fpost_articles%2F59811\" title=\"新卒１年目がバッチサーバーにECSを使ってDockerを導入した話 | feedforce Story\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://www.wantedly.com/companies/feedforce/post_articles/59811\"\u003ewww.wantedly.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003ch2\u003eecs-agent について\u003c/h2\u003e\n\n\u003cp\u003e\u003ca href=\"https://github.com/aws/amazon-ecs-agent\"\u003eecs-agent\u003c/a\u003e とは、Amazon ECS にインスタンスを認識させるために動かす必要のあるエージェントです。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fgithub.com%2Faws%2Famazon-ecs-agent\" title=\"aws/amazon-ecs-agent\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://github.com/aws/amazon-ecs-agent\"\u003egithub.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://hub.docker.com/r/amazon/amazon-ecs-agent/\"\u003eDocker イメージが配布されていて\u003c/a\u003e、通常はコンテナとして立ち上げます。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"http://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html\"\u003eECS Optimized AMI\u003c/a\u003e を利用していれば、インスタンスを起動したタイミングで勝手に立ち上げてくれるので、特に意識せずとも ECS を使えると思います。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=http%3A%2F%2Fdocs.aws.amazon.com%2FAmazonECS%2Flatest%2Fdeveloperguide%2Fecs-optimized_AMI.html\" title=\"Amazon ECS-Optimized AMI - Amazon EC2 Container Service\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"http://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html\"\u003edocs.aws.amazon.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eただし、ECS においてはこの ecs-agent がコンテナの配置、監視などを行っているため、かなり重要な役割となりますので、無視してはいけない存在です。\u003c/p\u003e\n\n\u003ch2\u003eecs-agent のバグによりいくつかのタスクが起動しなかった\u003c/h2\u003e\n\n\u003cp\u003e以前、以下の Issue で取り上げられている ecs-agent v1.14.2 のバグにより ECS でいくつかのタスクが起動しなくなっていました。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fgithub.com%2Faws%2Famazon-ecs-agent%2Fissues%2F833\" title=\"1.14.2 causing container instances to grind to a halt · Issue #833 · aws/amazon-ecs-agent\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://github.com/aws/amazon-ecs-agent/issues/833\"\u003egithub.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e2017/06/08 に ecs-agent を全コンテナインスタンスで v1.14.2 にアップデートしたことにより、06/08 から 06/13 にかけて 6 つのタスクが PENDING 状態のまま止まっていてインシデントが起きてしまいました。\u003c/p\u003e\n\n\u003cp\u003eこの時は、上記 Issue でも書かれているように、一旦 \u003ccode\u003eamazon/amazon-ecs-agent:latest\u003c/code\u003e イメージにバグが発生する以前の v1.14.1 を Push し直してくれたことで、バージョンをロールバックすることはできました。\u003c/p\u003e\n\n\u003cp\u003eただ、このような問題を再度起こさないためにも ecs-agent のバージョンは固定したいところですが、固定はできないという問題がここで発覚しました。\u003c/p\u003e\n\n\u003ch2\u003eECS Optimized AMI では ecs-agent のバージョンが固定されない\u003c/h2\u003e\n\n\u003cp\u003eECS Optimized AMI を使っていれば ecs-agent を自動的に立ち上げてくれますが、これが少々曲者です。\u003c/p\u003e\n\n\u003cp\u003eECS Optimized AMI を使ってインスタンスを立ち上げた時、起動する ecs-agent のバージョンは常に最新のものが使われるのです。\u003c/p\u003e\n\n\u003cp\u003eしかも、AMI の中に ecs-agent がパッケージングされているかと思ったら、AMI をアップデートせずとも、インスタンスを新しく起動したら最新の ecs-agent が自動的に使用されます。\u003c/p\u003e\n\n\u003cp\u003e更に言うと、この ecs-agent のバージョンをユーザーが固定することはできず、最新バージョンしか選択肢がありません。\u003c/p\u003e\n\n\u003cp\u003eそのため、上述したようなバグが ecs-agent に含まれてしまった場合に回避不可能になります。\u003c/p\u003e\n\n\u003cp\u003e新たにインスタンスを立ち上げず、手動で ecs-agent をアップデートしなければ今動いてるもののバージョンが変わることはありませんが、オートスケーリングの設定をしていた場合、スケールアウトしたらそのインスタンスからは最新の ecs-agent が使われてしまう、という状況です。\u003c/p\u003e\n\n\u003cp\u003eこの回避不可能な仕様に日々悩まされています。\u003c/p\u003e\n\n\u003cp\u003eちなみに、Docker のバージョンも ecs-agent と同じようにバージョンが固定されていません。\u003c/p\u003e\n\n\u003ch2\u003eどう運用しているか\u003c/h2\u003e\n\n\u003cp\u003eでは、弊社ではどう運用しているかというと、一部のコンテナインスタンスにカナリアリリース的にアップデートし、しばらく最新バージョンの ecs-agent をクラスタの中に紛れ込ませて稼働させておきます。\u003c/p\u003e\n\n\u003cp\u003e例えば 10 台のコンテナインスタンスを動かしていたとして、その内の 2, 3 台だけ ecs-agent をアップデートします。\u003c/p\u003e\n\n\u003cp\u003eアップデート自体は AWS コンソールから可能ですので簡単です。\u003c/p\u003e\n\n\u003cp\u003e数台だけアップデートした後 1, 2 週間ほど経ってから \u003ca href=\"https://github.com/aws/amazon-ecs-agent/issues\"\u003eecs-agent の Issue\u003c/a\u003e を確認して、特に大きな問題が起きてなさそうなら全台アップデートする、というような運用をしています。\u003c/p\u003e\n\n\u003cp\u003eこれで今のところ ecs-agent のバグを踏む確率は多少減ったかな、という印象です。\u003c/p\u003e\n\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eecs-agent のアップデートによりバグが入り込む可能性がある\u003c/li\u003e\n\u003cli\u003eECS Optimized AMI における ecs-agent と Docker のバージョン固定はできず、新しいインスタンスを起動すると最新が使われる\u003c/li\u003e\n\u003cli\u003e一部のコンテナインスタンスだけアップデートし、しばらく経って問題なければ全台アップデートする、という運用をしている\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eというわけで、今後も ECS による運用を続けていきますが、何か良いソリューションがあれば教えていただきたい次第です。\u003c/p\u003e\n","contentSnippet":"[追記] この記事の内容について訂正この記事内、及び Speaker Deck に投稿したスライドの中で誤っていた箇所があったため、訂正致します。「ECS Optimized AMI では ecs-agent のバージョンが固定されない」という内容ですが、そういった問題はありませんでした。AWS の方から直接アドバイスを頂いたところ、弊社が使用していた User Data のスクリプト内で $ yum update を実行していたことが原因となっていました。$ yum update によりインスタンスを新規に立てた際に常に最新の ecs-agent や Docker がインストールされていました。そのため、ECS Optimized AMI によってインストールされる ecs-agent と Docker のバージョンは以下のドキュメントで提示されているバージョンが常にインストールされることになります。docs.aws.amazon.comスライド中でも紹介しているように、一番困っていた問題が解消されたため AWS のサポートの方には非常に感謝をしております。誤った情報を公開してしまい、申し訳ありませんでした。こんにちは、バックエンドエンジニアの tsub (id:tsub511) です。先日の社内 LT 大会にて、「ここがつらいよ ECS」というタイトルで発表してきました。社内 LT 大会の記事についてはこちらをご覧ください。developer.feedforce.jp私が発表したスライドはこちらです。せっかくですので、スライドにて紹介している「第一位 ecs-agent と Docker のバージョンが勝手に上がる」についてもう少し詳しく解説をしたいと思います。ECS を用いたバッチシステムの運用について弊社では Amazon ECS を用いたバッチシステムを運用しています。Amazon ECS を用いたバッチシステムについての詳細は以前弊社の新卒エンジニアが書いてくれたので、こちらの記事をご覧ください。www.wantedly.comecs-agent についてecs-agent とは、Amazon ECS にインスタンスを認識させるために動かす必要のあるエージェントです。github.comDocker イメージが配布されていて、通常はコンテナとして立ち上げます。ECS Optimized AMI を利用していれば、インスタンスを起動したタイミングで勝手に立ち上げてくれるので、特に意識せずとも ECS を使えると思います。docs.aws.amazon.comただし、ECS においてはこの ecs-agent がコンテナの配置、監視などを行っているため、かなり重要な役割となりますので、無視してはいけない存在です。ecs-agent のバグによりいくつかのタスクが起動しなかった以前、以下の Issue で取り上げられている ecs-agent v1.14.2 のバグにより ECS でいくつかのタスクが起動しなくなっていました。github.com2017/06/08 に ecs-agent を全コンテナインスタンスで v1.14.2 にアップデートしたことにより、06/08 から 06/13 にかけて 6 つのタスクが PENDING 状態のまま止まっていてインシデントが起きてしまいました。この時は、上記 Issue でも書かれているように、一旦 amazon/amazon-ecs-agent:latest イメージにバグが発生する以前の v1.14.1 を Push し直してくれたことで、バージョンをロールバックすることはできました。ただ、このような問題を再度起こさないためにも ecs-agent のバージョンは固定したいところですが、固定はできないという問題がここで発覚しました。ECS Optimized AMI では ecs-agent のバージョンが固定されないECS Optimized AMI を使っていれば ecs-agent を自動的に立ち上げてくれますが、これが少々曲者です。ECS Optimized AMI を使ってインスタンスを立ち上げた時、起動する ecs-agent のバージョンは常に最新のものが使われるのです。しかも、AMI の中に ecs-agent がパッケージングされているかと思ったら、AMI をアップデートせずとも、インスタンスを新しく起動したら最新の ecs-agent が自動的に使用されます。更に言うと、この ecs-agent のバージョンをユーザーが固定することはできず、最新バージョンしか選択肢がありません。そのため、上述したようなバグが ecs-agent に含まれてしまった場合に回避不可能になります。新たにインスタンスを立ち上げず、手動で ecs-agent をアップデートしなければ今動いてるもののバージョンが変わることはありませんが、オートスケーリングの設定をしていた場合、スケールアウトしたらそのインスタンスからは最新の ecs-agent が使われてしまう、という状況です。この回避不可能な仕様に日々悩まされています。ちなみに、Docker のバージョンも ecs-agent と同じようにバージョンが固定されていません。どう運用しているかでは、弊社ではどう運用しているかというと、一部のコンテナインスタンスにカナリアリリース的にアップデートし、しばらく最新バージョンの ecs-agent をクラスタの中に紛れ込ませて稼働させておきます。例えば 10 台のコンテナインスタンスを動かしていたとして、その内の 2, 3 台だけ ecs-agent をアップデートします。アップデート自体は AWS コンソールから可能ですので簡単です。数台だけアップデートした後 1, 2 週間ほど経ってから ecs-agent の Issue を確認して、特に大きな問題が起きてなさそうなら全台アップデートする、というような運用をしています。これで今のところ ecs-agent のバグを踏む確率は多少減ったかな、という印象です。まとめecs-agent のアップデートによりバグが入り込む可能性があるECS Optimized AMI における ecs-agent と Docker のバージョン固定はできず、新しいインスタンスを起動すると最新が使われる一部のコンテナインスタンスだけアップデートし、しばらく経って問題なければ全台アップデートする、という運用をしているというわけで、今後も ECS による運用を続けていきますが、何か良いソリューションがあれば教えていただきたい次第です。","link":"https://developer.feedforce.jp/entry/2017/11/13/183623","isoDate":"2017-11-13T09:36:23.000Z","dateMiliSeconds":1510565783000,"imageUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/t/tsub511/20171113/20171113173603.jpg","authorName":"tsub"},{"title":"Go で s3-edit という CLI アプリケーションを作った","content":"\u003cp\u003e最近 Rust を少し学んでいたが、難しくて少し挫折しかけたのと、結局仕事への導入を考えるなら Go のほうが既に書ける人が何人かいる、というのもあり Go を書き始めた。\u003c/p\u003e\n\n\u003cp\u003e手初めてに欲しい CLI アプリケーションがあったのでそれをサクッと Go で書いてみた。\u003c/p\u003e\n\n\u003cp\u003e\u003ci class=\"fa fa-github\"\u003e\u003c/i\u003e \u003ca href=\"https://github.com/tsub/s3-edit\"\u003etsub/s3-edit: Edit directly a file on Amazon S3\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"最近 Rust を少し学んでいたが、難しくて少し挫折しかけたのと、結局仕事への導入を考えるなら Go のほうが既に書ける人が何人かいる、というのもあり Go を書き始めた。手初めてに欲しい CLI アプリケーションがあったのでそれをサクッと Go で書いてみた。 tsub/s3-edit: Edit directly a file on Amazon S3","link":"https://blog.tsub.me/post/create-s3-edit/","isoDate":"2017-09-05T13:30:00.000Z","dateMiliSeconds":1504618200000,"authorName":"tsub"},{"title":"pecoからfzfに移行した","content":"\u003cp\u003e今までずっと \u003ca href=\"https://github.com/peco/peco\"\u003epeco\u003c/a\u003e を使ってきたが、そろそろ別のツールに変えてみるか\u0026hellip;と思い立ったので \u003ca href=\"https://github.com/junegunn/fzf\"\u003efzf\u003c/a\u003e に移行した。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://github.com/junegunn/fzf\"\u003ejunegunn/fzf: A command-line fuzzy finder written in Go\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e自分は基本的に飽き性なので、定期的に環境を変えたくなる時期が来るのだが fzf が思ってたより良かったので紹介したい。\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"今までずっと peco を使ってきたが、そろそろ別のツールに変えてみるか…と思い立ったので fzf に移行した。junegunn/fzf: A command-line fuzzy finder written in Go自分は基本的に飽き性なので、定期的に環境を変えたくなる時期が来るのだが fzf が思ってたより良かったので紹介したい。","link":"https://blog.tsub.me/post/move-from-peco-to-fzf/","isoDate":"2017-05-03T00:30:00.000Z","dateMiliSeconds":1493771400000,"authorName":"tsub"},{"title":"ブログをGKEでの運用に移行した","content":"\u003cp\u003eこのブログはGitHub pagesを使って公開していたが、GKEに移行することにした。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://blog.tsub.me/post/created-blog-by-hugo/\"\u003eはてなブログからHugo on Github Pagesに移行しました\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eこれを聞いて、99%の人が、HugoでHTMLファイルを生成して公開しているならわざわざサーバーなんて必要ないんじゃないか？金の無駄じゃないか？と思うかもしれない。\u003c/p\u003e\n\n\u003cp\u003e自分もそう思う。\u003c/p\u003e\n\n\u003cp\u003e今回GKEを使ったのはGKEとk8sでのコンテナ運用を経験したかったことが非常に大きい。\u003c/p\u003e\n\n\u003cp\u003e会社ではECSを本番運用しているが、ECSに比べてk8sの方が良さそうな雰囲気しかないのでGKEの方も触っておこうかと思って移行した。\u003c/p\u003e\n\n\u003cp\u003eまた、今のところブログ以外に個人で運用しているWebサービス等はないため、ブログがちょうどいい題材だった。\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"このブログはGitHub pagesを使って公開していたが、GKEに移行することにした。はてなブログからHugo on Github Pagesに移行しましたこれを聞いて、99%の人が、HugoでHTMLファイルを生成して公開しているならわざわざサーバーなんて必要ないんじゃないか？金の無駄じゃないか？と思うかもしれない。自分もそう思う。今回GKEを使ったのはGKEとk8sでのコンテナ運用を経験したかったことが非常に大きい。会社ではECSを本番運用しているが、ECSに比べてk8sの方が良さそうな雰囲気しかないのでGKEの方も触っておこうかと思って移行した。また、今のところブログ以外に個人で運用しているWebサービス等はないため、ブログがちょうどいい題材だった。","link":"https://blog.tsub.me/post/operate-blog-server-on-gke/","isoDate":"2017-04-16T05:29:33.000Z","dateMiliSeconds":1492320573000,"authorName":"tsub"},{"title":"ぼくの情報収集方法","content":"\u003cp\u003eこの記事は\u003ca href=\"http://www.adventar.org/calendars/1427\"\u003efeedforce Advent Calender 2016\u003c/a\u003eの17日目の記事です。\u003c/p\u003e\n\n\u003cp\u003e前回の記事はpokotyamuによる\u003ca href=\"http://pokotyamu.hatenablog.com/entry/2016/12/16/095524\"\u003eHHKBを掃除した話\u003c/a\u003eでした\u003c/p\u003e\n\n\u003cp\u003e無刻印のキーだからといってどのキーでも当てはまると思って適当にやるとものすごい罠に引っかかっちゃうんですね。\u003c/p\u003e\n\n\u003cp\u003eさて、今回は多くのエンジニアにとって重要なキーワードである情報収集についてです。\u003c/p\u003e\n\n\u003cp\u003e自分は多分社内ではわりと情報収集よくやってる方だと思っているのですが、自分が普段どんな方法で情報収集してるかを共有したかったので今回まとめてみました。\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"この記事はfeedforce Advent Calender 2016の17日目の記事です。前回の記事はpokotyamuによるHHKBを掃除した話でした無刻印のキーだからといってどのキーでも当てはまると思って適当にやるとものすごい罠に引っかかっちゃうんですね。さて、今回は多くのエンジニアにとって重要なキーワードである情報収集についてです。自分は多分社内ではわりと情報収集よくやってる方だと思っているのですが、自分が普段どんな方法で情報収集してるかを共有したかったので今回まとめてみました。","link":"https://blog.tsub.me/post/how-i-collect-information/","isoDate":"2016-12-17T07:50:00.000Z","dateMiliSeconds":1481961000000,"authorName":"tsub"},{"title":"Blox Introduction","content":"\u003cp\u003eこの記事は\u003ca href=\"http://qiita.com/advent-calendar/2016/docker\"\u003eDocker Advent Calendar 2016\u003c/a\u003eの9日目の記事です。\u003c/p\u003e\n\n\u003cp\u003e先日AWSのre:Invent 2016で\u003ca href=\"https://blox.github.io/\"\u003eBlox\u003c/a\u003eが発表されました。\u003c/p\u003e\n\n\u003cp\u003eBloxはEC2 Container Service(ECS)関連のオープンソースのツール群のことです。\u003c/p\u003e\n\n\u003cp\u003eそしてそのツールとは主にECSのカスタムスケジューラを指します\u003c/p\u003e\n\n\u003cp\u003eECSはマネージドなスケジューラとマネージャを標準で備えていますが、Bloxはそれとは別に自分でホスティングする必要があります。\u003c/p\u003e\n\n\u003cp\u003eしかし、ECSに足りない機能を補ってくれるため導入するメリットは大きいでしょう。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://aws.amazon.com/jp/blogs/news/monitor-cluster-state-with-amazon-ecs-event-stream/\"\u003e先日リリースされた、CloudWatchEventsのECSイベントストリーム\u003c/a\u003eを利用することで、よりスムーズにECSのクラスタの状態を監視してカスタムスケジューラを作ることができるようになりました。\u003c/p\u003e\n\n\u003cp\u003eBloxはこれを使った一例と言えます\u003c/p\u003e\n\n\u003cp\u003eこの記事ではBloxについて試してみて分かった内容や所感について書いていきます\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://i.gyazo.com/4c00e85fca7b228d7aa0d5f1e6dd1d27.png\" alt=\"Blox thumbnail\" /\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"この記事はDocker Advent Calendar 2016の9日目の記事です。先日AWSのre:Invent 2016でBloxが発表されました。BloxはEC2 Container Service(ECS)関連のオープンソースのツール群のことです。そしてそのツールとは主にECSのカスタムスケジューラを指しますECSはマネージドなスケジューラとマネージャを標準で備えていますが、Bloxはそれとは別に自分でホスティングする必要があります。しかし、ECSに足りない機能を補ってくれるため導入するメリットは大きいでしょう。先日リリースされた、CloudWatchEventsのECSイベントストリームを利用することで、よりスムーズにECSのクラスタの状態を監視してカスタムスケジューラを作ることができるようになりました。Bloxはこれを使った一例と言えますこの記事ではBloxについて試してみて分かった内容や所感について書いていきます","link":"https://blog.tsub.me/post/blox-introduction/","isoDate":"2016-12-08T15:00:00.000Z","dateMiliSeconds":1481209200000,"authorName":"tsub"},{"title":"はてなブログからHugo on Github Pagesに移行しました","content":"\u003cp\u003eはてなブログをやめて、Hugo on Github Pagesに移行しました。\u003c/p\u003e\n\n\u003cp\u003eといっても、走りだしのブログであまり記事は多くないんですが..\u003c/p\u003e\n\n\u003cp\u003e移行した理由は、以前のブログを構築した際に、調子に乗ってはてなブログProに登録して独自ドメインを使っていたのですが、思ったよりも記事を書かずお金がちょっと勿体無いなーと思い始めてきたのでGithub Pagesに移行しました。\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"はてなブログをやめて、Hugo on Github Pagesに移行しました。といっても、走りだしのブログであまり記事は多くないんですが..移行した理由は、以前のブログを構築した際に、調子に乗ってはてなブログProに登録して独自ドメインを使っていたのですが、思ったよりも記事を書かずお金がちょっと勿体無いなーと思い始めてきたのでGithub Pagesに移行しました。","link":"https://blog.tsub.me/post/created-blog-by-hugo/","isoDate":"2016-08-11T16:01:16.000Z","dateMiliSeconds":1470931276000,"authorName":"tsub"},{"title":"neovimのterminal emulatorが便利すぎた","content":"\u003cp\u003e少し前にvimからneovimに移行したのですが、vimよりさくさくな気がする、程度でneovimの機能を特に活用していませんでした。\u003c/p\u003e\n\n\u003cp\u003e実はneovimにはterminal emulatorという機能があり、vimの中でshellを起動することができます。\u003c/p\u003e\n\n\u003cp\u003e例えばコードを書きつつ、rspecを実行したりpryやtigを使ったりなど、非常に便利です。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://gyazo.com/ca4b9ef1599801f1948721befe274654.png\"\u003e\u003cimg src=\"https://i.gyazo.com/ca4b9ef1599801f1948721befe274654.png\" alt=\"\" /\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"少し前にvimからneovimに移行したのですが、vimよりさくさくな気がする、程度でneovimの機能を特に活用していませんでした。実はneovimにはterminal emulatorという機能があり、vimの中でshellを起動することができます。例えばコードを書きつつ、rspecを実行したりpryやtigを使ったりなど、非常に便利です。","link":"https://blog.tsub.me/post/neovim-on-terminal-emulator/","isoDate":"2016-07-02T13:08:23.000Z","dateMiliSeconds":1467464903000,"authorName":"tsub"},{"title":"tokyo.ex #3 参加してきた","content":"\u003cp\u003etokyo.ex #3 に参加してきました。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"http://beam-lang.connpass.com/event/32704/\"\u003etokyo.ex #3\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e前々からtokyo.ex #1, #2と気にはなっていたんですが、気づいた時には定員が埋まってまして今回やっと参加できました。\u003c/p\u003e\n\n\u003cp\u003eと思ってたらわりと席空いてたりキャンセル多かったり、定員超えてるからといって諦めなくても良かったみたいですね\u003c/p\u003e\n\n\u003cp\u003e参加してみての全体的な感想ですが、正直最近elixirを触ってなかったのでいい刺激になりました。\u003c/p\u003e\n\n\u003cp\u003e話の内容は非常にレベルが高く、大半は理解できませんでしたが、その分elixirの勢いとコミュニティの熱さは十分伝わってきました。\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"tokyo.ex #3 に参加してきました。tokyo.ex #3前々からtokyo.ex #1, #2と気にはなっていたんですが、気づいた時には定員が埋まってまして今回やっと参加できました。と思ってたらわりと席空いてたりキャンセル多かったり、定員超えてるからといって諦めなくても良かったみたいですね参加してみての全体的な感想ですが、正直最近elixirを触ってなかったのでいい刺激になりました。話の内容は非常にレベルが高く、大半は理解できませんでしたが、その分elixirの勢いとコミュニティの熱さは十分伝わってきました。","link":"https://blog.tsub.me/post/tokyo-ex-3-entry-report/","isoDate":"2016-06-30T14:56:16.000Z","dateMiliSeconds":1467298576000,"authorName":"tsub"},{"title":"serverspecで複数のdocker containerに対してテストしたい","content":"\u003cp\u003e前回の記事でdocker containerに対してserverspecでテストができるようになりました。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://blog.tsub.me/post/serverspec-for-docker/\"\u003eserverspecでdocker containerに対してテストしたい\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003edockerを扱う以上、containerは複数立てるのが普通です。\u003c/p\u003e\n\n\u003cp\u003e今回は複数のcontainerを立てた時にそれぞれのcontainerに対してテストする方法について書いていきます。\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"前回の記事でdocker containerに対してserverspecでテストができるようになりました。serverspecでdocker containerに対してテストしたいdockerを扱う以上、containerは複数立てるのが普通です。今回は複数のcontainerを立てた時にそれぞれのcontainerに対してテストする方法について書いていきます。","link":"https://blog.tsub.me/post/serverspec-for-several-container/","isoDate":"2016-06-25T14:36:05.000Z","dateMiliSeconds":1466865365000,"authorName":"tsub"},{"title":"serverspecでdocker containerに対してテストしたい","content":"\u003cp\u003e仕事でこれからdockerを使い始めるので、dockerを触りつつメモがてら記事に残していきます。\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e","contentSnippet":"仕事でこれからdockerを使い始めるので、dockerを触りつつメモがてら記事に残していきます。","link":"https://blog.tsub.me/post/serverspec-for-docker/","isoDate":"2016-06-25T13:25:08.000Z","dateMiliSeconds":1466861108000,"authorName":"tsub"}]},"__N_SSG":true},"page":"/members/[name]","query":{"name":"tsub"},"buildId":"DnKMEcInvxv81jxizspcL","nextExport":false,"isFallback":false,"gsp":true,"head":[["meta",{"name":"viewport","content":"width=device-width"}],["meta",{"charSet":"utf-8"}],["link",{"rel":"icon shortcut","type":"image/png","href":"https://engineers.feedforce.jp/logo.png"}],["link",{"rel":"stylesheet","href":"https://fonts.googleapis.com/css2?family=Inter:wght@400;700\u0026display=swap"}],["title",{"children":"tsub | Feedforce Engineers' Blogs"}],["meta",{"property":"og:title","content":"tsub"}],["meta",{"property":"og:url","content":"https://engineers.feedforce.jp/members/tsub"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"property":"og:site","content":"Feedforce Engineers' Blogs"}],["meta",{"property":"og:image","content":"https://engineers.feedforce.jp/og.png"}],["link",{"rel":"canonical","href":"https://engineers.feedforce.jp/members/tsub"}],["link",{"rel":"alternate","type":"application/rss+xml","title":"Feedforce Engineers' Blogs","href":"https://engineers.feedforce.jp/rss.xml"}],["link",{"rel":"alternate","type":"application/atom+xml","title":"Feedforce Engineers' Blogs","href":"https://engineers.feedforce.jp/atom.xml"}]]}</script><script nomodule="" src="/_next/static/chunks/polyfills-fa276ba060a4a8ac7eef.js"></script><script src="/_next/static/chunks/main-8a83f0fd99327c4684a8.js" async=""></script><script src="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" async=""></script><script src="/_next/static/chunks/framework.1daf1ec1ecf144ee9147.js" async=""></script><script src="/_next/static/chunks/commons.9e003f150a446b53bdd9.js" async=""></script><script src="/_next/static/chunks/pages/_app-99db904e083fc7f74e35.js" async=""></script><script src="/_next/static/chunks/588505f8033a39c9ef82bc46b1145ac9fd1db500.1b31e9b3d8ab8514c941.js" async=""></script><script src="/_next/static/chunks/pages/members/%5Bname%5D-42a7756adc6c0800b4dc.js" async=""></script><script src="/_next/static/DnKMEcInvxv81jxizspcL/_buildManifest.js" async=""></script><script src="/_next/static/DnKMEcInvxv81jxizspcL/_ssgManifest.js" async=""></script></body></html>