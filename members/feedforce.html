<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon shortcut" type="image/png" href="https://engineers.feedforce.jp/logo.png"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&amp;display=swap"/><title>feedforce | Feedforce Engineers&#x27; Blogs</title><meta property="og:title" content="feedforce"/><meta property="og:url" content="https://engineers.feedforce.jp/members/feedforce"/><meta name="twitter:card" content="summary_large_image"/><meta property="og:site" content="Feedforce Engineers&#x27; Blogs"/><meta property="og:image" content="https://engineers.feedforce.jp/og.png"/><link rel="canonical" href="https://engineers.feedforce.jp/members/feedforce"/><link rel="alternate" type="application/rss+xml" title="Feedforce Engineers&#x27; Blogs" href="https://engineers.feedforce.jp/rss.xml"/><link rel="alternate" type="application/atom+xml" title="Feedforce Engineers&#x27; Blogs" href="https://engineers.feedforce.jp/atom.xml"/><link rel="preload" href="/_next/static/css/d7faf1fdf25fe7d3262e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/d7faf1fdf25fe7d3262e.css" data-n-g=""/><noscript data-n-css="true"></noscript><link rel="preload" href="/_next/static/chunks/main-8a83f0fd99327c4684a8.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.1daf1ec1ecf144ee9147.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.9e003f150a446b53bdd9.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-99db904e083fc7f74e35.js" as="script"/><link rel="preload" href="/_next/static/chunks/588505f8033a39c9ef82bc46b1145ac9fd1db500.7f1789362bee7bf8434b.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/members/%5Bname%5D-42a7756adc6c0800b4dc.js" as="script"/></head><body><div id="__next"><header class="site-header"><div class="content-wrapper"><div class="site-header__inner"><a class="site-header__logo-link" href="/"><img src="https://engineers.feedforce.jp/logo.svg" alt="Feedforce Engineers&#x27; Blogs" class="site-header__logo-img"/></a><div class="site-header__links"><a href="https://feedforcegroup.jp" class="site-header__link">Company</a><a href="https://github.com/feedforce" class="site-header__link">GitHub</a><a href="https://engineers.recruit.feedforce.jp" class="site-header__link">Recruit</a></div></div></div></header><section class="member"><div class="content-wrapper"><header class="member-header"><div class="member-header__avatar"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" alt="feedforce" width="100" height="100" class="member-header__avatar-img"/></div><h1 class="member-header__name">feedforce</h1><p class="member-header__bio">Feedforce Developer Blog</p><div class="member-header__links"></div></header><div class="member-posts-container"><div class="post-list"><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2021-09-02T04:47:25.000Z" class="post-link__date">a month ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/09/02/134725" class="post-link__main-link"><h2 class="post-link__title">Amazon EKS で高負荷時に CoreDNS が原因で稀にネットワークエラーが発生していた時のトラブルシュート</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2021-07-07T01:39:17.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/07/07/103917" class="post-link__main-link"><h2 class="post-link__title">Firestore エミュレーターを使ったテスト同士の競合が起きないようにしていい感じにテストできるようにした話</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2021-06-11T07:42:53.000Z" class="post-link__date">4 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/06/11/164253" class="post-link__main-link"><h2 class="post-link__title">【2021年夏】半期に1度の Engineer’s Principles Award 受賞者を紹介します</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2021-05-31T01:48:13.000Z" class="post-link__date">4 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/05/31/104813" class="post-link__main-link"><h2 class="post-link__title">プランニングの難しさを乗り越えて...スクラム開発が良い感じになった話</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2021-05-24T02:00:00.000Z" class="post-link__date">5 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/career_path_revised_2021" class="post-link__main-link"><h2 class="post-link__title">エンジニアキャリアパスをアップデートしました</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2021-05-17T00:38:42.000Z" class="post-link__date">5 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/05/13/093842" class="post-link__main-link"><h2 class="post-link__title">広告の複数媒体に対するCPA最小化・ROAS最大化となる予算配分を計算しよう</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2021-04-19T05:11:53.000Z" class="post-link__date">6 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/04/19/141153" class="post-link__main-link"><h2 class="post-link__title">ふりかえりカンファレンスのスタッフをやりました！</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2021-04-13T08:48:08.000Z" class="post-link__date">6 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/04/13/174808" class="post-link__main-link"><h2 class="post-link__title"> 夜間光データから土地価格を予測 コンペの参加記録</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2021-03-15T02:32:30.000Z" class="post-link__date">7 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/03/15/113230" class="post-link__main-link"><h2 class="post-link__title">エンジニア向けミートアップを開催します！</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2021-03-11T01:12:44.000Z" class="post-link__date">7 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/03/11/101244" class="post-link__main-link"><h2 class="post-link__title">Self-Attentionを用いてGoogle 無料リスティングの「拡張リスティングの不承認」に挑んだ話</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2021-03-04T09:03:04.000Z" class="post-link__date">7 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/03/04/180304" class="post-link__main-link"><h2 class="post-link__title">データ指向アプリケーションデザイン 第三章 旅行記</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2021-03-02T08:29:59.000Z" class="post-link__date">7 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/03/02/172959" class="post-link__main-link"><h2 class="post-link__title">データ指向アプリケーションデザイン 第二章 旅行記</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2021-02-09T02:41:10.000Z" class="post-link__date">8 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/02/09/114110" class="post-link__main-link"><h2 class="post-link__title">Terraform の terraform-provider-datadog で古い source から新しい source に更新する際の Warning を解消する方法</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2021-01-12T03:00:00.000Z" class="post-link__date">9 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/2021/01/12/120000" class="post-link__main-link"><h2 class="post-link__title">Google MyBusiness APIのGoクライアントを生成する</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2020-12-28T04:10:42.000Z" class="post-link__date">10 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/2020/12/28/131042" class="post-link__main-link"><h2 class="post-link__title">半期に1度の Engineer’s Principles Award 受賞者を紹介します</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/feedforce"><img src="https://engineers.feedforce.jp/avatars/feedforce.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">feedforce</div><time dateTime="2020-12-11T08:23:38.000Z" class="post-link__date">10 months ago</time></div></a><a href="https://developer.feedforce.jp/entry/2020/12/11/172338" class="post-link__main-link"><h2 class="post-link__title">半年モブプロしたらチームが大きく成長した話</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=developer.feedforce.jp" width="14" height="14" class="post-link__site-favicon"/>developer.feedforce.jp</div></a></article></div></div></div></section><footer class="site-footer"><div class="content-wrapper"><p>© <!-- -->Feedforce Group Inc.</p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"member":{"name":"feedforce","bio":"Feedforce Developer Blog","avatarSrc":"/avatars/feedforce.jpg","sources":["https://developer.feedforce.jp/rss"]},"postItems":[{"title":"Amazon EKS で高負荷時に CoreDNS が原因で稀にネットワークエラーが発生していた時のトラブルシュート","content":"\u003cp\u003eソーシャルPLUS の開発チームでインフラエンジニア をやっています \u003ca href=\"http://blog.hatena.ne.jp/mayuki123/\" class=\"hatena-id-icon\"\u003e\u003cimg src=\"https://cdn.profile-image.st-hatena.com/users/mayuki123/profile.png\" width=\"16\" height=\"16\" alt=\"\" class=\"hatena-id-icon\"\u003eid:mayuki123\u003c/a\u003e です。今月からフィードフォースから分社化をした株式会社ソーシャルPLUS の所属となりましたが、仕事内容は変わらずにサービスのインフラ改善を進めていく事になるかと思います。\u003c/p\u003e\n\n\u003cp\u003e2019年11月に技術スタックを整理してみたという記事から2年弱経過していますが、ソーシャルPLUSのインフラ環境は、一部アプリケーションについてはコンテナ環境を Amazon EKS にホスティングして本番運用するようになりました。あと数ヶ月ほどで全ての環境がEC2からコンテナに置き換えられると良いなと思っています(願望)。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fdeveloper.feedforce.jp%2Fentry%2F2019%2F11%2F25%2F120000\" title=\"ソーシャルPLUS の技術スタックを整理してみた - Feedforce Developer Blog\" class=\"embed-card embed-blogcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 190px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://developer.feedforce.jp/entry/2019/11/25/120000\"\u003edeveloper.feedforce.jp\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eそして、既に利用されている機能の一部を Amazon EKS に移行して、しばらく経過した時にアプリケーションでネットワークエラーが稀に発生していました。原因調査をした結果が CoreDNS の負荷によるものと発覚するまでのトラブルシュートの流れについて、記事として書き残しておきます。\u003c/p\u003e\n\n\u003cul class=\"table-of-contents\"\u003e\n    \u003cli\u003e\u003ca href=\"#発生していた事象\"\u003e発生していた事象\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#Datadog-を活用した原因調査\"\u003eDatadog を活用した原因調査\u003c/a\u003e\u003cul\u003e\n            \u003cli\u003e\u003ca href=\"#アプリケーションの負荷状況\"\u003eアプリケーションの負荷状況\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#EKS-上のコンテナの調査\"\u003eEKS 上のコンテナの調査\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n    \u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#EKS-のCoreDNS-の調査\"\u003eEKS のCoreDNS の調査\u003c/a\u003e\u003cul\u003e\n            \u003cli\u003e\u003ca href=\"#CoreDNS-のデバッグログの有効化\"\u003eCoreDNS のデバッグログの有効化\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#Kubernetes-の名前解決について\"\u003eKubernetes の名前解決について\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n    \u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#CoreDNS-の負荷軽減\"\u003eCoreDNS の負荷軽減\u003c/a\u003e\u003cul\u003e\n            \u003cli\u003e\u003ca href=\"#ドメインの末尾にドット--を追加する\"\u003eドメインの末尾にドット (.) を追加する\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#etcresolvconf-で-ndots1-の設定をする\"\u003e/etc/resolv.conf で ndots:1 の設定をする\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#その他の-CoreDNS-の負荷軽減の方法\"\u003eその他の CoreDNS の負荷軽減の方法\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n    \u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#最終的な結果\"\u003e最終的な結果\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#おわりに\"\u003eおわりに\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#おまけ\"\u003eおまけ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"発生していた事象\"\u003e発生していた事象\u003c/h2\u003e\n\n\u003cp\u003eソーシャルPLUSでは、バックエンドのアプリケーションでエラーが発生した時に、Bugsnag を利用して Slack 通知するようにしています。ある時に\u003ccode\u003eMysql2::Error::ConnectionError\u003c/code\u003e が発生しました。単発のネットワークエラーの場合はアプリケーションがリトライする事でサービス影響がない事も多く、一時的な問題と思って静観する事があるかと思います。しかし、また数日後に同じ事象が発生しました。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/m/mayuki123/20210830/20210830152912.png\" alt=\"f:id:mayuki123:20210830152912p:plain\" width=\"667\" height=\"258\" loading=\"lazy\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://ja.wikipedia.org/wiki/%E3%83%8F%E3%82%A4%E3%83%B3%E3%83%AA%E3%83%83%E3%83%92%E3%81%AE%E6%B3%95%E5%89%87\"\u003eハインリッヒの1：29：300の法則\u003c/a\u003eのように、ちょっとした異常を見落としていると重大なサービス障害となってしまう可能性があるので、原因調査を始めます。\u003c/p\u003e\n\n\u003ch2 id=\"Datadog-を活用した原因調査\"\u003eDatadog を活用した原因調査\u003c/h2\u003e\n\n\u003cp\u003eソーシャルPLUSでは、モニタリングサービスの Datadog を利用しているのでメトリクスやログの調査を出来るようになっています。どこが原因かを探り始めました。\u003c/p\u003e\n\n\u003ch3 id=\"アプリケーションの負荷状況\"\u003eアプリケーションの負荷状況\u003c/h3\u003e\n\n\u003cp\u003eまずはアプリケーションで利用するサーバの負荷状況を確認する所から始めました。\u003ccode\u003eMysql2::Error::ConnectionError\u003c/code\u003e が発生した時刻は EKS の Node の CPU 使用率が 70% ほどで、アプリケーションで負荷のかかる処理の最中でした。また、データベースの負荷は少し前に負荷対策の改善をした事もあって、今回の事件の犯人ではなさそうです。他にもEC2 と DB 間でネットワークのボトルネックがないかなどの確認はしましたが、CPU 使用率が高い以外の問題は特に見つかりませんでした。完全犯罪でしょうか。\u003c/p\u003e\n\n\u003ch3 id=\"EKS-上のコンテナの調査\"\u003eEKS 上のコンテナの調査\u003c/h3\u003e\n\n\u003cp\u003eサーバ単体の問題ではないとすると、Amazon EKS で何か起きている事を疑うことにしました。EKSで動かしているコンテナのログは Datadog Logs に送っているので、\u003cstrong\u003eエラーが発生していたアプリケーション以外のログ\u003c/strong\u003e を確認していると、MySQL の ConnectionError が発生した時間帯に下記の Warning のメッセージが出ている事に気づきました。このログは Amazon Kinesis Data Firehose にログを送る Fluent Bit のコンテナで発生しており、エラーが発生してたアプリケーションとは異なるノードに存在してました。\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003e[yyyy/mm/dd hh:mm:ss] [ warn] [net] getaddrinfo(host='kinesis.ap-northeast-1.amazonaws.com'): Name or service not known\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003e同時刻に特定のアプリケーション以外のコンテナも影響を受けていることから、EKS の中で問題がありそうです。元々、EKSに関する技術ブログは目を通すようにしていた事もあり、Kubernetes の DNS の名前解決で問題が発生する場合があるというのは知っていたので、CoreDNSに焦点を当てて調べることにしました。アウトプットをしてくれる人たちには、いつも感謝をしています。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/cloutive/production-ready-eks-coredns-configuration-6fea830606f8\"\u003eProduction Ready EKS CoreDNS Configuration | by Serkan Capkan | Cloutive Technology Solutions - Tech Blog | Medium\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://creators-note.chatwork.com/entry/2021/01/05/104206#%E4%B8%80%E5%AE%9A%E6%95%B0%E3%81%AEPod%E4%BB%A5%E4%B8%8A%E3%81%AB%E3%81%AA%E3%82%8B%E3%81%A8%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%81%8C%E4%B8%8D%E5%AE%89%E5%AE%9A%E3%81%AB%E3%81%AA%E3%82%8B\"\u003eEKS\u0026#x3067;DNS\u0026#x3092;\u0026#x5B89;\u0026#x5B9A;\u0026#x3055;\u0026#x305B;\u0026#x308B;\u0026#x305F;\u0026#x3081;\u0026#x306B;\u0026#x5BFE;\u0026#x5FDC;\u0026#x3057;\u0026#x305F;\u0026#x3053;\u0026#x3068; - Chatwork Creator\u0026#39;s Note\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://labs.gree.jp/blog/2020/01/20271/\"\u003e\u0026#x30B9;\u0026#x30DE;\u0026#x30DB;\u0026#x30B2;\u0026#x30FC;\u0026#x30E0;\u0026#x306E; API \u0026#x30B5;\u0026#x30FC;\u0026#x30D0;\u0026#x306B;\u0026#x304A;\u0026#x3051;\u0026#x308B; EKS \u0026#x306E;\u0026#x904B;\u0026#x7528;\u0026#x4E8B;\u0026#x4F8B; | \u0026#x30A8;\u0026#x30F3;\u0026#x30B8;\u0026#x30CB;\u0026#x30A2;\u0026#x30D6;\u0026#x30ED;\u0026#x30B0; | GREE Engineering\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003ch2 id=\"EKS-のCoreDNS-の調査\"\u003eEKS のCoreDNS の調査\u003c/h2\u003e\n\n\u003cp\u003eDatadog Agent で Kurbernetes の各種メトリクスを収集していて、EKS の CoreDNS の状況も Datadog の Metric Explorer で確認する事が出来るようになっています。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://docs.datadoghq.com/ja/integrations/coredns/?tab=docker#%E3%83%A1%E3%83%88%E3%83%AA%E3%82%AF%E3%82%B9\"\u003eDatadog で取得可能な CoreDNS のメトリクス\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003e\u003ccode\u003ecoredns.request_count\u003c/code\u003e を確認すると特定の時間帯で CoreDNS へのリクエストが多い状態で、このタイミングでの CoreDNS Pod の CPU 負荷は10％前後でしたが、それ以外に不審なメトリクスは存在しませんでした。まだ事象の原因との確信は持てないですが、負荷がそれなりにかかっていることは確かなのでリクエストが多くなる理由を調べます。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/m/mayuki123/20210831/20210831151005.png\" alt=\"f:id:mayuki123:20210831151005p:plain\" width=\"522\" height=\"200\" loading=\"lazy\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003ch3 id=\"CoreDNS-のデバッグログの有効化\"\u003eCoreDNS のデバッグログの有効化\u003c/h3\u003e\n\n\u003cp\u003eまずは CoreDNS のデバッグログを確認したいとなるかと思いますが、EKS の CoreDNS はデフォルトだとデバッグログの出力がオフの状態のため、どのようなリクエストが到達しているのかは確認する事ができません。CoreDNS のログを有効化する方法は AWS のナレッジベースにある記事に方法が記載されています。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/premiumsupport/knowledge-center/eks-dns-failure/\"\u003eAmazon EKS \u0026#x3067;\u0026#x306E; DNS \u0026#x969C;\u0026#x5BB3;\u0026#x306E;\u0026#x30C8;\u0026#x30E9;\u0026#x30D6;\u0026#x30EB;\u0026#x30B7;\u0026#x30E5;\u0026#x30FC;\u0026#x30C6;\u0026#x30A3;\u0026#x30F3;\u0026#x30B0;\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eこの記事によると、Namespace(\u003ccode\u003ekube-system\u003c/code\u003e) に Configmap (\u003ccode\u003ecoredns\u003c/code\u003e) があるので、Corefile 設定に \u003ccode\u003elog\u003c/code\u003e を追加するとデバッグログ が出力されるようになります。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e# kubectl -n kube-system edit configmap coredns\nkind: ConfigMap\napiVersion: v1\ndata:\n  Corefile: |\n    .:53 {\n        log    # Enabling CoreDNS Logging\n        errors\n        health\n        kubernetes cluster.local in-addr.arpa ip6.arpa {\n          pods insecure\n          upstream\n          fallthrough in-addr.arpa ip6.arpa\n        }\n        ...\u003c/pre\u003e\n\n\n\u003cp\u003e上記の設定をすると CoreDNS のPod の標準出力にデバッグログ が出力されるようになります。私の触っていた EKS の環境の場合は、数分ほどで CoreDNS の Pod で reload が発生して元の設定（デバッグログ がオフ）に戻るようになってました。\u003c/p\u003e\n\n\u003ch3 id=\"Kubernetes-の名前解決について\"\u003eKubernetes の名前解決について\u003c/h3\u003e\n\n\u003cp\u003e次にKubernetes 上のコンテナはどのように名前解決するのかを知っておく必要があります。Kurbernetes の Pod の DNS リゾルバー(\u003ccode\u003e/etc/resolv.conf\u003c/code\u003e) のデフォルト設定は下記のようになっています。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e% kubectl exec fluent-bit-46zvl -- cat /etc/resolv.conf\nnameserver 172.20.0.10\nsearch logging.svc.cluster.local svc.cluster.local cluster.local\noptions ndots:5\u003c/pre\u003e\n\n\n\u003cp\u003eこの状態で Fluent Bit のコンテナから Amazon Kinesis の API エンドポイントに疎通する場合は、CoreDNS に8回のリクエストが発生します。これは、IPv4 , IPv6 の2種類の名前解決を \u003ccode\u003esearch\u003c/code\u003e の数だけ名前解決を試みた後で EKS 外に名前解決をする設定になっているからです。この設定になっているおかげで Kubernetes の Service を使った名前解決が出来るようになっています。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/m/mayuki123/20210831/20210831154909.png\" alt=\"f:id:mayuki123:20210831154909p:plain\" width=\"1200\" height=\"328\" loading=\"lazy\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003eまた、\u003ccode\u003eoptions ndots:5\u003c/code\u003e の設定は \u003ccode\u003e.\u003c/code\u003e の数が 5個以上の時は最初から外部に名前解決するようになります。そのため、Amazon Aurora や ElastiCache などのデータベースへの クラスターエンドポイントは \u003ccode\u003e.\u003c/code\u003e の数が五個以上あるので、CoreDNSへのリクエスト回数は少なくて済みます。ここを意識しなくてよいのはありがたいですね。\u003c/p\u003e\n\n\u003cp\u003eソーシャルPLUSというプロダクトの特性上、EKS 内のアプリケーションから外部サービスの API を実行する機会が多々あります。特定のタイミングで外部のサービスに大量のAPIリクエストを実行した際に、CoreDNS へのリクエストが増大してしまい不安定になってしまったのではと考えられます。\u003c/p\u003e\n\n\u003ch2 id=\"CoreDNS-の負荷軽減\"\u003eCoreDNS の負荷軽減\u003c/h2\u003e\n\n\u003cp\u003eKurbernetes 上のコンテナの名前解決を知ると、外部サービスのAPI を実行する際には CoreDNS へのリクエストが多くなる事が分かりました。ここで、CoreDNS へのリクエスト数を減らす方法は下記の二つがあります。これも AWS のナレッジベースに方法が記載されているので、詳細は下記の記事を読む方が良いと思います。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/premiumsupport/knowledge-center/eks-dns-failure/\"\u003eAmazon EKS \u0026#x3067;\u0026#x306E; DNS \u0026#x969C;\u0026#x5BB3;\u0026#x306E;\u0026#x30C8;\u0026#x30E9;\u0026#x30D6;\u0026#x30EB;\u0026#x30B7;\u0026#x30E5;\u0026#x30FC;\u0026#x30C6;\u0026#x30A3;\u0026#x30F3;\u0026#x30B0;\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003ch3 id=\"ドメインの末尾にドット--を追加する\"\u003eドメインの末尾にドット (.) を追加する\u003c/h3\u003e\n\n\u003cp\u003e接続先のドメインの最後に \u003ccode\u003e.\u003c/code\u003e をつけると、EKS の内部で名前解決を複数回しないようになり、CoreDNS へのリクエストの総数が減ります。一例をあげると、\u003ccode\u003eexample.com\u003c/code\u003e ではなく、 \u003ccode\u003eexample.com.\u003c/code\u003e とする事で最初から EKS の外部に名前解決をしてくれるようになります。ドメインが SDK の内部で定義されているような場合など、変更出来ない場合はこの方法は利用出来ないかと思います。\u003c/p\u003e\n\n\u003ch3 id=\"etcresolvconf-で-ndots1-の設定をする\"\u003e\u003ccode\u003e/etc/resolv.conf\u003c/code\u003e で ndots:1 の設定をする\u003c/h3\u003e\n\n\u003cp\u003e\u003ccode\u003e/etc/resolv.conf\u003c/code\u003e に \u003ccode\u003eoptions ndots:5\u003c/code\u003e とデフォルトで設定されている数値を \u003ccode\u003e1\u003c/code\u003e にする事で、ドメインに \u003ccode\u003e.\u003c/code\u003e が含まれている場合は常に EKS の外部に名前解決するようになります。Kubernetes の Manifest に \u003ccode\u003espec.dnsConfig\u003c/code\u003e パラメータを設定する事で Pod 単位で変更が出来ます。ただし、この設定をすると EKS 内部で名前解決をしなくなってしまいますが、\u003ccode\u003e\u0026lt;name\u0026gt;.\u0026lt;namespace\u0026gt;.svc.cluster.local.\u003c/code\u003e のように最後に \u003ccode\u003e.\u003c/code\u003e をつけると名前解決出来ました。Kurbernetes の Service の数が多いとこの方法を周知させるのも大変だと思います。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003eapiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hoge\nspec:\n  template:\n    spec:\n      dnsConfig:\n        options:\n          - name: ndots\n            value: \u0026#34;1\u0026#34;\u003c/pre\u003e\n\n\n\u003ch3 id=\"その他の-CoreDNS-の負荷軽減の方法\"\u003eその他の CoreDNS の負荷軽減の方法\u003c/h3\u003e\n\n\u003cp\u003e上記の二つの方法は CoreDNS へのリクエスト数を減らすことで、負荷を軽減するようなアプローチでした。CoreDNS の Pod 数はデフォルトで 2個となりますが、CoreDNS のPod をオートスケールする手段もあります。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/docs/tasks/administer-cluster/dns-horizontal-autoscaling/\"\u003eAutoscale the DNS Service in a Cluster\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eまた、Daemonset で DNS キャッシュをノード単位で配置するという方法もあります。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/tasks/administer-cluster/nodelocaldns/\"\u003eKubernetesクラスターでNodeLocal DNSキャッシュを使用する\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eこの辺りは他の方が書いた技術ブログも多くあるかと思うので、この記事では特に説明はしないです。\u003c/p\u003e\n\n\u003ch2 id=\"最終的な結果\"\u003e最終的な結果\u003c/h2\u003e\n\n\u003cp\u003eソーシャルPLUSでは最終的に根本原因の CoreDNS へのリクエスト数を減らすために \u003ccode\u003e/etc/resolv.conf\u003c/code\u003e で \u003ccode\u003endots:1\u003c/code\u003e の設定をするようにしました。この設定をアプリケーションの Pod に適応した所、CoreDNS へのリクエスト数は 25% ほどと目に見えて減少させる事が出来ました。キャプチャは載せてないですが、CoreDNS の Pod の CPU使用率も 以前の半分ほどになったので、負荷軽減の目的は達成しました。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/m/mayuki123/20210831/20210831171734.png\" alt=\"f:id:mayuki123:20210831171734p:plain\" width=\"527\" height=\"187\" loading=\"lazy\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003eここまで、確信を持てないまま CoreDNS の負荷軽減に取り組みましたが、元々のネットワークエラーであった \u003ccode\u003eMysql2::Error::ConnectionError\u003c/code\u003e のエラーは再発しなくなりました。また、EKS 上の他のコンテナも \u003ccode\u003eName or service not known\u003c/code\u003e のような名前解決が出来ないといったエラーも発生しなくなりました。CoreDNS の負荷を減らす事で悩まされていた問題の解消が出来たと思います。今回のように比較的早い段階で気づく事が出来たので、お客さんへのサービス影響のある問題に発展せずに済みました。\u003c/p\u003e\n\n\u003cp\u003e今後、利用者数が増えてより負荷のかかる状況になってきた時には再発する可能性はありますが、早い段階で気付けるように日々確認するダッシュボードにメトリクスを追加するようにしています。その時がきた場合は CoreDNS の Pod 数の調整や DNS キャッシュの導入が必要になりそうです。\u003c/p\u003e\n\n\u003ch2 id=\"おわりに\"\u003eおわりに\u003c/h2\u003e\n\n\u003cp\u003e最終的には Pod の DNS 設定を調整するだけでネットワークエラーは解決しました。この記事では、結果だけではなくて解決に至るまでの経緯をメインにまとめてみました。実施していて良かったと思うことを下記にまとめます。これらの事が出来ていなければ、今回のようなネットワークエラーはたまに発生する事象として、根本原因の追及は出来なかったと思うので、サービスのオブザーバビリティを整備する事や日々の情報収集は大事ですね。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eアプリケーションのエラーを Slack に通知していた\u003c/li\u003e\n\u003cli\u003eKurbernetes のメトリクスを Datadog で確認できる状態だった\u003c/li\u003e\n\u003cli\u003eコンテナのログを一元的に Datadog Logs  で閲覧できるようにしていた\u003c/li\u003e\n\u003cli\u003e他の人の技術ブログから Kubernetes の CoreDNS が不安定になることを知っていた\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eこの記事に間違っている内容や、もっと良い改善方法がある事をご存知の方がいましたら、優しく教えてください。\u003c/p\u003e\n\n\u003ch2 id=\"おまけ\"\u003eおまけ\u003c/h2\u003e\n\n\u003cp\u003e現在、ソーシャルPLUS では作りたい機能が山ほどある状況でまだまだ成長するサービスになると思うので、成長を続けるサービスに携わりたいエンジニアやデザイナーのご応募をお待ちしております！サイトにはまだないですが、インフラエンジニアも近いうちに募集をする事にはなると思います。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fopen.talentio.com%2F1%2Fc%2Ffeedforce%2Frequisitions%2Fdetail%2F21802\" title=\"Railsエンジニア【Shopify App開発/ID連携サービス】 / 株式会社フィードフォース\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://open.talentio.com/1/c/feedforce/requisitions/detail/21802\"\u003eopen.talentio.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fopen.talentio.com%2F1%2Fc%2Ffeedforce%2Frequisitions%2Fdetail%2F21755\" title=\"フロントエンドエンジニア【Shopifyアプリ開発/ID連携サービス/React/TypeScript】 / 株式会社フィードフォース\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://open.talentio.com/1/c/feedforce/requisitions/detail/21755\"\u003eopen.talentio.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fopen.talentio.com%2F1%2Fc%2Ffeedforce%2Frequisitions%2Fdetail%2F21760\" title=\"UI/UXデザイナー【ID連携サービス/マーケティング支援SaaS】 / 株式会社フィードフォース\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://open.talentio.com/1/c/feedforce/requisitions/detail/21760\"\u003eopen.talentio.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eフィードフォース の他のサービスもエンジニアを募集してますので、興味があればご応募お待ちしております！\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fengineers.recruit.feedforce.jp%2F%3F_ga%3D2.157559610.1029003260.1630297434-1923366822.1626416415%23entry\" title=\"フィードフォース エンジニア・デザイナー採用サイト\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://engineers.recruit.feedforce.jp/?_ga=2.157559610.1029003260.1630297434-1923366822.1626416415#entry\"\u003eengineers.recruit.feedforce.jp\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n","contentSnippet":"ソーシャルPLUS の開発チームでインフラエンジニア をやっています id:mayuki123 です。今月からフィードフォースから分社化をした株式会社ソーシャルPLUS の所属となりましたが、仕事内容は変わらずにサービスのインフラ改善を進めていく事になるかと思います。2019年11月に技術スタックを整理してみたという記事から2年弱経過していますが、ソーシャルPLUSのインフラ環境は、一部アプリケーションについてはコンテナ環境を Amazon EKS にホスティングして本番運用するようになりました。あと数ヶ月ほどで全ての環境がEC2からコンテナに置き換えられると良いなと思っています(願望)。developer.feedforce.jpそして、既に利用されている機能の一部を Amazon EKS に移行して、しばらく経過した時にアプリケーションでネットワークエラーが稀に発生していました。原因調査をした結果が CoreDNS の負荷によるものと発覚するまでのトラブルシュートの流れについて、記事として書き残しておきます。発生していた事象Datadog を活用した原因調査アプリケーションの負荷状況EKS 上のコンテナの調査EKS のCoreDNS の調査CoreDNS のデバッグログの有効化Kubernetes の名前解決についてCoreDNS の負荷軽減ドメインの末尾にドット (.) を追加する/etc/resolv.conf で ndots:1 の設定をするその他の CoreDNS の負荷軽減の方法最終的な結果おわりにおまけ発生していた事象ソーシャルPLUSでは、バックエンドのアプリケーションでエラーが発生した時に、Bugsnag を利用して Slack 通知するようにしています。ある時にMysql2::Error::ConnectionError が発生しました。単発のネットワークエラーの場合はアプリケーションがリトライする事でサービス影響がない事も多く、一時的な問題と思って静観する事があるかと思います。しかし、また数日後に同じ事象が発生しました。ハインリッヒの1：29：300の法則のように、ちょっとした異常を見落としていると重大なサービス障害となってしまう可能性があるので、原因調査を始めます。Datadog を活用した原因調査ソーシャルPLUSでは、モニタリングサービスの Datadog を利用しているのでメトリクスやログの調査を出来るようになっています。どこが原因かを探り始めました。アプリケーションの負荷状況まずはアプリケーションで利用するサーバの負荷状況を確認する所から始めました。Mysql2::Error::ConnectionError が発生した時刻は EKS の Node の CPU 使用率が 70% ほどで、アプリケーションで負荷のかかる処理の最中でした。また、データベースの負荷は少し前に負荷対策の改善をした事もあって、今回の事件の犯人ではなさそうです。他にもEC2 と DB 間でネットワークのボトルネックがないかなどの確認はしましたが、CPU 使用率が高い以外の問題は特に見つかりませんでした。完全犯罪でしょうか。EKS 上のコンテナの調査サーバ単体の問題ではないとすると、Amazon EKS で何か起きている事を疑うことにしました。EKSで動かしているコンテナのログは Datadog Logs に送っているので、エラーが発生していたアプリケーション以外のログ を確認していると、MySQL の ConnectionError が発生した時間帯に下記の Warning のメッセージが出ている事に気づきました。このログは Amazon Kinesis Data Firehose にログを送る Fluent Bit のコンテナで発生しており、エラーが発生してたアプリケーションとは異なるノードに存在してました。[yyyy/mm/dd hh:mm:ss] [ warn] [net] getaddrinfo(host='kinesis.ap-northeast-1.amazonaws.com'): Name or service not known同時刻に特定のアプリケーション以外のコンテナも影響を受けていることから、EKS の中で問題がありそうです。元々、EKSに関する技術ブログは目を通すようにしていた事もあり、Kubernetes の DNS の名前解決で問題が発生する場合があるというのは知っていたので、CoreDNSに焦点を当てて調べることにしました。アウトプットをしてくれる人たちには、いつも感謝をしています。Production Ready EKS CoreDNS Configuration | by Serkan Capkan | Cloutive Technology Solutions - Tech Blog | MediumEKSでDNSを安定させるために対応したこと - Chatwork Creator's Noteスマホゲームの API サーバにおける EKS の運用事例 | エンジニアブログ | GREE EngineeringEKS のCoreDNS の調査Datadog Agent で Kurbernetes の各種メトリクスを収集していて、EKS の CoreDNS の状況も Datadog の Metric Explorer で確認する事が出来るようになっています。Datadog で取得可能な CoreDNS のメトリクスcoredns.request_count を確認すると特定の時間帯で CoreDNS へのリクエストが多い状態で、このタイミングでの CoreDNS Pod の CPU 負荷は10％前後でしたが、それ以外に不審なメトリクスは存在しませんでした。まだ事象の原因との確信は持てないですが、負荷がそれなりにかかっていることは確かなのでリクエストが多くなる理由を調べます。CoreDNS のデバッグログの有効化まずは CoreDNS のデバッグログを確認したいとなるかと思いますが、EKS の CoreDNS はデフォルトだとデバッグログの出力がオフの状態のため、どのようなリクエストが到達しているのかは確認する事ができません。CoreDNS のログを有効化する方法は AWS のナレッジベースにある記事に方法が記載されています。Amazon EKS での DNS 障害のトラブルシューティングこの記事によると、Namespace(kube-system) に Configmap (coredns) があるので、Corefile 設定に log を追加するとデバッグログ が出力されるようになります。# kubectl -n kube-system edit configmap corednskind: ConfigMapapiVersion: v1data:  Corefile: |    .:53 {        log    # Enabling CoreDNS Logging        errors        health        kubernetes cluster.local in-addr.arpa ip6.arpa {          pods insecure          upstream          fallthrough in-addr.arpa ip6.arpa        }        ...上記の設定をすると CoreDNS のPod の標準出力にデバッグログ が出力されるようになります。私の触っていた EKS の環境の場合は、数分ほどで CoreDNS の Pod で reload が発生して元の設定（デバッグログ がオフ）に戻るようになってました。Kubernetes の名前解決について次にKubernetes 上のコンテナはどのように名前解決するのかを知っておく必要があります。Kurbernetes の Pod の DNS リゾルバー(/etc/resolv.conf) のデフォルト設定は下記のようになっています。% kubectl exec fluent-bit-46zvl -- cat /etc/resolv.confnameserver 172.20.0.10search logging.svc.cluster.local svc.cluster.local cluster.localoptions ndots:5この状態で Fluent Bit のコンテナから Amazon Kinesis の API エンドポイントに疎通する場合は、CoreDNS に8回のリクエストが発生します。これは、IPv4 , IPv6 の2種類の名前解決を search の数だけ名前解決を試みた後で EKS 外に名前解決をする設定になっているからです。この設定になっているおかげで Kubernetes の Service を使った名前解決が出来るようになっています。また、options ndots:5 の設定は . の数が 5個以上の時は最初から外部に名前解決するようになります。そのため、Amazon Aurora や ElastiCache などのデータベースへの クラスターエンドポイントは . の数が五個以上あるので、CoreDNSへのリクエスト回数は少なくて済みます。ここを意識しなくてよいのはありがたいですね。ソーシャルPLUSというプロダクトの特性上、EKS 内のアプリケーションから外部サービスの API を実行する機会が多々あります。特定のタイミングで外部のサービスに大量のAPIリクエストを実行した際に、CoreDNS へのリクエストが増大してしまい不安定になってしまったのではと考えられます。CoreDNS の負荷軽減Kurbernetes 上のコンテナの名前解決を知ると、外部サービスのAPI を実行する際には CoreDNS へのリクエストが多くなる事が分かりました。ここで、CoreDNS へのリクエスト数を減らす方法は下記の二つがあります。これも AWS のナレッジベースに方法が記載されているので、詳細は下記の記事を読む方が良いと思います。Amazon EKS での DNS 障害のトラブルシューティングドメインの末尾にドット (.) を追加する接続先のドメインの最後に . をつけると、EKS の内部で名前解決を複数回しないようになり、CoreDNS へのリクエストの総数が減ります。一例をあげると、example.com ではなく、 example.com. とする事で最初から EKS の外部に名前解決をしてくれるようになります。ドメインが SDK の内部で定義されているような場合など、変更出来ない場合はこの方法は利用出来ないかと思います。/etc/resolv.conf で ndots:1 の設定をする/etc/resolv.conf に options ndots:5 とデフォルトで設定されている数値を 1 にする事で、ドメインに . が含まれている場合は常に EKS の外部に名前解決するようになります。Kubernetes の Manifest に spec.dnsConfig パラメータを設定する事で Pod 単位で変更が出来ます。ただし、この設定をすると EKS 内部で名前解決をしなくなってしまいますが、\u003cname\u003e.\u003cnamespace\u003e.svc.cluster.local. のように最後に . をつけると名前解決出来ました。Kurbernetes の Service の数が多いとこの方法を周知させるのも大変だと思います。apiVersion: apps/v1kind: Deploymentmetadata:  name: hogespec:  template:    spec:      dnsConfig:        options:          - name: ndots            value: \"1\"その他の CoreDNS の負荷軽減の方法上記の二つの方法は CoreDNS へのリクエスト数を減らすことで、負荷を軽減するようなアプローチでした。CoreDNS の Pod 数はデフォルトで 2個となりますが、CoreDNS のPod をオートスケールする手段もあります。Autoscale the DNS Service in a Clusterまた、Daemonset で DNS キャッシュをノード単位で配置するという方法もあります。KubernetesクラスターでNodeLocal DNSキャッシュを使用するこの辺りは他の方が書いた技術ブログも多くあるかと思うので、この記事では特に説明はしないです。最終的な結果ソーシャルPLUSでは最終的に根本原因の CoreDNS へのリクエスト数を減らすために /etc/resolv.conf で ndots:1 の設定をするようにしました。この設定をアプリケーションの Pod に適応した所、CoreDNS へのリクエスト数は 25% ほどと目に見えて減少させる事が出来ました。キャプチャは載せてないですが、CoreDNS の Pod の CPU使用率も 以前の半分ほどになったので、負荷軽減の目的は達成しました。ここまで、確信を持てないまま CoreDNS の負荷軽減に取り組みましたが、元々のネットワークエラーであった Mysql2::Error::ConnectionError のエラーは再発しなくなりました。また、EKS 上の他のコンテナも Name or service not known のような名前解決が出来ないといったエラーも発生しなくなりました。CoreDNS の負荷を減らす事で悩まされていた問題の解消が出来たと思います。今回のように比較的早い段階で気づく事が出来たので、お客さんへのサービス影響のある問題に発展せずに済みました。今後、利用者数が増えてより負荷のかかる状況になってきた時には再発する可能性はありますが、早い段階で気付けるように日々確認するダッシュボードにメトリクスを追加するようにしています。その時がきた場合は CoreDNS の Pod 数の調整や DNS キャッシュの導入が必要になりそうです。おわりに最終的には Pod の DNS 設定を調整するだけでネットワークエラーは解決しました。この記事では、結果だけではなくて解決に至るまでの経緯をメインにまとめてみました。実施していて良かったと思うことを下記にまとめます。これらの事が出来ていなければ、今回のようなネットワークエラーはたまに発生する事象として、根本原因の追及は出来なかったと思うので、サービスのオブザーバビリティを整備する事や日々の情報収集は大事ですね。アプリケーションのエラーを Slack に通知していたKurbernetes のメトリクスを Datadog で確認できる状態だったコンテナのログを一元的に Datadog Logs  で閲覧できるようにしていた他の人の技術ブログから Kubernetes の CoreDNS が不安定になることを知っていたこの記事に間違っている内容や、もっと良い改善方法がある事をご存知の方がいましたら、優しく教えてください。おまけ現在、ソーシャルPLUS では作りたい機能が山ほどある状況でまだまだ成長するサービスになると思うので、成長を続けるサービスに携わりたいエンジニアやデザイナーのご応募をお待ちしております！サイトにはまだないですが、インフラエンジニアも近いうちに募集をする事にはなると思います。open.talentio.comopen.talentio.comopen.talentio.comフィードフォース の他のサービスもエンジニアを募集してますので、興味があればご応募お待ちしております！engineers.recruit.feedforce.jp","link":"https://developer.feedforce.jp/entry/2021/09/02/134725","isoDate":"2021-09-02T04:47:25.000Z","dateMiliSeconds":1630558045000,"imageUrl":"https://cdn.user.blog.st-hatena.com/default_entry_og_image/4268819/1588226000876991","authorName":"feedforce"},{"title":"Firestore エミュレーターを使ったテスト同士の競合が起きないようにしていい感じにテストできるようにした話","content":"\u003cp\u003eこんにちは、エンジニアの \u003ca href=\"http://blog.hatena.ne.jp/len_prog/\" class=\"hatena-id-icon\"\u003e\u003cimg src=\"https://cdn.profile-image.st-hatena.com/users/len_prog/profile.png\" width=\"16\" height=\"16\" alt=\"\" class=\"hatena-id-icon\"\u003eid:len_prog\u003c/a\u003e です。\u003c/p\u003e\n\n\u003cp\u003e私が所属している \u003ca href=\"https://ecbooster.jp/\"\u003eEC Booster\u003c/a\u003e チームでは、「\u003ca href=\"https://support.ecbooster.jp/ja/articles/4854572-%E3%82%AB%E3%82%A4%E3%82%BC%E3%83%B3%E3%82%AB%E3%83%BC%E3%83%89%E3%81%AE%E6%A6%82%E8%A6%81%E3%81%A8%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6\"\u003eカイゼンカード\u003c/a\u003e」機能の開発に Firebase を採用しています。\u003cbr /\u003e\nその中でも特に Cloud Functions for Firebase と Cloud Firestore をメインで使用しており、これらの採用により短い開発期間で機能をリリースすることができました 🎉\u003c/p\u003e\n\n\u003cp\u003eしかし、Firebase を採用したことで苦労したことが全く無かったわけではありません。\u003cbr /\u003e\n特に、テスト周りはインターネット上にもあまり情報が多くない状況で、色々ハマりながら開発をしてきました。\u003c/p\u003e\n\n\u003cp\u003eそこで、今回の記事では、いくつかあったハマりごとの中でも特に厄介だったものについて対策を書いていきます。\u003c/p\u003e\n\n\u003ch1\u003eFirestore Emulator のプロジェクト共有時のデータ競合\u003c/h1\u003e\n\n\u003cp\u003e\u003ca href=\"https://firebase.google.com/docs/emulator-suite?hl=ja\"\u003eFirebase Local Emulator Suite\u003c/a\u003e を使って Firestore に接続するテストを書いていた際に、\u003cbr /\u003e\nテストを単体で実行した場合には通るのに、他のテストと並列に実行した場合のみドキュメントの状態が予期せぬものになりテストが落ちてしまうことに悩まされました。\u003c/p\u003e\n\n\u003cp\u003e調査の結果、これは、接続先プロジェクトがすべてのテストで同じになってしまっているのが原因ということが分かりました。\u003c/p\u003e\n\n\u003cp\u003eこの状態で同じドキュメントを書き換えるテストが並列で走ってしまった場合、実行タイミングによってはドキュメントが予期せぬ状態になってしまいます。\u003cbr /\u003e\nまた、テスト結果が不安定だとテストが信用できず、実装を保証するものになりません。\u003c/p\u003e\n\n\u003cp\u003eこのままでは役に立つテストが書けないと思い試行錯誤した結果、\u003cstrong\u003eテストごとに違うプロジェクトの Firestore に接続する\u003c/strong\u003eことでそれぞれのテストが独立した状態で実行でき、結果としてデータ競合が防げることが分かりました。\u003c/p\u003e\n\n\u003cp\u003e以下、サンプルアプリケーションを用いてこの方法について書いていきます。\u003c/p\u003e\n\n\u003ch1\u003eサンプルアプリケーションの概要\u003c/h1\u003e\n\n\u003cp\u003e今回は、サンプルとして簡易的な RPG を開発することを想定します。\u003cbr /\u003e\nゲームに登場するキャラクターは、以下のような構造のドキュメントを持つ \u003ccode\u003echaracters\u003c/code\u003e コレクションで管理されています。\u003c/p\u003e\n\n\u003cpre class=\"code lang-typescript\" data-lang=\"typescript\" data-unlink\u003e\u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n  name: \u003cspan class=\"synType\"\u003estring\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n  level: \u003cspan class=\"synType\"\u003enumber\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n  job: \u003cspan class=\"synType\"\u003estring\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003eまた、このゲームでは以下の行動のみが可能と仮定します(これだけじゃゲームとして成り立たないと思いますが、簡単のためということでお許しください)\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eキャラクターは、レベルアップすることができる\u003c/li\u003e\n\u003cli\u003eキャラクターは、転職することができる\n\n\u003cul\u003e\n\u003cli\u003e転職すると、キャラクターのレベルが1に戻る\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eなお、アプリケーション上においてキャラクターのレベルアップは、\u003ccode\u003echaracterLevelUpUseCase\u003c/code\u003e、キャラクターの転職は \u003ccode\u003echaracterJobChangeUseCase\u003c/code\u003e という関数を呼ぶことで行えることとします。\u003c/p\u003e\n\n\u003cp\u003eここからは、実際にこれら2つの関数のテストコードが競合する様子を見ていきます。\u003c/p\u003e\n\n\u003ch1\u003eデータ競合発生時の構成\u003c/h1\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/l/len_prog/20210624/20210624165133.png\" alt=\"f:id:len_prog:20210624165133p:plain:w500\" width=\"1200\" height=\"790\" loading=\"lazy\" title=\"\" class=\"hatena-fotolife\" style=\"width:500px\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003echaracterJobChangeUseCase\u003c/code\u003e と \u003ccode\u003echaracterLevelUpUseCase\u003c/code\u003e が \u003ccode\u003emy-game\u003c/code\u003e プロジェクトの Firestore を共有してしまっています。\u003cbr /\u003e\nこの状態で両方の関数から同じドキュメントを書き換えてしまった場合、データ競合が発生する可能性があります。\u003cbr /\u003e\nこの場合、実際のコードは以下のようになります。\u003c/p\u003e\n\n\u003cpre class=\"code lang-typescript\" data-lang=\"typescript\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e// functions/src/usecases/characterJobChangeUseCase.spec.ts\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003eimport\u003c/span\u003e * \u003cspan class=\"synStatement\"\u003eas\u003c/span\u003e admin \u003cspan class=\"synStatement\"\u003efrom\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e\u0026quot;firebase-admin\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003eimport\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e characterJobChangeUseCase \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e \u003cspan class=\"synStatement\"\u003efrom\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e\u0026quot;@/usecases/characterJobChangeUseCase\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n\nadmin.initializeApp\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n  projectId: \u003cspan class=\"synConstant\"\u003e\u0026quot;my-game\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e \u003cspan class=\"synComment\"\u003e// ここが問題\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\n\u003cspan class=\"synStatement\"\u003econst\u003c/span\u003e charactersCollection \u003cspan class=\"synStatement\"\u003e=\u003c/span\u003e admin\n  .firestore\u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e\n  .collection\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e\u0026quot;characters\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\ndescribe\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003echaracterJobChangeUseCase\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003econst\u003c/span\u003e targetCharacterId \u003cspan class=\"synStatement\"\u003e=\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e\u0026quot;target-character-id\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n\n  beforeEach\u003cspan class=\"synStatement\"\u003e(async\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003eawait\u003c/span\u003e charactersCollection.doc\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.set\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n        name: \u003cspan class=\"synConstant\"\u003e\u0026quot;アルス\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e\n        level: \u003cspan class=\"synConstant\"\u003e10\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e\n        job: \u003cspan class=\"synConstant\"\u003e\u0026quot;すっぴん\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\n  afterEach\u003cspan class=\"synStatement\"\u003e(async\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003eawait\u003c/span\u003e charactersCollection.doc\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.\u003cspan class=\"synStatement\"\u003edelete();\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\n  it\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e\u0026quot;キャラクターが転職した場合、レベルが1に戻ること\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e \u003cspan class=\"synStatement\"\u003easync\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003eawait\u003c/span\u003e characterJobChangeUseCase\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e \u003cspan class=\"synComment\"\u003e// characterJobChangeUsecase#handle に渡された引数の ID を持つユーザーのレベルが1に戻る\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003econst\u003c/span\u003e jobChangedCharacter \u003cspan class=\"synStatement\"\u003e=\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e(await\u003c/span\u003e charactersCollection.doc\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.get\u003cspan class=\"synStatement\"\u003e())\u003c/span\u003e.data\u003cspan class=\"synStatement\"\u003e();\u003c/span\u003e\n\n    expect\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003ejobChangedCharacter.level\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.toBe\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e \u003cspan class=\"synComment\"\u003e// 実行タイミング次第では、1になるはずが11になってしまう！\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\n\n\u003cpre class=\"code lang-typescript\" data-lang=\"typescript\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e// functions/src/usecases/characterLevelUpUseCase.spec.ts\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003eimport\u003c/span\u003e * \u003cspan class=\"synStatement\"\u003eas\u003c/span\u003e admin \u003cspan class=\"synStatement\"\u003efrom\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e\u0026quot;firebase-admin\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003eimport\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e characterLevelUpUseCase \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e \u003cspan class=\"synStatement\"\u003efrom\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e\u0026quot;@/usecases/characterLevelUpUseCase\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n\nadmin.initializeApp\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n  projectId: \u003cspan class=\"synConstant\"\u003e\u0026quot;my-game\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e \u003cspan class=\"synComment\"\u003e// ここが問題\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\n\u003cspan class=\"synStatement\"\u003econst\u003c/span\u003e charactersCollection \u003cspan class=\"synStatement\"\u003e=\u003c/span\u003e admin\n  .firestore\u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e\n  .collection\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e\u0026quot;characters\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\ndescribe\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003echaracterLevelUpUseCase\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003econst\u003c/span\u003e targetCharacterId \u003cspan class=\"synStatement\"\u003e=\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e\u0026quot;target-character-id\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n\n  beforeEach\u003cspan class=\"synStatement\"\u003e(async\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003eawait\u003c/span\u003e charactersCollection.doc\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.set\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n        name: \u003cspan class=\"synConstant\"\u003e\u0026quot;アルス\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e\n        level: \u003cspan class=\"synConstant\"\u003e10\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e\n        job: \u003cspan class=\"synConstant\"\u003e\u0026quot;すっぴん\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\n  afterEach\u003cspan class=\"synStatement\"\u003e(async\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003eawait\u003c/span\u003e charactersCollection.doc\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.\u003cspan class=\"synStatement\"\u003edelete();\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\n  it\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e\u0026quot;キャラクターがレベルアップした場合、レベルが1上がること\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e \u003cspan class=\"synStatement\"\u003easync\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003eawait\u003c/span\u003e characterLevelUpUseCase\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e \u003cspan class=\"synComment\"\u003e// characterJobChangeUsecase#handle に渡された引数の ID を持つユーザーのレベルが1上がる\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003econst\u003c/span\u003e grownCharacter \u003cspan class=\"synStatement\"\u003e=\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e(await\u003c/span\u003e charactersCollection.doc\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.get\u003cspan class=\"synStatement\"\u003e())\u003c/span\u003e.data\u003cspan class=\"synStatement\"\u003e();\u003c/span\u003e\n\n    expect\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003egrownCharacter.level\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.toBe\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e11\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e \u003cspan class=\"synComment\"\u003e// 実行タイミング次第では、11になるはずが1に戻ってしまう！\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003e見ての通り、両方のテストが \u003ccode\u003emy-game\u003c/code\u003e プロジェクトの Firestore の、ID: \u003ccode\u003etarget-character-id\u003c/code\u003e のドキュメントを更新してしまっています。\u003cbr /\u003e\nこれらのテストコードを並列で実行した場合、\u003cstrong\u003eキャラクターが転職したのにレベルが1に戻らない\u003c/strong\u003e、\u003cstrong\u003eキャラクターがレベルアップしたはずなのになぜかレベル1に戻ってしまう\u003c/strong\u003eなど予期せぬ状態になってしまい、\nテストが落ちてしまう可能性があります。\u003c/p\u003e\n\n\u003cp\u003eこの状態ではテストコードが信用できないので、テストごとに向き先プロジェクトを変えてこの問題を解決していきます。\u003c/p\u003e\n\n\u003ch1\u003eデータ競合解決後の構成\u003c/h1\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/l/len_prog/20210705/20210705113933.png\" alt=\"f:id:len_prog:20210705113933p:plain:w500\" width=\"1200\" height=\"779\" loading=\"lazy\" title=\"\" class=\"hatena-fotolife\" style=\"width:500px\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003e上図②③のようにテストごとに接続先プロジェクトを独立させることで、他のテストとの並列実行が原因のデータ競合を防ぐことができます。\u003cbr /\u003e\n具体的には、以下のように \u003ccode\u003eadmin.initializeApp()\u003c/code\u003eの第一引数に他のテストと重複しないプロジェクトID を渡すようにします。\u003c/p\u003e\n\n\u003cpre class=\"code lang-typescript\" data-lang=\"typescript\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e// functions/src/usecases/characterJobChangeUseCase.spec.ts\u003c/span\u003e\n\nadmin.initializeApp\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n  projectId: \u003cspan class=\"synConstant\"\u003e\u0026quot;character-job-change-use-case-spec\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e \u003cspan class=\"synComment\"\u003e//  図の②に対応\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\n\u003cspan class=\"synComment\"\u003e// functions/src/usecases/characterLevelUpUseCase.spec.ts\u003c/span\u003e\n\nadmin.initializeApp\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n  projectId: \u003cspan class=\"synConstant\"\u003e\u0026quot;character-level-up-use-case-spec\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e \u003cspan class=\"synComment\"\u003e// 図の③に対応\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003e変更後のコードの全体像は以下のようになります。\u003c/p\u003e\n\n\u003cpre class=\"code lang-typescript\" data-lang=\"typescript\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e// functions/src/usecases/characterJobChangeUseCase.spec.ts\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003eimport\u003c/span\u003e * \u003cspan class=\"synStatement\"\u003eas\u003c/span\u003e admin \u003cspan class=\"synStatement\"\u003efrom\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e\u0026quot;firebase-admin\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003eimport\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e characterJobChangeUseCase \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e \u003cspan class=\"synStatement\"\u003efrom\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e\u0026quot;@/usecases/characterJobChangeUseCase\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n\nadmin.initializeApp\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n  projectId: \u003cspan class=\"synConstant\"\u003e\u0026quot;character-job-change-use-case-spec\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e \u003cspan class=\"synComment\"\u003e//  図の②に対応\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\n\u003cspan class=\"synComment\"\u003e// ここから下は構成変更前のコードと同じ\u003c/span\u003e\n\n\u003cspan class=\"synStatement\"\u003econst\u003c/span\u003e charactersCollection \u003cspan class=\"synStatement\"\u003e=\u003c/span\u003e admin\n  .firestore\u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e\n  .collection\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e\u0026quot;characters\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\ndescribe\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003echaracterJobChangeUseCase\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003econst\u003c/span\u003e targetCharacterId \u003cspan class=\"synStatement\"\u003e=\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e\u0026quot;target-character-id\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n\n  beforeEach\u003cspan class=\"synStatement\"\u003e(async\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003eawait\u003c/span\u003e charactersCollection.doc\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.set\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n        name: \u003cspan class=\"synConstant\"\u003e\u0026quot;アルス\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e\n        level: \u003cspan class=\"synConstant\"\u003e10\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e\n        job: \u003cspan class=\"synConstant\"\u003e\u0026quot;すっぴん\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\n  afterEach\u003cspan class=\"synStatement\"\u003e(async\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003eawait\u003c/span\u003e charactersCollection.doc\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.\u003cspan class=\"synStatement\"\u003edelete();\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\n  it\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e\u0026quot;キャラクターが転職した場合、レベルが1に戻ること\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e \u003cspan class=\"synStatement\"\u003easync\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003eawait\u003c/span\u003e characterJobChangeUseCase\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e \u003cspan class=\"synComment\"\u003e// characterJobChangeUsecase#handle に渡された引数の ID を持つユーザーのレベルが1に戻る\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003econst\u003c/span\u003e jobChangedCharacter \u003cspan class=\"synStatement\"\u003e=\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e(await\u003c/span\u003e charactersCollection.doc\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.get\u003cspan class=\"synStatement\"\u003e())\u003c/span\u003e.data\u003cspan class=\"synStatement\"\u003e();\u003c/span\u003e\n\n    expect\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003ejobChangedCharacter.level\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.toBe\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e \u003cspan class=\"synComment\"\u003e// 転職するとレベルが1に戻ることを検証できるようになった\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\n\n\u003cpre class=\"code lang-typescript\" data-lang=\"typescript\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e// functions/src/usecases/characterLevelUpUseCase.spec.ts\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003eimport\u003c/span\u003e * \u003cspan class=\"synStatement\"\u003eas\u003c/span\u003e admin \u003cspan class=\"synStatement\"\u003efrom\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e\u0026quot;firebase-admin\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n\u003cspan class=\"synStatement\"\u003eimport\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e characterLevelUpUseCase \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e \u003cspan class=\"synStatement\"\u003efrom\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e\u0026quot;@/usecases/characterLevelUpUseCase\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n\nadmin.initializeApp\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n  projectId: \u003cspan class=\"synConstant\"\u003e\u0026quot;character-level-up-use-case-spec\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e \u003cspan class=\"synComment\"\u003e// 図の③に対応\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\n\u003cspan class=\"synComment\"\u003e// ここから下は構成変更前のコードと同じ\u003c/span\u003e\n\n\u003cspan class=\"synStatement\"\u003econst\u003c/span\u003e charactersCollection \u003cspan class=\"synStatement\"\u003e=\u003c/span\u003e admin\n  .firestore\u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e\n  .collection\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e\u0026quot;characters\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\ndescribe\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003echaracterLevelUpUseCase\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003econst\u003c/span\u003e targetCharacterId \u003cspan class=\"synStatement\"\u003e=\u003c/span\u003e \u003cspan class=\"synConstant\"\u003e\u0026quot;target-character-id\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n\n  beforeEach\u003cspan class=\"synStatement\"\u003e(async\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003eawait\u003c/span\u003e charactersCollection.doc\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.set\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n        name: \u003cspan class=\"synConstant\"\u003e\u0026quot;アルス\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e\n        level: \u003cspan class=\"synConstant\"\u003e10\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e\n        job: \u003cspan class=\"synConstant\"\u003e\u0026quot;すっぴん\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\n  afterEach\u003cspan class=\"synStatement\"\u003e(async\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003eawait\u003c/span\u003e charactersCollection.doc\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.\u003cspan class=\"synStatement\"\u003edelete();\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\n  it\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e\u0026quot;キャラクターがレベルアップした場合、レベルが1上がること\u0026quot;\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e,\u003c/span\u003e \u003cspan class=\"synStatement\"\u003easync\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e()\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003eawait\u003c/span\u003e characterLevelUpUseCase\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e \u003cspan class=\"synComment\"\u003e// characterJobChangeUsecase#handle に渡された引数の ID を持つユーザーのレベルが1上がる\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003econst\u003c/span\u003e grownCharacter \u003cspan class=\"synStatement\"\u003e=\u003c/span\u003e \u003cspan class=\"synStatement\"\u003e(await\u003c/span\u003e charactersCollection.doc\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003etargetCharacterId\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.get\u003cspan class=\"synStatement\"\u003e())\u003c/span\u003e.data\u003cspan class=\"synStatement\"\u003e();\u003c/span\u003e\n\n    expect\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003egrownCharacter.level\u003cspan class=\"synStatement\"\u003e)\u003c/span\u003e.toBe\u003cspan class=\"synStatement\"\u003e(\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e11\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e \u003cspan class=\"synComment\"\u003e// レベルアップした場合にレベルが1上がることを検証できるようになった\u003c/span\u003e\n  \u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003e}\u003c/span\u003e\u003cspan class=\"synStatement\"\u003e);\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003eこのようにテストごとに向き先プロジェクトを変えることで、それぞれのテストで担保したいことをちゃんと担保できるようになります。\u003c/p\u003e\n\n\u003ch1\u003eちょっと微妙な点\u003c/h1\u003e\n\n\u003cp\u003e上記の方法でテストごとに独立した環境の Firestore を操作できるようになり、データ競合を防げるようになりました。\u003c/p\u003e\n\n\u003cp\u003eしかし、この方法にはひとつだけ微妙な点があります。\u003cbr /\u003e\n問題の説明のために、先程掲載した\u003ccode\u003e競合解決後の構成図\u003c/code\u003eを再掲します。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/l/len_prog/20210705/20210705113933.png\" alt=\"f:id:len_prog:20210705113933p:plain:w500\" width=\"1200\" height=\"779\" loading=\"lazy\" title=\"\" class=\"hatena-fotolife\" style=\"width:500px\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003e上図①の接続先は、\u003ccode\u003e$ firebase use\u003c/code\u003e で指定したプロジェクトか、\u003ccode\u003e$ firebase emulators:start\u003c/code\u003e に \u003ccode\u003e--project\u003c/code\u003eを渡した場合にはそのプロジェクトになり、そのほかの方法で変えることは今のところできないようです。\u003c/p\u003e\n\n\u003cp\u003eそのため、プロジェクトをテストごとに分けた場合、上図②③のテスト中にテスト自体は動くものの、Firebase Emulator の UI からデータの内容を見ることはできなくなります。\u003c/p\u003e\n\n\u003cp\u003e一応、接続先を \u003ccode\u003e$ firebase use\u003c/code\u003e で指定しているものに切り替えるようコードを書き換えたりすればデバッグはできますが、\nいちいち書き換えの手間が生じるので若干面倒です。\u003c/p\u003e\n\n\u003cp\u003eまた、これは Firebase Enulator の UI で立ち上がっているすべてのプロジェクトの Firestore を見られるようになれば解決する問題ではあり、実際に \u003ca href=\"https://github.com/firebase/firebase-tools-ui\"\u003efirebase/firebase-tools-ui\u003c/a\u003e リポジトリに \u003ca href=\"https://github.com/firebase/firebase-tools-ui/issues/281\"\u003eissue\u003c/a\u003e も立っていますが、すぐに対応が終わりそうには見えない状況なので、しばらくは不便な状況が続くことが予想されます。\u003c/p\u003e\n\n\u003ch1\u003e所感\u003c/h1\u003e\n\n\u003cp\u003eFirebase は便利ですが、当然ながら全くハマらずに開発できる銀の弾丸ではないですね。\u003cbr /\u003e\nしかし、基本的には便利でドキュメントもそれなりに読みやすく、個人的には使っていて満足感があります。\u003c/p\u003e\n\n\u003cp\u003e今後も日々の開発で得た Firebase や GCP 周りの TIPS を書いていけたらと思っておりますので、よろしくお願いいたします 🙏\u003c/p\u003e\n","contentSnippet":"こんにちは、エンジニアの id:len_prog です。私が所属している EC Booster チームでは、「カイゼンカード」機能の開発に Firebase を採用しています。しかし、Firebase を採用したことで苦労したことが全く無かったわけではありません。そこで、今回の記事では、いくつかあったハマりごとの中でも特に厄介だったものについて対策を書いていきます。Firestore Emulator のプロジェクト共有時のデータ競合Firebase Local Emulator Suite を使って Firestore に接続するテストを書いていた際に、調査の結果、これは、接続先プロジェクトがすべてのテストで同じになってしまっているのが原因ということが分かりました。この状態で同じドキュメントを書き換えるテストが並列で走ってしまった場合、実行タイミングによってはドキュメントが予期せぬ状態になってしまいます。このままでは役に立つテストが書けないと思い試行錯誤した結果、テストごとに違うプロジェクトの Firestore に接続することでそれぞれのテストが独立した状態で実行でき、結果としてデータ競合が防げることが分かりました。以下、サンプルアプリケーションを用いてこの方法について書いていきます。サンプルアプリケーションの概要今回は、サンプルとして簡易的な RPG を開発することを想定します。characters コレクションで管理されています。{  name: string;  level: number;  job: string;}また、このゲームでは以下の行動のみが可能と仮定します(これだけじゃゲームとして成り立たないと思いますが、簡単のためということでお許しください)キャラクターは、レベルアップすることができるキャラクターは、転職することができる転職すると、キャラクターのレベルが1に戻るなお、アプリケーション上においてキャラクターのレベルアップは、characterLevelUpUseCase、キャラクターの転職は characterJobChangeUseCase という関数を呼ぶことで行えることとします。ここからは、実際にこれら2つの関数のテストコードが競合する様子を見ていきます。データ競合発生時の構成characterJobChangeUseCase と characterLevelUpUseCase が my-game プロジェクトの Firestore を共有してしまっています。// functions/src/usecases/characterJobChangeUseCase.spec.tsimport * as admin from \"firebase-admin\";import { characterJobChangeUseCase } from \"@/usecases/characterJobChangeUseCase\";admin.initializeApp({  projectId: \"my-game\", // ここが問題});const charactersCollection = admin  .firestore()  .collection(\"characters\");describe(characterJobChangeUseCase, () =\u003e {  const targetCharacterId = \"target-character-id\";  beforeEach(async () =\u003e {    await charactersCollection.doc(targetCharacterId).set({        name: \"アルス\",        level: 10,        job: \"すっぴん\";    });  });  afterEach(async () =\u003e {    await charactersCollection.doc(targetCharacterId).delete();  });  it(\"キャラクターが転職した場合、レベルが1に戻ること\", async () =\u003e {    await characterJobChangeUseCase(targetCharacterId); // characterJobChangeUsecase#handle に渡された引数の ID を持つユーザーのレベルが1に戻る    const jobChangedCharacter = (await charactersCollection.doc(targetCharacterId).get()).data();    expect(jobChangedCharacter.level).toBe(1); // 実行タイミング次第では、1になるはずが11になってしまう！  });});// functions/src/usecases/characterLevelUpUseCase.spec.tsimport * as admin from \"firebase-admin\";import { characterLevelUpUseCase } from \"@/usecases/characterLevelUpUseCase\";admin.initializeApp({  projectId: \"my-game\", // ここが問題});const charactersCollection = admin  .firestore()  .collection(\"characters\");describe(characterLevelUpUseCase, () =\u003e {  const targetCharacterId = \"target-character-id\";  beforeEach(async () =\u003e {    await charactersCollection.doc(targetCharacterId).set({        name: \"アルス\",        level: 10,        job: \"すっぴん\";    });  });  afterEach(async () =\u003e {    await charactersCollection.doc(targetCharacterId).delete();  });  it(\"キャラクターがレベルアップした場合、レベルが1上がること\", async () =\u003e {    await characterLevelUpUseCase(targetCharacterId); // characterJobChangeUsecase#handle に渡された引数の ID を持つユーザーのレベルが1上がる    const grownCharacter = (await charactersCollection.doc(targetCharacterId).get()).data();    expect(grownCharacter.level).toBe(11); // 実行タイミング次第では、11になるはずが1に戻ってしまう！  });});見ての通り、両方のテストが my-game プロジェクトの Firestore の、ID: target-character-id のドキュメントを更新してしまっています。キャラクターが転職したのにレベルが1に戻らない、キャラクターがレベルアップしたはずなのになぜかレベル1に戻ってしまうなど予期せぬ状態になってしまい、テストが落ちてしまう可能性があります。この状態ではテストコードが信用できないので、テストごとに向き先プロジェクトを変えてこの問題を解決していきます。データ競合解決後の構成上図②③のようにテストごとに接続先プロジェクトを独立させることで、他のテストとの並列実行が原因のデータ競合を防ぐことができます。admin.initializeApp()の第一引数に他のテストと重複しないプロジェクトID を渡すようにします。// functions/src/usecases/characterJobChangeUseCase.spec.tsadmin.initializeApp({  projectId: \"character-job-change-use-case-spec\", //  図の②に対応});// functions/src/usecases/characterLevelUpUseCase.spec.tsadmin.initializeApp({  projectId: \"character-level-up-use-case-spec\", // 図の③に対応});変更後のコードの全体像は以下のようになります。// functions/src/usecases/characterJobChangeUseCase.spec.tsimport * as admin from \"firebase-admin\";import { characterJobChangeUseCase } from \"@/usecases/characterJobChangeUseCase\";admin.initializeApp({  projectId: \"character-job-change-use-case-spec\", //  図の②に対応});// ここから下は構成変更前のコードと同じconst charactersCollection = admin  .firestore()  .collection(\"characters\");describe(characterJobChangeUseCase, () =\u003e {  const targetCharacterId = \"target-character-id\";  beforeEach(async () =\u003e {    await charactersCollection.doc(targetCharacterId).set({        name: \"アルス\",        level: 10,        job: \"すっぴん\";    });  });  afterEach(async () =\u003e {    await charactersCollection.doc(targetCharacterId).delete();  });  it(\"キャラクターが転職した場合、レベルが1に戻ること\", async () =\u003e {    await characterJobChangeUseCase(targetCharacterId); // characterJobChangeUsecase#handle に渡された引数の ID を持つユーザーのレベルが1に戻る    const jobChangedCharacter = (await charactersCollection.doc(targetCharacterId).get()).data();    expect(jobChangedCharacter.level).toBe(1); // 転職するとレベルが1に戻ることを検証できるようになった  });});// functions/src/usecases/characterLevelUpUseCase.spec.tsimport * as admin from \"firebase-admin\";import { characterLevelUpUseCase } from \"@/usecases/characterLevelUpUseCase\";admin.initializeApp({  projectId: \"character-level-up-use-case-spec\", // 図の③に対応});// ここから下は構成変更前のコードと同じconst charactersCollection = admin  .firestore()  .collection(\"characters\");describe(characterLevelUpUseCase, () =\u003e {  const targetCharacterId = \"target-character-id\";  beforeEach(async () =\u003e {    await charactersCollection.doc(targetCharacterId).set({        name: \"アルス\",        level: 10,        job: \"すっぴん\";    });  });  afterEach(async () =\u003e {    await charactersCollection.doc(targetCharacterId).delete();  });  it(\"キャラクターがレベルアップした場合、レベルが1上がること\", async () =\u003e {    await characterLevelUpUseCase(targetCharacterId); // characterJobChangeUsecase#handle に渡された引数の ID を持つユーザーのレベルが1上がる    const grownCharacter = (await charactersCollection.doc(targetCharacterId).get()).data();    expect(grownCharacter.level).toBe(11); // レベルアップした場合にレベルが1上がることを検証できるようになった  });});このようにテストごとに向き先プロジェクトを変えることで、それぞれのテストで担保したいことをちゃんと担保できるようになります。ちょっと微妙な点上記の方法でテストごとに独立した環境の Firestore を操作できるようになり、データ競合を防げるようになりました。しかし、この方法にはひとつだけ微妙な点があります。競合解決後の構成図を再掲します。上図①の接続先は、$ firebase use で指定したプロジェクトか、$ firebase emulators:start に --projectを渡した場合にはそのプロジェクトになり、そのほかの方法で変えることは今のところできないようです。そのため、プロジェクトをテストごとに分けた場合、上図②③のテスト中にテスト自体は動くものの、Firebase Emulator の UI からデータの内容を見ることはできなくなります。一応、接続先を $ firebase use で指定しているものに切り替えるようコードを書き換えたりすればデバッグはできますが、いちいち書き換えの手間が生じるので若干面倒です。また、これは Firebase Enulator の UI で立ち上がっているすべてのプロジェクトの Firestore を見られるようになれば解決する問題ではあり、実際に firebase/firebase-tools-ui リポジトリに issue も立っていますが、すぐに対応が終わりそうには見えない状況なので、しばらくは不便な状況が続くことが予想されます。所感Firebase は便利ですが、当然ながら全くハマらずに開発できる銀の弾丸ではないですね。今後も日々の開発で得た Firebase や GCP 周りの TIPS を書いていけたらと思っておりますので、よろしくお願いいたします 🙏","link":"https://developer.feedforce.jp/entry/2021/07/07/103917","isoDate":"2021-07-07T01:39:17.000Z","dateMiliSeconds":1625621957000,"imageUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/l/len_prog/20210705/20210705113933.png","authorName":"feedforce"},{"title":"【2021年夏】半期に1度の Engineer’s Principles Award 受賞者を紹介します","content":"\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/f/feedforce_recruit/20210611/20210611163915.jpg\" alt=\"f:id:feedforce_recruit:20210611163915j:plain\" width=\"1200\" height=\"700\" loading=\"lazy\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003eこんにちは。人事の今岡と申します。\n2021年もあっという間に6月ですね。\u003c/p\u003e\n\n\u003cp\u003eフィードフォースでは先日オンライン納会が開催され、半期に一度の「Engineer’s Principles Award 2021 Summer」の受賞者が発表されました。\n今回アワードを受賞した開発メンバーと表彰内容をご紹介します。\u003c/p\u003e\n\n\u003cp\u003e前回の表彰者紹介はコチラ\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fdeveloper.feedforce.jp%2Fentry%2F2020%2F12%2F28%2F131042\" title=\"半期に1度の Engineer’s Principles Award 受賞者を紹介します - Feedforce Developer Blog\" class=\"embed-card embed-blogcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 190px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://developer.feedforce.jp/entry/2020/12/28/131042\"\u003edeveloper.feedforce.jp\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003ch2\u003eEngineer’s Principles Award とは\u003c/h2\u003e\n\n\u003cp\u003eEngineer’s Principles とは、フィードフォースの開発メンバー向けに現場が主体となって設定した、5つの行動指針です。\n半期に一度、開発メンバー同士で投票を行い、行動指針の項目ごとに最も体現しているメンバーが選ばれ表彰されます。\u003c/p\u003e\n\n\u003cp\u003eEngineer’s Principles についてはこちら\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fmedia.feedforce.jp%2Fn%2Fnd1f2236470b3\" title=\"フィードフォースが目指すエンジニア像とは。「Engineer’s Principles」を紹介します｜フィードフォースのnote\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://media.feedforce.jp/n/nd1f2236470b3\"\u003emedia.feedforce.jp\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003ch2\u003e受賞者紹介\u003c/h2\u003e\n\n\u003cp\u003e※表彰コメントは本来社内向けのものであるため一部変更させていただいています。受賞者によって各種アカウントを載せています。\u003c/p\u003e\n\n\u003ch3\u003e🏆「Stay Humble; 常に謙虚であるべし」受賞者\u003c/h3\u003e\n\n\u003ch4\u003e@len_prog さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\n社内でメジャーな Rails 以外でバックエンドを実装する際に、なぜそうするのかという理由やレイヤーの切り方を他のメンバーにわかりやすく説明していました。\n一方、自分自身で苦手なことがあった場合に、他の人に相談したり、フィードバックを求めそれを受け入れる姿勢は、まさに Stay Humble だと思いました。\u003c/p\u003e\n\n\u003cp\u003e\u003ci class=\"blogicon-twitter\"\u003e\u003c/i\u003e \u003ca href=\"https://twitter.com/len_prog\"\u003eLen (@len_prog)\u003c/a\u003e , \u003ci class=\"blogicon-entry\"\u003e\u003c/i\u003e \u003ca href=\"https://len-prog.hatenablog.com/\"\u003eBlog\u003c/a\u003e\u003c/p\u003e\n\n\u003ch4\u003e@katsunn さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\n事前に色々なアイデアを用意しつつも、相談の過程でお互いの認識や意図を踏まえたうえで改善を進めていく一方、ただ受け入れるだけではなく、\nプロフェッショナルとして自分なりに咀嚼したアウトプットにしていく姿勢が非常に素晴らしく、ベンチマークにすべきだと感じました。\u003c/p\u003e\n\n\u003cp\u003e\u003ci class=\"blogicon-twitter\"\u003e\u003c/i\u003e  \u003ca href=\"https://twitter.com/nomo_017\"\u003eのもち(@nomo_017)\u003c/a\u003e\u003c/p\u003e\n\n\u003ch3\u003e🏆「Be Positive \u0026amp; Proactive; 常に肯定的・主体的であるべし」受賞者\u003c/h3\u003e\n\n\u003ch4\u003e@sukechannnn さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\nエンジニアとして様々なチームビルディングや開発手法を試しているだけではなく、ビジネス視点からも方向性を考え、\nプロダクトオーナーとしてプロダクトを成長させようとしている姿勢は、まさにこの言葉にぴったりだと思います。\u003c/p\u003e\n\n\u003cp\u003e\u003ci class=\"blogicon-twitter\"\u003e\u003c/i\u003e \u003ca href=\"https://twitter.com/sukechannnn\"\u003e sukechannnn (@sukechannnn)\u003c/a\u003e , \u003ci class=\"fa fa-github\" aria-hidden=\"true\"\u003e\u003c/i\u003e \u003ca href=\"https://github.com/sukechannnn\"\u003esukechannnn\u003c/a\u003e\u003c/p\u003e\n\n\u003ch4\u003e@daido1976 さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\n分野を問わず新しいことに前向きに挑戦し、気になったことはどんどん質問するのに加え、\n育休中のメンバーに代わって、率先してチームを引っ張っている行動力が素晴らしいと思いました。\u003c/p\u003e\n\n\u003cp\u003e\u003ci class=\"blogicon-twitter\"\u003e\u003c/i\u003e  \u003ca href=\"https://twitter.com/daido1976\"\u003eDaido Shota (@daido1976)\u003c/a\u003e , \u003ci class=\"fa fa-github\" aria-hidden=\"true\"\u003e\u003c/i\u003e  \u003ca href=\"https://github.com/daido1976\"\u003e daido1976\u003c/a\u003e\u003c/p\u003e\n\n\u003ch3\u003e🏆「Be Prepared; 常に来たるべき機会に備えるべし」受賞者\u003c/h3\u003e\n\n\u003ch4\u003e@daido1976 さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\n自分のキャリアや目指すべき方向を踏まえつつ、常にアンテナを立てて知識を広く持とうとしている姿勢がよいと感じています。\nさらに、そうして蓄積したスキルを開発だけではなく、自ら手を挙げ講師をつとめた新卒向け Web 研修にも活かしている点がまさに Be Prepared だと思いました。\u003c/p\u003e\n\n\u003cp\u003e\u003ci class=\"blogicon-twitter\"\u003e\u003c/i\u003e  \u003ca href=\"https://twitter.com/daido1976\"\u003eDaido Shota (@daido1976)\u003c/a\u003e , \u003ci class=\"fa fa-github\" aria-hidden=\"true\"\u003e\u003c/i\u003e  \u003ca href=\"https://github.com/daido1976\"\u003e daido1976\u003c/a\u003e\u003c/p\u003e\n\n\u003ch4\u003e@namikingsoft さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\nOmni Hub の開発において、あまり開発経験がなかったはずの Rust を使いこなしつつ WAF を含めたインフラ構築をしていて、\n@namikingsoft さんの強みが発揮される局面でした。また dfplus.io でもパフォーマンス改善でコアな知識を活かすなど、まさにこれまでの準備の賜物だと思います。\u003c/p\u003e\n\n\u003cp\u003e\u003ci class=\"fa fa-github\" aria-hidden=\"true\"\u003e\u003c/i\u003e \u003ca href=\"https://github.com/namikingsoft\"\u003enamikingsoft\u003c/a\u003e\u003c/p\u003e\n\n\u003ch3\u003e🏆「Share All; 己の知見、試行、失敗、遍く共有すべし」受賞者\u003c/h3\u003e\n\n\u003ch4\u003e@masutaka さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\nLooker 導入において知見や失敗など社内共有しているほか、そもそも  esa にどう記録すべきかといった、「共有のための知見の共有」にまで配慮しています。\nSlack や esa 、Blog への共有はエンジニアのみならず、全社的にプラスの影響を与えていて、まさに共有の神様と言えるでしょう。\u003c/p\u003e\n\n\u003cp\u003e\u003ci class=\"blogicon-twitter\"\u003e\u003c/i\u003e \u003ca href=\"https://twitter.com/masutaka\"\u003eTakashi Masuda (@masutaka)\u003c/a\u003e , \u003ci class=\"fa fa-github\" aria-hidden=\"true\"\u003e\u003c/i\u003e \u003ca href=\"https://github.com/masutaka\"\u003emasutaka\u003c/a\u003e , \u003ci class=\"blogicon-entry\"\u003e\u003c/i\u003e \u003ca href=\"https://masutaka.net/\"\u003eBlog\u003c/a\u003e\u003c/p\u003e\n\n\u003ch4\u003e@kogai さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\nShopify 周りでは、社内だけでなく社外に対してのプレゼンスを示しています。また Omni Hub の開発で多忙な中、\n社内勉強会 Rust の会では実際の新規事業のプロダクトコードを題材に実践的な知見を共有するなど、その共有力はフィードフォースエンジニアの鑑（かがみ）だと思います。\u003c/p\u003e\n\n\u003cp\u003e\u003ci class=\"blogicon-twitter\"\u003e\u003c/i\u003e \u003ca href=\"https://twitter.com/iamchawan\"\u003e茶碗 (@iamchawan)\u003c/a\u003e ,\u003ci class=\"fa fa-github\" aria-hidden=\"true\"\u003e\u003c/i\u003e \u003ca href=\"https://github.com/kogai\"\u003ekogai\u003c/a\u003e , \u003ci class=\"blogicon-entry\"\u003e\u003c/i\u003e \u003ca href=\"https://k9bookshelf.com/blogs/development\"\u003eBlog\u003c/a\u003e\u003c/p\u003e\n\n\u003ch3\u003e🏆「Just Do It; 全力でやりきるべし」受賞者\u003c/h3\u003e\n\n\u003ch4\u003e@namikingsoftさん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\nOmni  Hub リリースまでの道筋をきちんと立ててスケジュール以上の速さで完走して去っていくその姿は、まさに Just Do It でした。\u003c/p\u003e\n\n\u003cp\u003e\u003ci class=\"fa fa-github\" aria-hidden=\"true\"\u003e\u003c/i\u003e \u003ca href=\"https://github.com/namikingsoft\"\u003enamikingsoft\u003c/a\u003e\u003c/p\u003e\n\n\u003ch2\u003e周囲の賞賛・承認を共有するよい機会に\u003c/h2\u003e\n\n\u003cp\u003e以上、延べ9名の受賞者でした。\u003c/p\u003e\n\n\u003cp\u003e表彰コメントは、\u003cstrong\u003e開発メンバー同士の投票時に自由記述できるコメントがもとになっているので\u003c/strong\u003e、周囲からの賞賛・承認の声を全社で共有できるよい機会となっています。\u003c/p\u003e\n\n\u003cp\u003e前回に引き続き連続受賞しているメンバーもいますが、投票コメントには毎回違ったエピソードが集まっており、日ごろから継続的に実践をしているからこそ周りのエンジニアの目に留まるのだと感じました。\u003c/p\u003e\n\n\u003cp\u003e受賞者のみなさん、おめでとうございました！\u003c/p\u003e\n","contentSnippet":"こんにちは。人事の今岡と申します。2021年もあっという間に6月ですね。フィードフォースでは先日オンライン納会が開催され、半期に一度の「Engineer’s Principles Award 2021 Summer」の受賞者が発表されました。今回アワードを受賞した開発メンバーと表彰内容をご紹介します。前回の表彰者紹介はコチラdeveloper.feedforce.jpEngineer’s Principles Award とはEngineer’s Principles とは、フィードフォースの開発メンバー向けに現場が主体となって設定した、5つの行動指針です。半期に一度、開発メンバー同士で投票を行い、行動指針の項目ごとに最も体現しているメンバーが選ばれ表彰されます。Engineer’s Principles についてはこちらmedia.feedforce.jp受賞者紹介※表彰コメントは本来社内向けのものであるため一部変更させていただいています。受賞者によって各種アカウントを載せています。🏆「Stay Humble; 常に謙虚であるべし」受賞者@len_prog さん表彰コメント： Len (@len_prog) ,  Blog@katsunn さん表彰コメント：  のもち(@nomo_017)🏆「Be Positive \u0026 Proactive; 常に肯定的・主体的であるべし」受賞者@sukechannnn さん表彰コメント：  sukechannnn (@sukechannnn) ,  sukechannnn@daido1976 さん表彰コメント：  Daido Shota (@daido1976) ,    daido1976🏆「Be Prepared; 常に来たるべき機会に備えるべし」受賞者@daido1976 さん表彰コメント：  Daido Shota (@daido1976) ,    daido1976@namikingsoft さん表彰コメント： namikingsoft🏆「Share All; 己の知見、試行、失敗、遍く共有すべし」受賞者@masutaka さん表彰コメント： Takashi Masuda (@masutaka) ,  masutaka ,  Blog@kogai さん表彰コメント： 茶碗 (@iamchawan) , kogai ,  Blog🏆「Just Do It; 全力でやりきるべし」受賞者@namikingsoftさん表彰コメント： namikingsoft周囲の賞賛・承認を共有するよい機会に以上、延べ9名の受賞者でした。表彰コメントは、開発メンバー同士の投票時に自由記述できるコメントがもとになっているので、周囲からの賞賛・承認の声を全社で共有できるよい機会となっています。前回に引き続き連続受賞しているメンバーもいますが、投票コメントには毎回違ったエピソードが集まっており、日ごろから継続的に実践をしているからこそ周りのエンジニアの目に留まるのだと感じました。受賞者のみなさん、おめでとうございました！","link":"https://developer.feedforce.jp/entry/2021/06/11/164253","isoDate":"2021-06-11T07:42:53.000Z","dateMiliSeconds":1623397373000,"imageUrl":"https://cdn.user.blog.st-hatena.com/default_entry_og_image/4268819/1588226000876991","authorName":"feedforce"},{"title":"プランニングの難しさを乗り越えて...スクラム開発が良い感じになった話","content":"\u003cp\u003eこんにちは。フィードフォースの \u003ca href=\"https://ecbooster.jp/\"\u003eEC Booster\u003c/a\u003e チームで開発（主にプロダクトオーナー）をしている \u003ca href=\"https://twitter.com/sukechannnn\"\u003e@sukechannnn\u003c/a\u003e です。元々ずっとバックエンドエンジニアでしたが、最近プロダクトオーナーをやるようになりました（理由はのちほど！）。\u003c/p\u003e\n\n\u003cp\u003e昨年のアドベントカレンダーで \u003ca href=\"https://developer.feedforce.jp/entry/2020/12/11/172338\"\u003e半年モブプロしたらチームが大きく成長した話\u003c/a\u003e というブログを書いたのですが、2021年3月から \u003cstrong\u003eモブプロを取り入れたスクラム開発\u003c/strong\u003e をしています。それに伴って、\"モブプロ\" と \"個人タスク⇢レビュー\" の両軸で開発するようになりました（\u003ca href=\"https://prtimes.jp/main/html/rd/p/000000040.000071307.html\"\u003e先日リリースしたカイゼンカード\u003c/a\u003e はスクラムで開発しました）。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fdeveloper.feedforce.jp%2Fentry%2F2020%2F12%2F11%2F172338\" title=\"半年モブプロしたらチームが大きく成長した話 - Feedforce Developer Blog\" class=\"embed-card embed-blogcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 190px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003c/p\u003e\n\n\u003cp\u003e今は良い感じに回っていますが、そうなるまでに色々と試行錯誤したので、そこで得た学びをお伝えできればと思います。全員リモートワークで開発するなら、モブプロを取り入れたスクラムはおすすめです！\u003c/p\u003e\n\n\u003cul class=\"table-of-contents\"\u003e\n    \u003cli\u003e\u003ca href=\"#モブプロの良さと難しさ\"\u003eモブプロの良さと難しさ\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#そうだスクラムしよう\"\u003eそうだ、スクラムしよう！\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#プランニングが終わらない問題\"\u003eプランニングが終わらない問題\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#原因はissue-が散らかっていることだった\"\u003e原因は「issue が散らかっていること」だった\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#issue-をグルーピング優先順位はそれぞれで\"\u003eissue をグルーピング、優先順位はそれぞれで\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#まとめ\"\u003eまとめ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"モブプロの良さと難しさ\"\u003eモブプロの良さと難しさ\u003c/h2\u003e\n\n\u003cp\u003eモブプロ中心の開発を初めた当初は、以下の利点を感じていました。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eドメイン知識の共有がしやすい\u003c/li\u003e\n\u003cli\u003eコンテキストの共有がしやすい（\"何をどう作るか\" という議論もしやすい）\u003c/li\u003e\n\u003cli\u003eレビューが要らない\u003c/li\u003e\n\u003cli\u003eリモートワークでもさみしくない（だいじ）\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eしばらくモブプロを続ける中で、開発メンバー全員がドメイン知識やフロント〜バックエンド全体の技術的な知識を共有している状態になりました。なので、なにか悩みがあってモブプロで共有すると「わかる〜」となるし、何より単純に仲良くなったと思います（ﾖｼｯ!!）。\u003c/p\u003e\n\n\u003cp\u003e一方で、だんだんと \u003cstrong\u003eモブプロだけ\u003c/strong\u003e の開発が窮屈になってきました。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e知識の共有が進んできて \"全員でやらなくても良くない？\" というタスクが増えてきた\u003c/li\u003e\n\u003cli\u003e個人でじっくり考えた方が良いタスクもあるのが分かった（新しい技術の調査、設計の見直しなど）\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eこれはチームが成長したことで出てきた嬉しい悩みなのですが、とはいえ完全にモブプロを辞めるのも上述したメリットを失いそうで怖い...。チーム全員で「今後どう開発していこう？」というのを話し合い、\u003cstrong\u003eモブプロを取り入れたスクラム開発\u003c/strong\u003e を試してみることにしました。\u003c/p\u003e\n\n\u003ch2 id=\"そうだスクラムしよう\"\u003eそうだ、スクラムしよう！\u003c/h2\u003e\n\n\u003cp\u003eスクラム開発をしようと思ったのは、ストーリーポイント\u003ca href=\"#f-9495249b\" name=\"fn-9495249b\" title=\"ストーリーポイント：プロダクトバックログ（タスク）を見積もるためにチームが使う単位で、前回の見積もりに対する相対評価を用いる\"\u003e*1\u003c/a\u003eで見積もって \u003cstrong\u003eベロシティ\u003ca href=\"#f-33d76d3d\" name=\"fn-33d76d3d\" title=\"ベロシティ：スプリントの期間でチームが届けることができる見積もり（ストーリーポイント）の合計のこと\"\u003e*2\u003c/a\u003eを測りたい\u003c/strong\u003e という別の目的もありました。\u003c/p\u003e\n\n\u003cp\u003eモブプロで開発していると新機能のメイン開発は着実に進んでいくのですが、それ以外の細かいタスク（主に保守系）が見積もりづらい状況で、空いた時間にやるという形になってしまっていました（それ用に時間は設けていましたが）。\u003c/p\u003e\n\n\u003cp\u003eモブプロ以外の個人タスクを計画的にやりたい、見積もりもしっかりやりたい、ということで、スクラムを導入することで、\u003cstrong\u003eモブプロと個人開発のいいとこ取り\u003c/strong\u003e をしようと考えました。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e新機能開発などのコンテキストの共有が重要なタスクは引き続きモブプロでやる\n\n\u003cul\u003e\n\u003cli\u003eストーリーポイントで見積もる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eそれ以外は個人タスクとして各自で進められるように、プランニングでしっかり整理する\n\n\u003cul\u003e\n\u003cli\u003e個人タスクもストーリーポイントで見積もる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e全てのタスクをストーリーポイントで見積もるのでベロシティが測れるようになる\n\n\u003cul\u003e\n\u003cli\u003e振り返りで見積もりの精度を上げられる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eめっちゃ良さそう...そう思っていざやってみたところ、１つ大きな壁にぶち当たってしまいました。\u003c/p\u003e\n\n\u003ch2 id=\"プランニングが終わらない問題\"\u003eプランニングが終わらない問題\u003c/h2\u003e\n\n\u003cp\u003e\u003ca href=\"https://www.shoeisha.co.jp/book/detail/9784798130507\"\u003eエッセンシャルスクラム\u003c/a\u003eにもある通り、１週間のプランニングに２時間以上かけるべきではありません。僕らは「１スプリント=１週間」で回しているため、２時間の予定で始めたプランニングですが、これが終わらない...。最初から何回かは４時間以上かかり、全員ヘトヘトになってしまいました。\u003c/p\u003e\n\n\u003cp\u003eモブプロはプランニングが簡単です。全員やることが同じなので、基本的にタスクが直列で繋がっていきます。そのため「今スプリントはここから⇢ここまで」という感じで Sprint Backlog 的なものを決めることができました。\u003c/p\u003e\n\n\u003cp\u003eしかし、スクラムの見積もりはもっと横断的なものです。単純に、今取り組んでいるものだけ見れば良いのではなく、これから取り組むものをたくさんある issue から選ぶ必要があります。そう、この \u003cstrong\u003eたくさんある issue の中から今スプリントにやるタスクを選ぶこと\u003c/strong\u003e に時間がかかってしまうのです。\u003c/p\u003e\n\n\u003cp\u003e以前にもスクラム開発を試したことがあるのですが、その時もこれが原因でプランニングがとても大変でした。気にするトピックが多すぎてだんだん何について議論してるか分からなくなり、空中戦になってしまうんですよね...。\u003c/p\u003e\n\n\u003cp\u003eその原因は、主に以下の２つでした。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eバックログの整理/管理に責任を持つ人（プロダクトオーナー\u003ca href=\"#f-339964b7\" name=\"fn-339964b7\" title=\"プロダクトオーナー：プロダクトバックログの管理をする人で、優先順位を付けることに責任を持つ（１人の人間が務める、委員会ではない）\"\u003e*3\u003c/a\u003e）がいなかった\u003c/li\u003e\n\u003cli\u003eissue の数と種類が多く、バックログリファインメント\u003ca href=\"#f-f2375d03\" name=\"fn-f2375d03\" title=\"バックログリファインメント：プランニングの前にプロダクトバックログを見直し、プランニング可能な状態にしておくこと\"\u003e*4\u003c/a\u003eをしても整理しきれなかった\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eプロダクトオーナー不在の問題は、元々それっぽいことをしていた僕が、改めてプロダクトオーナーやりますと手を上げ、バックログ管理の責任を持つことになりました。\u003c/p\u003e\n\n\u003cp\u003eそれでも、バックログリファインメントが上手く行かない問題は残っていました。リファインメントの概念は理解していて、しっかり時間も取っていたのに、いざプランニングをすると色々な issue を見すぎて伸びてしまう...。過去に何度も直面したこの問題に、改めて取り組むことにしました。\u003c/p\u003e\n\n\u003ch2 id=\"原因はissue-が散らかっていることだった\"\u003e原因は「issue が散らかっていること」だった\u003c/h2\u003e\n\n\u003cp\u003e僕たちが開発している EC Booster は、ショッピング広告の自動運用やデータフィードの更新など、様々なジョブが裏で動いています。そのため、運用作業が日々発生し、運用の中で見つかる例外ケースやバグの修正が多々あります。\nまた、フロントエンドとバックエンドを全員が開発するため、１つのリポジトリで管理していることもあり、色々な種類の issue が１つのレーンに入り乱れてしまっていました。\u003c/p\u003e\n\n\u003cp\u003eそのため、優先順位を付けるのも難しく、また「次スプリントで何をどこまでやるか？」を判断するのが難しくなってしまっていました。\u003c/p\u003e\n\n\u003cp\u003eプロダクトバックログを整理しなければ、というのは分かっているのですが、スクラムに関する本やブログには整理の方法は書いてありません。どうやって整理したら分かりやすくなるかな...と考えていたところ、同僚が共有してくれた以下の記事が参考になりました。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://note.com/gonjyu/n/nd7bf3efa0728\"\u003eエンジニア歴17年の俺が、事業系の開発タスクをバンバン投げてくる非エンジニアに、保守の必要性を死ぬほど分かりやすく説明する。\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eこの記事の中で「issueには \"種類\" がある」と言っていて、issue の種類別に整理された図が載っていました。これだ...！\u003c/p\u003e\n\n\u003ch2 id=\"issue-をグルーピング優先順位はそれぞれで\"\u003eissue をグルーピング、優先順位はそれぞれで\u003c/h2\u003e\n\n\u003cp\u003e上記の記事を参考に、issue を \u003cstrong\u003e新機能開発\u003c/strong\u003e、\u003cstrong\u003eバグ修正/運用改善\u003c/strong\u003e、\u003cstrong\u003eライブラリーアップデート\u003c/strong\u003e に分けて、それぞれのレーンで優先順位を付けるようにしました。\u003c/p\u003e\n\n\u003cp\u003e\u003cfigure class=\"figure-image figure-image-fotolife\" title=\"issue をグルーピング、優先順位はそれぞれで\"\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sukechannnn/20210526/20210526215948.png\" alt=\"f:id:sukechannnn:20210526215948p:plain\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003cfigcaption\u003eissue をグルーピング、優先順位はそれぞれで\u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e\n\n\u003cp\u003eissue の種類が同じなので、優先順位を付けるのは簡単です。さらに、スプリントバックログに入れるタスクを \u003cstrong\u003e新機能開発：運用系 = ６：４\u003c/strong\u003e の割合にする、という決めを作りました。さらに、何回かスプリントを回してベロシティも見えてきました。\u003c/p\u003e\n\n\u003cp\u003eここまで情報が揃うと \u003cstrong\u003e次のスプリントで何をやるか決める基準\u003c/strong\u003e ができてきます。\u003c/p\u003e\n\n\u003cp\u003eそもそもの「次のプランニングでどの issue について話すか？」というのも、それぞれのレーンで優先順位が高い issue を６：４のバランスとベロシティを参考に選べるようになりました。\u003cstrong\u003eプランニングの前\u003c/strong\u003eにプロダクトオーナーが（開発チームと協力しながら）当たりを付けておくことで、プランニングで話すトピックを事前に共有できるようになり、開発メンバーそれぞれが事前に頭を整理しておくこともできるようになりました。\u003c/p\u003e\n\n\u003cp\u003eこれにより、プランニングがかなりスムーズに進むようになったので、いよいよスクラムが回り始めました。新機能開発はモブプロの同期的な開発で、それ以外のタスクは個人タスク⇢レビューという非同期な開発で進められるようになり、デリバリーの最大化を目指しつつ、個人の稼働率も上げられるようになりました。\u003c/p\u003e\n\n\u003cp\u003e\u003cfigure class=\"figure-image figure-image-fotolife\" title=\"GitHub Project を使ってタスク管理してる様子...横に長いんですが、情報が整理されてる方が優先順位を付けやすい\"\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sukechannnn/20210526/20210526212511.png\" alt=\"f:id:sukechannnn:20210526212511p:plain\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003cfigcaption\u003eGitHub Project を使ってタスク管理してる様子...横に長いんですが、情報が整理されてる方が優先順位を付けやすい\u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e\n\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\n\u003cp\u003eissue をグルーピングしそれぞれで優先順位を付けたことで、プランニングが時間内に収まるようになっただけでなく、プランニングで話すトピックを絞ったことでより深い議論をすることができるようになりました。今は「モブプロを取り入れたスクラム」がとても良い感じに回っています！\u003c/p\u003e\n\n\u003cp\u003e↓ EC Booster チームでの「スプリントの回し方」資料を公開しているので、気になった方はぜひ見てみてください！（もっとこうしたら良いよ！という助言などあれば頂けると嬉しいです！）\u003c/p\u003e\n\n\u003ciframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vTQY639rUAwDDtLfj_c9WbU1E0IlDSFzAbrP-XFCmbg8V_sNKPX_pCvKpiy50CQpS02nXvZnQHBb6JT/embed?start=false\u0026loop=false\u0026delayms=3000\" frameborder=\"0\" width=\"960\" height=\"569\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"\u003e\u003c/iframe\u003e\n\n\n\u003cp\u003eこんな感じ開発している EC Booster ですが、ただ今 \u003cstrong\u003eバックエンド（Ruby, Rails）が得意なエンジニアを猛烈に必要としています！！！\u003c/strong\u003e\u003c/p\u003e\n\n\u003cp\u003eもしちょっっっとでも興味があれば、 \u003cstrong\u003e僕とお話しましょう！\u003c/strong\u003e 以下から気軽に応募してください！\n\u003ca href=\"https://open.talentio.com/1/c/feedforce/requisitions/detail/19785\"\u003ehttps://open.talentio.com/1/c/feedforce/requisitions/detail/19785\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e最後まで読んでいただき、ありがとうございました！\u003c/p\u003e\n\u003cdiv class=\"footnote\"\u003e\n\u003cp class=\"footnote\"\u003e\u003ca href=\"#fn-9495249b\" name=\"f-9495249b\" class=\"footnote-number\"\u003e*1\u003c/a\u003e\u003cspan class=\"footnote-delimiter\"\u003e:\u003c/span\u003e\u003cspan class=\"footnote-text\"\u003e\u003ca href=\"https://www.ryuzee.com/contents/blog/3716\"\u003eストーリーポイント\u003c/a\u003e：プロダクトバックログ（タスク）を見積もるためにチームが使う単位で、前回の見積もりに対する相対評価を用いる\u003c/span\u003e\u003c/p\u003e\n\u003cp class=\"footnote\"\u003e\u003ca href=\"#fn-33d76d3d\" name=\"f-33d76d3d\" class=\"footnote-number\"\u003e*2\u003c/a\u003e\u003cspan class=\"footnote-delimiter\"\u003e:\u003c/span\u003e\u003cspan class=\"footnote-text\"\u003e\u003ca href=\"https://www.ryuzee.com/contents/blog/4802\"\u003eベロシティ\u003c/a\u003e：スプリントの期間でチームが届けることができる見積もり（ストーリーポイント）の合計のこと\u003c/span\u003e\u003c/p\u003e\n\u003cp class=\"footnote\"\u003e\u003ca href=\"#fn-339964b7\" name=\"f-339964b7\" class=\"footnote-number\"\u003e*3\u003c/a\u003e\u003cspan class=\"footnote-delimiter\"\u003e:\u003c/span\u003e\u003cspan class=\"footnote-text\"\u003e\u003ca href=\"https://www.ryuzee.com/contents/blog/7143\"\u003eプロダクトオーナー\u003c/a\u003e：プロダクトバックログの管理をする人で、優先順位を付けることに責任を持つ（１人の人間が務める、委員会ではない）\u003c/span\u003e\u003c/p\u003e\n\u003cp class=\"footnote\"\u003e\u003ca href=\"#fn-f2375d03\" name=\"f-f2375d03\" class=\"footnote-number\"\u003e*4\u003c/a\u003e\u003cspan class=\"footnote-delimiter\"\u003e:\u003c/span\u003e\u003cspan class=\"footnote-text\"\u003e\u003ca href=\"https://www.ryuzee.com/contents/blog/5024\"\u003eバックログリファインメント\u003c/a\u003e：プランニングの前にプロダクトバックログを見直し、プランニング可能な状態にしておくこと\u003c/span\u003e\u003c/p\u003e\n\u003c/div\u003e","contentSnippet":"こんにちは。フィードフォースの EC Booster チームで開発（主にプロダクトオーナー）をしている @sukechannnn です。元々ずっとバックエンドエンジニアでしたが、最近プロダクトオーナーをやるようになりました（理由はのちほど！）。昨年のアドベントカレンダーで 半年モブプロしたらチームが大きく成長した話 というブログを書いたのですが、2021年3月から モブプロを取り入れたスクラム開発 をしています。それに伴って、\"モブプロ\" と \"個人タスク⇢レビュー\" の両軸で開発するようになりました（先日リリースしたカイゼンカード はスクラムで開発しました）。今は良い感じに回っていますが、そうなるまでに色々と試行錯誤したので、そこで得た学びをお伝えできればと思います。全員リモートワークで開発するなら、モブプロを取り入れたスクラムはおすすめです！モブプロの良さと難しさそうだ、スクラムしよう！プランニングが終わらない問題原因は「issue が散らかっていること」だったissue をグルーピング、優先順位はそれぞれでまとめモブプロの良さと難しさモブプロ中心の開発を初めた当初は、以下の利点を感じていました。ドメイン知識の共有がしやすいコンテキストの共有がしやすい（\"何をどう作るか\" という議論もしやすい）レビューが要らないリモートワークでもさみしくない（だいじ）しばらくモブプロを続ける中で、開発メンバー全員がドメイン知識やフロント〜バックエンド全体の技術的な知識を共有している状態になりました。なので、なにか悩みがあってモブプロで共有すると「わかる〜」となるし、何より単純に仲良くなったと思います（ﾖｼｯ!!）。一方で、だんだんと モブプロだけ の開発が窮屈になってきました。知識の共有が進んできて \"全員でやらなくても良くない？\" というタスクが増えてきた個人でじっくり考えた方が良いタスクもあるのが分かった（新しい技術の調査、設計の見直しなど）これはチームが成長したことで出てきた嬉しい悩みなのですが、とはいえ完全にモブプロを辞めるのも上述したメリットを失いそうで怖い...。チーム全員で「今後どう開発していこう？」というのを話し合い、モブプロを取り入れたスクラム開発 を試してみることにしました。そうだ、スクラムしよう！スクラム開発をしようと思ったのは、ストーリーポイント*1で見積もって ベロシティ*2を測りたい という別の目的もありました。モブプロで開発していると新機能のメイン開発は着実に進んでいくのですが、それ以外の細かいタスク（主に保守系）が見積もりづらい状況で、空いた時間にやるという形になってしまっていました（それ用に時間は設けていましたが）。モブプロ以外の個人タスクを計画的にやりたい、見積もりもしっかりやりたい、ということで、スクラムを導入することで、モブプロと個人開発のいいとこ取り をしようと考えました。新機能開発などのコンテキストの共有が重要なタスクは引き続きモブプロでやるストーリーポイントで見積もるそれ以外は個人タスクとして各自で進められるように、プランニングでしっかり整理する個人タスクもストーリーポイントで見積もる全てのタスクをストーリーポイントで見積もるのでベロシティが測れるようになる振り返りで見積もりの精度を上げられるめっちゃ良さそう...そう思っていざやってみたところ、１つ大きな壁にぶち当たってしまいました。プランニングが終わらない問題エッセンシャルスクラムにもある通り、１週間のプランニングに２時間以上かけるべきではありません。僕らは「１スプリント=１週間」で回しているため、２時間の予定で始めたプランニングですが、これが終わらない...。最初から何回かは４時間以上かかり、全員ヘトヘトになってしまいました。モブプロはプランニングが簡単です。全員やることが同じなので、基本的にタスクが直列で繋がっていきます。そのため「今スプリントはここから⇢ここまで」という感じで Sprint Backlog 的なものを決めることができました。しかし、スクラムの見積もりはもっと横断的なものです。単純に、今取り組んでいるものだけ見れば良いのではなく、これから取り組むものをたくさんある issue から選ぶ必要があります。そう、この たくさんある issue の中から今スプリントにやるタスクを選ぶこと に時間がかかってしまうのです。以前にもスクラム開発を試したことがあるのですが、その時もこれが原因でプランニングがとても大変でした。気にするトピックが多すぎてだんだん何について議論してるか分からなくなり、空中戦になってしまうんですよね...。その原因は、主に以下の２つでした。バックログの整理/管理に責任を持つ人（プロダクトオーナー*3）がいなかったissue の数と種類が多く、バックログリファインメント*4をしても整理しきれなかったプロダクトオーナー不在の問題は、元々それっぽいことをしていた僕が、改めてプロダクトオーナーやりますと手を上げ、バックログ管理の責任を持つことになりました。それでも、バックログリファインメントが上手く行かない問題は残っていました。リファインメントの概念は理解していて、しっかり時間も取っていたのに、いざプランニングをすると色々な issue を見すぎて伸びてしまう...。過去に何度も直面したこの問題に、改めて取り組むことにしました。原因は「issue が散らかっていること」だった僕たちが開発している EC Booster は、ショッピング広告の自動運用やデータフィードの更新など、様々なジョブが裏で動いています。そのため、運用作業が日々発生し、運用の中で見つかる例外ケースやバグの修正が多々あります。また、フロントエンドとバックエンドを全員が開発するため、１つのリポジトリで管理していることもあり、色々な種類の issue が１つのレーンに入り乱れてしまっていました。そのため、優先順位を付けるのも難しく、また「次スプリントで何をどこまでやるか？」を判断するのが難しくなってしまっていました。プロダクトバックログを整理しなければ、というのは分かっているのですが、スクラムに関する本やブログには整理の方法は書いてありません。どうやって整理したら分かりやすくなるかな...と考えていたところ、同僚が共有してくれた以下の記事が参考になりました。エンジニア歴17年の俺が、事業系の開発タスクをバンバン投げてくる非エンジニアに、保守の必要性を死ぬほど分かりやすく説明する。この記事の中で「issueには \"種類\" がある」と言っていて、issue の種類別に整理された図が載っていました。これだ...！issue をグルーピング、優先順位はそれぞれで上記の記事を参考に、issue を 新機能開発、バグ修正/運用改善、ライブラリーアップデート に分けて、それぞれのレーンで優先順位を付けるようにしました。issue をグルーピング、優先順位はそれぞれでissue の種類が同じなので、優先順位を付けるのは簡単です。さらに、スプリントバックログに入れるタスクを 新機能開発：運用系 = ６：４ の割合にする、という決めを作りました。さらに、何回かスプリントを回してベロシティも見えてきました。ここまで情報が揃うと 次のスプリントで何をやるか決める基準 ができてきます。そもそもの「次のプランニングでどの issue について話すか？」というのも、それぞれのレーンで優先順位が高い issue を６：４のバランスとベロシティを参考に選べるようになりました。プランニングの前にプロダクトオーナーが（開発チームと協力しながら）当たりを付けておくことで、プランニングで話すトピックを事前に共有できるようになり、開発メンバーそれぞれが事前に頭を整理しておくこともできるようになりました。これにより、プランニングがかなりスムーズに進むようになったので、いよいよスクラムが回り始めました。新機能開発はモブプロの同期的な開発で、それ以外のタスクは個人タスク⇢レビューという非同期な開発で進められるようになり、デリバリーの最大化を目指しつつ、個人の稼働率も上げられるようになりました。GitHub Project を使ってタスク管理してる様子...横に長いんですが、情報が整理されてる方が優先順位を付けやすいまとめissue をグルーピングしそれぞれで優先順位を付けたことで、プランニングが時間内に収まるようになっただけでなく、プランニングで話すトピックを絞ったことでより深い議論をすることができるようになりました。今は「モブプロを取り入れたスクラム」がとても良い感じに回っています！↓ EC Booster チームでの「スプリントの回し方」資料を公開しているので、気になった方はぜひ見てみてください！（もっとこうしたら良いよ！という助言などあれば頂けると嬉しいです！）こんな感じ開発している EC Booster ですが、ただ今 バックエンド（Ruby, Rails）が得意なエンジニアを猛烈に必要としています！！！もしちょっっっとでも興味があれば、 僕とお話しましょう！ 以下から気軽に応募してください！https://open.talentio.com/1/c/feedforce/requisitions/detail/19785最後まで読んでいただき、ありがとうございました！*1:ストーリーポイント：プロダクトバックログ（タスク）を見積もるためにチームが使う単位で、前回の見積もりに対する相対評価を用いる*2:ベロシティ：スプリントの期間でチームが届けることができる見積もり（ストーリーポイント）の合計のこと*3:プロダクトオーナー：プロダクトバックログの管理をする人で、優先順位を付けることに責任を持つ（１人の人間が務める、委員会ではない）*4:バックログリファインメント：プランニングの前にプロダクトバックログを見直し、プランニング可能な状態にしておくこと","link":"https://developer.feedforce.jp/entry/2021/05/31/104813","isoDate":"2021-05-31T01:48:13.000Z","dateMiliSeconds":1622425693000,"imageUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sukechannnn/20210526/20210526215948.png","authorName":"feedforce"},{"title":"エンジニアキャリアパスをアップデートしました","content":"\u003cp\u003eこんにちは、\u003ca href=\"https://twitter.com/meihong\"\u003emeihong\u003c/a\u003e です。\u003c/p\u003e\n\n\u003cp\u003e株式会社フィードフォースでは\u003ca href=\"https://media.feedforce.jp/n/nc7a2e89635eb\"\u003e定期評価ではなく本人の希望するタイミングで評価を行う制度\u003c/a\u003eを導入しています。具体的には、各等級ごとに満たすべき基準・条件、またはスキルがあらかじめ提示されており、それを満たしていれば次の等級に進める制度になります。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fmedia.feedforce.jp%2Fn%2Fn222a08fd3e2b\" title=\"半年に1回の評価制度を毎月の評価制度に変えた話｜フィードフォースのnote\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://media.feedforce.jp/n/n222a08fd3e2b\"\u003emedia.feedforce.jp\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eこの基準やスキルを私たちはキャリアパスと呼んでいますが、今回、エンジニアのキャリアパスをアップデートしましたのでご紹介したいと思います。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/m/meihong/20210524/20210524010544.png\" alt=\"f:id:meihong:20210524010544p:plain\" width=\"1200\" height=\"630\" loading=\"lazy\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003ch2\u003eなぜキャリアパスをアップデートしたのか\u003c/h2\u003e\n\n\u003cp\u003eもともとのキャリアパスは\u003ca href=\"https://media.feedforce.jp/n/n222a08fd3e2b\"\u003e導入当初に設計されたもの\u003c/a\u003eをベースに、マネージャやエンジニア、新規事業向けエンジニアといった個々人の志向に応じて細分化されていました。\u003c/p\u003e\n\n\u003cp\u003eこれはこれでよくできたものだったのですが、しばらく運用している中でいくつかの課題点を感じるようになってきました。\n例えば、\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e志向ごとに分かれすぎていて、志向を横断した動きが想定しづらくなった。\u003c/li\u003e\n\u003cli\u003e独り立ちと判断される等級であるメンバーとその一つ上のシニアの境界に「見えない高い壁」が存在するようになった。\u003c/li\u003e\n\u003cli\u003eシニア以上の等級になるとチームや会社を牽引することを求められ、技術をそれ以上深掘りすることに対して会社がどう考えているのかが見えづらくなった。\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eといったところです。\u003c/p\u003e\n\n\u003cp\u003e特にキャリアパス全体として、職種問わず等級が上がれば上がるほどチームや会社への影響力が求められる設計になっています。\u003c/p\u003e\n\n\u003cp\u003eもちろんエンジニアも全体への影響力は持つべきなのですが、その持ち方は他の職種と異なり、技術力の広さ、深さといった持ち方もあるのではないかと考えるようになりました。\u003c/p\u003e\n\n\u003cp\u003eここで、個人的にはプロフェッショナルとしてのスキルは体積であり、その底面積はスキルの幅広さだと考えています。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/m/meihong/20210523/20210523235853.png\" alt=\"f:id:meihong:20210523235853p:plain\" width=\"1200\" height=\"731\" loading=\"lazy\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003e極端に底面積が狭いのはさすがに現時点では厳しいとは思いますが、\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e底面積がそれなりである代わりに高さ(= 深さ)がある\u003c/li\u003e\n\u003cli\u003e底面積が広い (= 引き出しが多い) 反面高さはそこまででもない\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eの両者は体積という意味では同じはずです。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/m/meihong/20210524/20210524000640.png\" alt=\"f:id:meihong:20210524000640p:plain\" width=\"1200\" height=\"576\" loading=\"lazy\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003eこの両者が共存できる余地が欲しいと考えていました。\u003c/p\u003e\n\n\u003cp\u003eそんな中、弊社デザイナーのキャリアパスがアップデートされました。その中でも目を引いたのは、必須スキルと専門スキルという考え方です。\u003c/p\u003e\n\n\u003cp\u003e必須スキルはデザイナーとして必ず持っていて欲しいスキルである一方、専門スキルは本人の志向、特性に応じてピックアップできるというもので、大学の専攻を思い出す建て付けでした。\u003c/p\u003e\n\n\u003cp\u003e\u003cs\u003eこれをパクる\u003c/s\u003eこれにインスパイアされて、エンジニアのキャリアパスもアップデートすることにしました。\u003c/p\u003e\n\n\u003ch2\u003eどのように更新したのか\u003c/h2\u003e\n\n\u003cp\u003e結果から先にお伝えしておくと、大まかに以下のような方向性に改訂しました。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e志向ごとのキャリアパスは止めた。\u003c/li\u003e\n\u003cli\u003e旧来の「志向」を専門スキルに分解し、専門スキルの組み合わせで個々人の志向・特性を表現できるようにした。\u003c/li\u003e\n\u003cli\u003e等級が上がれば上がるほど満たすべき専門スキルの最低数が増えるようにした。\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eその結果として、例えば\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eバックエンドエンジニアに特化\u003c/li\u003e\n\u003cli\u003eフルスタックエンジニア\u003c/li\u003e\n\u003cli\u003eフルスタックな知識をベースに事業の 0 → 1 フェイズに参画できるエンジニア\u003c/li\u003e\n\u003cli\u003eカスタマーサクセスエンジニア\u003c/li\u003e\n\u003cli\u003eアジャイルコーチ\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eといった、実際に社内に存在している各エンジニアの志向や得意なポイントを表現できるようになりました。\u003c/p\u003e\n\n\u003ch2\u003e産みの苦しみ\u003c/h2\u003e\n\n\u003cp\u003eここに至るまでには色々な葛藤がありました。\n社内の esa にキャリアパスを更新したいと宣言はしたものの、社内のエンジニア個々人の顔を思い浮かべつつ何を専門スキルとして設定するかを考えると想像以上に難しい問題だということに気付きました。\u003c/p\u003e\n\n\u003ch3\u003e必須スキルと専門スキル\u003c/h3\u003e\n\n\u003cp\u003eそもそも必須スキルと専門スキルとは何か、そこの定義から考えることにしました。\u003c/p\u003e\n\n\u003cp\u003e必須スキルとは文字通り、全てのエンジニアが共通に要求されるスキルセットのことです。どちらかというと「バックエンド」「フロントエンド」といった用語で定義されるスキルセットというよりも「フィードフォースに所属するエンジニアとしての振る舞い方」ではないでしょうか。\u003c/p\u003e\n\n\u003cp\u003eそう考えながら改訂前のキャリアパスを改めて眺めていると、改訂前のキャリアパスはその振る舞いを定義していることに気付きました。その結果、改訂前のキャリアパスが必須スキルのベースとなりました。\u003c/p\u003e\n\n\u003cp\u003eそうです、キャリアパスの改訂によって、より要求水準が上がったとも言えます。\u003c/p\u003e\n\n\u003cp\u003e一方、専門スキルは、本人の得意分野、志向、特性を定義するものです。\nその志向・方向性で貢献するのであれば、各等級ごとにどの水準の成果を出すべきか。それを定義するものが専門スキルになります。\u003c/p\u003e\n\n\u003ch3\u003e専門スキルとはどうあるべきか\u003c/h3\u003e\n\n\u003cp\u003e本人の志向を定義するものが専門スキルと説明しましたが、例えばカスタマーサクセスエンジニアやエンジニアリングマネージャといった職種にしてもエンジニアの延長である以上はエンジニアとしての「共通言語」を身につけているべきです。\u003c/p\u003e\n\n\u003cp\u003eその「共通言語」とは、例えば設計力であったり、フロントエンドやバックエンドのスキルが該当します。\u003c/p\u003e\n\n\u003cp\u003eこういった知識を前提として例えば事業開発であったりチームビルディングを行うべきで、これらの知識がなければエンジニアとの「共通言語」を持っていないと判断せざるを得ません。\u003c/p\u003e\n\n\u003cp\u003e一方で、「フロントエンド力」と「バックエンド力」が同じくらい強いエンジニアというのは SSR エンジニアで、そうそう市場には存在しません。そこで、フルスタックとはいえどこかの分野に軸足を置くことができる制度というのも必須に感じました。\u003c/p\u003e\n\n\u003cp\u003eただ、ここの軸足とはあくまでも「フロントエンド」「バックエンド」「インフラ」といった区分けで、エンジニアとしてコードを書き続ける選択をするのであれば、フロントエンド/バックエンド/インフラといった区分に関係なく設計力・実装力が担保されているべきでしょう。\u003c/p\u003e\n\n\u003ch3\u003e17 の専門スキル\u003c/h3\u003e\n\n\u003cp\u003eここのバランス感が非常に難しい点でしたが、これを元に 17 の専門スキルを定義しました。\nただし、17 の専門スキルは完全に独立しているわけではなく、以下 6 つは本人の志向を定義するものとして、必ずどれか一つが必須選択としました。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eバックエンド\u003c/li\u003e\n\u003cli\u003eフロントエンド\u003c/li\u003e\n\u003cli\u003eデータベース\u003c/li\u003e\n\u003cli\u003e基盤\u003c/li\u003e\n\u003cli\u003eカスタマーサクセス\u003c/li\u003e\n\u003cli\u003e組織支援\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eさらに、上記のうち以下 4 つを選択した場合は「実装・設計」と呼ばれるスキルが必須となります。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eバックエンド\u003c/li\u003e\n\u003cli\u003eフロントエンド\u003c/li\u003e\n\u003cli\u003eデータベース\u003c/li\u003e\n\u003cli\u003e基盤\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eこれにより、コードを書き続けるのであればただコードを書くだけでなく、実装力・設計力が要求される建て付けを実現しました。\u003c/p\u003e\n\n\u003cp\u003eまた、詳細は省きますが、さらにいくつかの例外を設置することで、「全ての分野で等しく強い SSR なフルスタックエンジニア」が求められないようにしています。\u003c/p\u003e\n\n\u003chr /\u003e\n\n\u003cp\u003e様々なエッジケースを考慮したせいでちょっと複雑になった感の否めない新しいキャリアパスですが、以前のものと比べるとその分より柔軟なものになったと思います。\u003c/p\u003e\n\n\u003cp\u003e今回は敢えて詳細を省きましたが、\u003ca href=\"https://engineers.recruit.feedforce.jp/#entry\"\u003eご興味をお持ちいただけたら是非カジュアル面談でねっちょりとご説明します\u003c/a\u003e！\u003c/p\u003e\n","contentSnippet":"こんにちは、meihong です。株式会社フィードフォースでは定期評価ではなく本人の希望するタイミングで評価を行う制度を導入しています。具体的には、各等級ごとに満たすべき基準・条件、またはスキルがあらかじめ提示されており、それを満たしていれば次の等級に進める制度になります。media.feedforce.jpこの基準やスキルを私たちはキャリアパスと呼んでいますが、今回、エンジニアのキャリアパスをアップデートしましたのでご紹介したいと思います。なぜキャリアパスをアップデートしたのかもともとのキャリアパスは導入当初に設計されたものをベースに、マネージャやエンジニア、新規事業向けエンジニアといった個々人の志向に応じて細分化されていました。これはこれでよくできたものだったのですが、しばらく運用している中でいくつかの課題点を感じるようになってきました。例えば、志向ごとに分かれすぎていて、志向を横断した動きが想定しづらくなった。独り立ちと判断される等級であるメンバーとその一つ上のシニアの境界に「見えない高い壁」が存在するようになった。シニア以上の等級になるとチームや会社を牽引することを求められ、技術をそれ以上深掘りすることに対して会社がどう考えているのかが見えづらくなった。といったところです。特にキャリアパス全体として、職種問わず等級が上がれば上がるほどチームや会社への影響力が求められる設計になっています。もちろんエンジニアも全体への影響力は持つべきなのですが、その持ち方は他の職種と異なり、技術力の広さ、深さといった持ち方もあるのではないかと考えるようになりました。ここで、個人的にはプロフェッショナルとしてのスキルは体積であり、その底面積はスキルの幅広さだと考えています。極端に底面積が狭いのはさすがに現時点では厳しいとは思いますが、底面積がそれなりである代わりに高さ(= 深さ)がある底面積が広い (= 引き出しが多い) 反面高さはそこまででもないの両者は体積という意味では同じはずです。この両者が共存できる余地が欲しいと考えていました。そんな中、弊社デザイナーのキャリアパスがアップデートされました。その中でも目を引いたのは、必須スキルと専門スキルという考え方です。必須スキルはデザイナーとして必ず持っていて欲しいスキルである一方、専門スキルは本人の志向、特性に応じてピックアップできるというもので、大学の専攻を思い出す建て付けでした。これをパクるこれにインスパイアされて、エンジニアのキャリアパスもアップデートすることにしました。どのように更新したのか結果から先にお伝えしておくと、大まかに以下のような方向性に改訂しました。志向ごとのキャリアパスは止めた。旧来の「志向」を専門スキルに分解し、専門スキルの組み合わせで個々人の志向・特性を表現できるようにした。等級が上がれば上がるほど満たすべき専門スキルの最低数が増えるようにした。その結果として、例えばバックエンドエンジニアに特化フルスタックエンジニアフルスタックな知識をベースに事業の 0 → 1 フェイズに参画できるエンジニアカスタマーサクセスエンジニアアジャイルコーチといった、実際に社内に存在している各エンジニアの志向や得意なポイントを表現できるようになりました。産みの苦しみここに至るまでには色々な葛藤がありました。社内の esa にキャリアパスを更新したいと宣言はしたものの、社内のエンジニア個々人の顔を思い浮かべつつ何を専門スキルとして設定するかを考えると想像以上に難しい問題だということに気付きました。必須スキルと専門スキルそもそも必須スキルと専門スキルとは何か、そこの定義から考えることにしました。必須スキルとは文字通り、全てのエンジニアが共通に要求されるスキルセットのことです。どちらかというと「バックエンド」「フロントエンド」といった用語で定義されるスキルセットというよりも「フィードフォースに所属するエンジニアとしての振る舞い方」ではないでしょうか。そう考えながら改訂前のキャリアパスを改めて眺めていると、改訂前のキャリアパスはその振る舞いを定義していることに気付きました。その結果、改訂前のキャリアパスが必須スキルのベースとなりました。そうです、キャリアパスの改訂によって、より要求水準が上がったとも言えます。一方、専門スキルは、本人の得意分野、志向、特性を定義するものです。その志向・方向性で貢献するのであれば、各等級ごとにどの水準の成果を出すべきか。それを定義するものが専門スキルになります。専門スキルとはどうあるべきか本人の志向を定義するものが専門スキルと説明しましたが、例えばカスタマーサクセスエンジニアやエンジニアリングマネージャといった職種にしてもエンジニアの延長である以上はエンジニアとしての「共通言語」を身につけているべきです。その「共通言語」とは、例えば設計力であったり、フロントエンドやバックエンドのスキルが該当します。こういった知識を前提として例えば事業開発であったりチームビルディングを行うべきで、これらの知識がなければエンジニアとの「共通言語」を持っていないと判断せざるを得ません。一方で、「フロントエンド力」と「バックエンド力」が同じくらい強いエンジニアというのは SSR エンジニアで、そうそう市場には存在しません。そこで、フルスタックとはいえどこかの分野に軸足を置くことができる制度というのも必須に感じました。ただ、ここの軸足とはあくまでも「フロントエンド」「バックエンド」「インフラ」といった区分けで、エンジニアとしてコードを書き続ける選択をするのであれば、フロントエンド/バックエンド/インフラといった区分に関係なく設計力・実装力が担保されているべきでしょう。17 の専門スキルここのバランス感が非常に難しい点でしたが、これを元に 17 の専門スキルを定義しました。ただし、17 の専門スキルは完全に独立しているわけではなく、以下 6 つは本人の志向を定義するものとして、必ずどれか一つが必須選択としました。バックエンドフロントエンドデータベース基盤カスタマーサクセス組織支援さらに、上記のうち以下 4 つを選択した場合は「実装・設計」と呼ばれるスキルが必須となります。バックエンドフロントエンドデータベース基盤これにより、コードを書き続けるのであればただコードを書くだけでなく、実装力・設計力が要求される建て付けを実現しました。また、詳細は省きますが、さらにいくつかの例外を設置することで、「全ての分野で等しく強い SSR なフルスタックエンジニア」が求められないようにしています。様々なエッジケースを考慮したせいでちょっと複雑になった感の否めない新しいキャリアパスですが、以前のものと比べるとその分より柔軟なものになったと思います。今回は敢えて詳細を省きましたが、ご興味をお持ちいただけたら是非カジュアル面談でねっちょりとご説明します！","link":"https://developer.feedforce.jp/entry/career_path_revised_2021","isoDate":"2021-05-24T02:00:00.000Z","dateMiliSeconds":1621821600000,"imageUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/m/meihong/20210524/20210524010544.png","authorName":"feedforce"},{"title":"広告の複数媒体に対するCPA最小化・ROAS最大化となる予算配分を計算しよう","content":"\u003cp\u003eこんにちは　機械学習エンジニアの\u003ca href=\"https://twitter.com/feed_yao\"\u003e八百俊哉\u003c/a\u003eです。\u003c/p\u003e\n\n\u003cp\u003e今回は複数媒体へ広告を出稿する際に、多くの方が悩まれるであろう「各媒体への予算配分」に関して有効な配分手法を紹介します。\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e今回の記事で登場する広告用語\u003c/strong\u003e\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e媒体・・・広告の配信先や配信手法\u003c/li\u003e\n\u003cli\u003eROAS・・・広告経由で発生した売り上げを広告費用で割った値(広告の費用対効果)\u003c/li\u003e\n\u003cli\u003eCPA・・・1件のコンバージョン(目標)を獲得するのにかかった広告コスト\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003ch1\u003e広告運用者が抱える課題とは？\u003c/h1\u003e\n\n\u003cp\u003e1つの媒体のみで運用している場合は別ですが、\u003cstrong\u003e複数の媒体で広告配信を行っている場合は、どの媒体に対していくら予算を割り振れば良いのかわからない場合があると思います。\u003c/strong\u003e\u003c/p\u003e\n\n\u003cp\u003e過去の実績を元に成果が良い媒体に対して、多く予算を割り振れば良いことは理解しているものの、\u003cstrong\u003e「どれくらい」「どの媒体から」予算を割り振れば良いのか\u003c/strong\u003eは経験則や簡単な分析で決めている方も多いのではないでしょうか？\u003c/p\u003e\n\n\u003cp\u003e今回はこれらの課題を解決するために、\u003cstrong\u003e数学的に根拠のある予算配分方法\u003c/strong\u003eについて紹介しようと思います。\u003c/p\u003e\n\n\u003cp\u003eまず今回の手法を紹介するにあたり、例題がある方が話が進めやすいので以下の広告運用者さんを例に考えます。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e広告運用者○○さん\n\n現在A,B,Cの３媒体で広告配信を行っています。\n\n全体のROASを高めるために予算配分を見直したいと考えています。\n\n３媒体での合計予算は3万円です。\u003c/pre\u003e\n\n\n\u003cp\u003eでは、実際にどのようにして最適な予算を求めるのか見ていきましょう。\u003c/p\u003e\n\n\u003ch1\u003e過去の実績から各媒体の実績をシミュレーションします\u003c/h1\u003e\n\n\u003cp\u003e最初に過去の実績から各媒体での予算とROASの傾向を、式で表現します。\u003c/p\u003e\n\n\u003cp\u003eここで\u003cstrong\u003eROASを最大化するということは、限られた予算の中で売り上げを最大化すると言い換えることができる\u003c/strong\u003eので、今回は \u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20%28%E4%BA%88%E7%AE%97%2C%E5%A3%B2%E3%82%8A%E4%B8%8A%E3%81%92%29\" alt=\" (\u0026#x4E88;\u0026#x7B97;,\u0026#x58F2;\u0026#x308A;\u0026#x4E0A;\u0026#x3052;)\"/\u003e を2次回帰で近似します。\u003c/p\u003e\n\n\u003cp\u003e今回の例だと媒体A,B,Cに対してそれぞれ近似式が用意できるので以下のように表現できます。(各媒体の予算を\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20x_1%2Cx_2%2Cx_3\" alt=\" x_1,x_2,x_3\"/\u003eとします)\u003c/p\u003e\n\n\u003cdiv align=\"center\"\u003e\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20%5Cdisplaystyle%0AA%E3%81%AE%E5%A3%B2%E3%82%8A%E4%B8%8A%E3%81%92%28x_1%29%20%3D%20a_A%20x_1%5E2%20%2B%20b_A%20x_1%0A\" alt=\" \\displaystyle\nA\u0026#x306E;\u0026#x58F2;\u0026#x308A;\u0026#x4E0A;\u0026#x3052;(x_1) = a_A x_1^2 + b_A x_1\n\"/\u003e\n\u003c/div\u003e\n\n\n\n\n\u003cdiv align=\"center\"\u003e\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20%5Cdisplaystyle%0AB%E3%81%AE%E5%A3%B2%E3%82%8A%E4%B8%8A%E3%81%92%28x_2%29%20%3D%20a_B%20x_2%5E2%20%2B%20b_B%20x_2%0A\" alt=\" \\displaystyle\nB\u0026#x306E;\u0026#x58F2;\u0026#x308A;\u0026#x4E0A;\u0026#x3052;(x_2) = a_B x_2^2 + b_B x_2\n\"/\u003e\n\u003c/div\u003e\n\n\n\n\n\u003cdiv align=\"center\"\u003e\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20%5Cdisplaystyle%0AC%E3%81%AE%E5%A3%B2%E3%82%8A%E4%B8%8A%E3%81%92%28x_3%29%20%3D%20a_C%20x_3%5E2%20%2B%20b_C%20x_3%0A\" alt=\" \\displaystyle\nC\u0026#x306E;\u0026#x58F2;\u0026#x308A;\u0026#x4E0A;\u0026#x3052;(x_3) = a_C x_3^2 + b_C x_3\n\"/\u003e\n\u003c/div\u003e\n\n\n\u003cp\u003e\u003cbr\u003e\n予算が0円の時は、原点を通る(売り上げが0円)になるように切片は使用していないです。\u003c/p\u003e\n\n\u003ch1\u003eラグランジュの未定乗数法を用いて最適な予算配分を見つける\u003c/h1\u003e\n\n\u003ch2\u003eラグランジュの未定乗数法とは？\u003c/h2\u003e\n\n\u003cp\u003eラグランジュの未定乗数法とは、\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003e束縛条件のもとで最適化を行うための数学的な方法である。いくつかの変数に対して、いくつかの関数の値を固定するという束縛条件のもとで、別のある1つの関数の極値を求める\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fja.wikipedia.org%2Fwiki%2F%25E3%2583%25A9%25E3%2582%25B0%25E3%2583%25A9%25E3%2583%25B3%25E3%2582%25B8%25E3%2583%25A5%25E3%2581%25AE%25E6%259C%25AA%25E5%25AE%259A%25E4%25B9%2597%25E6%2595%25B0%25E6%25B3%2595\" title=\"ラグランジュの未定乗数法 - Wikipedia\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://ja.wikipedia.org/wiki/%E3%83%A9%E3%82%B0%E3%83%A9%E3%83%B3%E3%82%B8%E3%83%A5%E3%81%AE%E6%9C%AA%E5%AE%9A%E4%B9%97%E6%95%B0%E6%B3%95\"\u003eja.wikipedia.org\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003e少し小難しく聞こえますが、今回の例題に当てはめて考えてみます。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003eいくつかの変数に対して(各媒体の予算)\n\nいくつかの関数の値を固定する束縛条件(3媒体の総予算は3万円)\n\n別のある関数の極値を求める(3媒体の売り上げが最大となるポイントを求める)\u003c/pre\u003e\n\n\n\u003cp\u003eラグランジュの未定乗数法とは、上のような条件を満たす予算\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20x_1%2Cx_2%2Cx_3\" alt=\" x_1,x_2,x_3\"/\u003eを見つけてくれる手法です。\u003c/p\u003e\n\n\u003cp\u003eラグランジュの未定乗数法では、媒体A,B,Cのそれぞれの\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20%28%E4%BA%88%E7%AE%97%2C%E5%A3%B2%E3%82%8A%E4%B8%8A%E3%81%92%29\" alt=\" (\u0026#x4E88;\u0026#x7B97;,\u0026#x58F2;\u0026#x308A;\u0026#x4E0A;\u0026#x3052;)\"/\u003e に対して\u003cstrong\u003e近似式が二階微分可能である必要がある\u003c/strong\u003eため、今回の例では2次回帰で近似を行いました。\u003c/p\u003e\n\n\u003cp\u003eまた今回は、\u003cstrong\u003e3媒体の総予算(束縛条件)が広告によって全て使用される\u003c/strong\u003eという仮説のもとで計算しています。予算を全て使わない場合は、計算が複雑になってしまうので今回は紹介しません。\u003c/p\u003e\n\n\u003ch2\u003e実際にどのように計算するのか検証します\u003c/h2\u003e\n\n\u003cp\u003eまず初めに束縛条件\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20x_1%2Cx_2%2Cx_3\" alt=\" x_1,x_2,x_3\"/\u003e を定義します。今回の束縛条件は、それぞれの予算\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20x_1%2Cx_2%2Cx_3\" alt=\" x_1,x_2,x_3\"/\u003eを足し合わせたものが30000円になるということですので、以下のように書けます。\u003c/p\u003e\n\n\u003cdiv align=\"center\"\u003e\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20%0Ax_1%20%2B%20x_2%20%2B%20x_3%20%3D%2030000%0A%5Ctag%7B1%7D%0A\" alt=\" \nx_1 + x_2 + x_3 = 30000\n\\tag{1}\n\"/\u003e\u003c/div\u003e\n\n\n\u003cp\u003e\u003cbr\u003e\nここで式(1)を変換し、\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20g%28x_1%2Cx_2%2Cx_3%29\" alt=\" g(x_1,x_2,x_3)\"/\u003eとおきます。\u003c/p\u003e\n\n\u003cdiv align=\"center\"\u003e\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%0Ag%28x_1%2Cx_2%2Cx_3%29%20%3D%20x_1%20%2B%20x_2%20%2B%20x_3%20-%2030000%20%3D%200%0A\" alt=\"\ng(x_1,x_2,x_3) = x_1 + x_2 + x_3 - 30000 = 0\n\"/\u003e\u003c/div\u003e\n\n\n\u003cp\u003e\u003cbr\u003e\nまた、今回最大にしたい3媒体の総売り上げを\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20f%28x_1%2Cx_2%2Cx_3%29\" alt=\" f(x_1,x_2,x_3)\"/\u003eと置きます。\u003c/p\u003e\n\n\u003cdiv align=\"center\"\u003e\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%0A%5Cbegin%7Baligned%7D%0A%20f%28x_1%2Cx_2%2Cx_3%29%20%26%3D%20A%E3%81%AE%E5%A3%B2%E3%82%8A%E4%B8%8A%E3%81%92%28x_1%29%20%2B%20B%E3%81%AE%E5%A3%B2%E3%82%8A%E4%B8%8A%E3%81%92%28x_2%29%20%2B%20C%E3%81%AE%E5%A3%B2%E3%82%8A%E4%B8%8A%E3%81%92%28x_3%29%20%5C%5C%0A%26%3D%20a_A%20x_1%5E2%20%2B%20b_A%20x_1%20%2B%20a_B%20x_2%5E2%20%2B%20b_B%20x_2%20%2B%20a_C%20x_3%5E2%20%2B%20b_C%20x_3%0A%5Cend%7Baligned%7D%0A\" alt=\"\n\\begin{aligned}\n f(x_1,x_2,x_3) \u0026amp;= A\u0026#x306E;\u0026#x58F2;\u0026#x308A;\u0026#x4E0A;\u0026#x3052;(x_1) + B\u0026#x306E;\u0026#x58F2;\u0026#x308A;\u0026#x4E0A;\u0026#x3052;(x_2) + C\u0026#x306E;\u0026#x58F2;\u0026#x308A;\u0026#x4E0A;\u0026#x3052;(x_3) \\\\\n\u0026amp;= a_A x_1^2 + b_A x_1 + a_B x_2^2 + b_B x_2 + a_C x_3^2 + b_C x_3\n\\end{aligned}\n\"/\u003e\u003c/div\u003e\n\n\n\u003cp\u003e\u003cbr\u003e\nここで未定乗数\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20%5Clambda%20\" alt=\" \\lambda \"/\u003eと\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20f%28x_1%2Cx_2%2Cx_3%29%2Cg%28x_1%2Cx_2%2Cx_3%29\" alt=\" f(x_1,x_2,x_3),g(x_1,x_2,x_3)\"/\u003eを用いてラグランジュ関数\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20L\" alt=\" L\"/\u003eを作ります。\u003c/p\u003e\n\n\u003cdiv align=\"center\"\u003e\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%0A%5Cbegin%7Baligned%7D%0AL%28x_1%2Cx_2%2Cx_3%2C%5Clambda%29%20%26%3D%20a_A%20x_1%5E2%20%2B%20b_A%20x_1%20%2B%20a_B%20x_2%5E2%20%2B%20b_B%20x_2%20%2B%20a_C%20x_3%5E2%20%2B%20b_C%20x_3%20-%20%5Clambda%20%28x_1%20%2B%20x_2%20%2B%20x_3%20-%2030000%29%0A%5Cend%7Baligned%7D%0A\" alt=\"\n\\begin{aligned}\nL(x_1,x_2,x_3,\\lambda) \u0026amp;= a_A x_1^2 + b_A x_1 + a_B x_2^2 + b_B x_2 + a_C x_3^2 + b_C x_3 - \\lambda (x_1 + x_2 + x_3 - 30000)\n\\end{aligned}\n\"/\u003e\u003c/div\u003e\n\n\n\u003cp\u003e\u003cbr\u003e\nそれぞれの変数で偏微分すると以下のようになります。\u003c/p\u003e\n\n\u003cdiv align=\"center\"\u003e\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%0A%5Cbegin%7Baligned%7D%0A%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20x_1%7D%20%26%3D%202%20a_A%20x_1%20%2B%20b_A%20-%20%5Clambda%20%20%3D%200%5C%5C%0A%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20x_2%7D%20%26%3D%202%20a_B%20x_2%20%2B%20b_B%20-%20%5Clambda%20%3D%200%5C%5C%0A%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20x_3%7D%20%26%3D%202%20a_C%20x_3%20%2B%20b_C%20-%20%5Clambda%20%3D%200%5C%5C%0A%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20%5Clambda%7D%20%26%3D%20-%20x_1%20-%20x_2%20-%20x_3%20%2B%2030000%20%3D%200%5C%5C%0A%5Cend%7Baligned%7D%0A\" alt=\"\n\\begin{aligned}\n\\frac{\\partial L}{\\partial x_1} \u0026amp;= 2 a_A x_1 + b_A - \\lambda  = 0\\\\\n\\frac{\\partial L}{\\partial x_2} \u0026amp;= 2 a_B x_2 + b_B - \\lambda = 0\\\\\n\\frac{\\partial L}{\\partial x_3} \u0026amp;= 2 a_C x_3 + b_C - \\lambda = 0\\\\\n\\frac{\\partial L}{\\partial \\lambda} \u0026amp;= - x_1 - x_2 - x_3 + 30000 = 0\\\\\n\\end{aligned}\n\"/\u003e\u003c/div\u003e\n\n\n\u003cp\u003e\u003cbr\u003e\nこれら4変数の4元連立方程式を説くと、予算30000円で総売り上げが最大になる予算配分\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20x_1%2Cx_2%2Cx_3\" alt=\" x_1,x_2,x_3\"/\u003eが求まります。\u003c/p\u003e\n\n\u003cp\u003e今回は、ROASを最大化するための方法を紹介しましたがCPAを最小化する場合は2次回帰式を求める際に\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20%28cost%2Ccv%29\" alt=\" (cost,cv)\"/\u003eとしてcvを最大化するようにラグランジュを適応することで求めることができます。\u003c/p\u003e\n\n\u003cp\u003eまた今回の例では3媒体までの予算配分を計算しましたが、\u003cstrong\u003e媒体数を増やしても計算速度が極端に遅くなることがない\u003c/strong\u003eところが今回の手法の良いところです。\u003c/p\u003e\n\n\u003ch1\u003eこの手法の課題点\u003c/h1\u003e\n\n\u003cp\u003eここまで「ネット広告の複数媒体に対するCPA最小化・ROAS最大化となる予算配分」を紹介しましたが、この手法には2つほど課題があります。\u003c/p\u003e\n\n\u003cp\u003eまず一つ目が、最適予算\u003cimg src=\"https://chart.apis.google.com/chart?cht=tx\u0026chl=%20%28x_1%2Cx_2%2Cx_3%29\" alt=\" (x_1,x_2,x_3)\"/\u003eにマイナスの結果が得られる可能性があるということです。売り上げを最大化しようとするあまり、もともとROASが低い媒体に対しては予算を割り振らずにマイナスの予算を割り振り、そのほかのROASが高い媒体により多くの予算を割り振ろうとしてしまうことが確認できています。\u003c/p\u003e\n\n\u003cp\u003e次に、媒体の周期性や外部要因を一切考慮していないということです。広告は少なからず外部要因によって成果が左右されますが、この手法では過去の実績のみを用いて最適予算を割り振るので外部要因は一切考慮されていないということに注意が必要です。\u003c/p\u003e\n\n\u003ch1\u003eまとめ\u003c/h1\u003e\n\n\u003cp\u003eいかがだったでしょうか。\n今回は、ラグランジュの未定乗数法を用いて複数媒体への予算配分方法を紹介しました。流石に手作業では計算できないので私はpythonで上記の流れを実装しています。\u003c/p\u003e\n\n\u003cp\u003eラグランジュの未定乗数法は、理系の方は大学の数学の講義で習っていたかもしれないです。私も大学の時に習いましたが、当時は何に使うのか一切わかりませんでした。社会人になって学生の時に学んだことが活用できると、学んだ甲斐があったと感じることができて良いです。\u003c/p\u003e\n\n\u003cp\u003e最後まで読んでいただきありがとうございます。\u003c/p\u003e\n","contentSnippet":"こんにちは　機械学習エンジニアの八百俊哉です。今回は複数媒体へ広告を出稿する際に、多くの方が悩まれるであろう「各媒体への予算配分」に関して有効な配分手法を紹介します。今回の記事で登場する広告用語媒体・・・広告の配信先や配信手法ROAS・・・広告経由で発生した売り上げを広告費用で割った値(広告の費用対効果)CPA・・・1件のコンバージョン(目標)を獲得するのにかかった広告コスト広告運用者が抱える課題とは？1つの媒体のみで運用している場合は別ですが、複数の媒体で広告配信を行っている場合は、どの媒体に対していくら予算を割り振れば良いのかわからない場合があると思います。過去の実績を元に成果が良い媒体に対して、多く予算を割り振れば良いことは理解しているものの、「どれくらい」「どの媒体から」予算を割り振れば良いのかは経験則や簡単な分析で決めている方も多いのではないでしょうか？今回はこれらの課題を解決するために、数学的に根拠のある予算配分方法について紹介しようと思います。まず今回の手法を紹介するにあたり、例題がある方が話が進めやすいので以下の広告運用者さんを例に考えます。広告運用者○○さん現在A,B,Cの３媒体で広告配信を行っています。全体のROASを高めるために予算配分を見直したいと考えています。３媒体での合計予算は3万円です。では、実際にどのようにして最適な予算を求めるのか見ていきましょう。過去の実績から各媒体の実績をシミュレーションします最初に過去の実績から各媒体での予算とROASの傾向を、式で表現します。ここでROASを最大化するということは、限られた予算の中で売り上げを最大化すると言い換えることができるので、今回は  を2次回帰で近似します。今回の例だと媒体A,B,Cに対してそれぞれ近似式が用意できるので以下のように表現できます。(各媒体の予算をとします)ラグランジュの未定乗数法を用いて最適な予算配分を見つけるラグランジュの未定乗数法とは？ラグランジュの未定乗数法とは、束縛条件のもとで最適化を行うための数学的な方法である。いくつかの変数に対して、いくつかの関数の値を固定するという束縛条件のもとで、別のある1つの関数の極値を求めるja.wikipedia.org少し小難しく聞こえますが、今回の例題に当てはめて考えてみます。いくつかの変数に対して(各媒体の予算)いくつかの関数の値を固定する束縛条件(3媒体の総予算は3万円)別のある関数の極値を求める(3媒体の売り上げが最大となるポイントを求める)ラグランジュの未定乗数法とは、上のような条件を満たす予算を見つけてくれる手法です。ラグランジュの未定乗数法では、媒体A,B,Cのそれぞれの に対して近似式が二階微分可能である必要があるため、今回の例では2次回帰で近似を行いました。また今回は、3媒体の総予算(束縛条件)が広告によって全て使用されるという仮説のもとで計算しています。予算を全て使わない場合は、計算が複雑になってしまうので今回は紹介しません。実際にどのように計算するのか検証しますまず初めに束縛条件 を定義します。今回の束縛条件は、それぞれの予算を足し合わせたものが30000円になるということですので、以下のように書けます。ここで式(1)を変換し、とおきます。また、今回最大にしたい3媒体の総売り上げをと置きます。ここで未定乗数とを用いてラグランジュ関数を作ります。それぞれの変数で偏微分すると以下のようになります。これら4変数の4元連立方程式を説くと、予算30000円で総売り上げが最大になる予算配分が求まります。今回は、ROASを最大化するための方法を紹介しましたがCPAを最小化する場合は2次回帰式を求める際にとしてcvを最大化するようにラグランジュを適応することで求めることができます。また今回の例では3媒体までの予算配分を計算しましたが、媒体数を増やしても計算速度が極端に遅くなることがないところが今回の手法の良いところです。この手法の課題点ここまで「ネット広告の複数媒体に対するCPA最小化・ROAS最大化となる予算配分」を紹介しましたが、この手法には2つほど課題があります。まず一つ目が、最適予算にマイナスの結果が得られる可能性があるということです。売り上げを最大化しようとするあまり、もともとROASが低い媒体に対しては予算を割り振らずにマイナスの予算を割り振り、そのほかのROASが高い媒体により多くの予算を割り振ろうとしてしまうことが確認できています。次に、媒体の周期性や外部要因を一切考慮していないということです。広告は少なからず外部要因によって成果が左右されますが、この手法では過去の実績のみを用いて最適予算を割り振るので外部要因は一切考慮されていないということに注意が必要です。まとめいかがだったでしょうか。今回は、ラグランジュの未定乗数法を用いて複数媒体への予算配分方法を紹介しました。流石に手作業では計算できないので私はpythonで上記の流れを実装しています。ラグランジュの未定乗数法は、理系の方は大学の数学の講義で習っていたかもしれないです。私も大学の時に習いましたが、当時は何に使うのか一切わかりませんでした。社会人になって学生の時に学んだことが活用できると、学んだ甲斐があったと感じることができて良いです。最後まで読んでいただきありがとうございます。","link":"https://developer.feedforce.jp/entry/2021/05/13/093842","isoDate":"2021-05-17T00:38:42.000Z","dateMiliSeconds":1621211922000,"imageUrl":"https://cdn.user.blog.st-hatena.com/default_entry_og_image/4268819/1588226000876991","authorName":"feedforce"},{"title":"ふりかえりカンファレンスのスタッフをやりました！","content":"\u003cp\u003eこんにちは \u003ca href=\"http://blog.hatena.ne.jp/pokotyamu/\"\u003eid:pokotyamu\u003c/a\u003e です！\n最近は、モンハンライズにハマっています！ハンマー担いでブンブンしてます！\u003c/p\u003e\n\n\u003cp\u003e4月16日(土)に行われた「ふりかえりカンファレンス」のスタッフをやりました！\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/p/pokotyamu/20210416/20210416155303.png\" alt=\"f:id:pokotyamu:20210416155303p:plain\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003e今回はそこでの学びや感じたことを社内勉強会で発表したので、スライドとコメントをまとめます。\u003c/p\u003e\n\n\u003ch2\u003eFFTT 発表資料\u003c/h2\u003e\n\n\u003cscript async class=\"speakerdeck-embed\" data-id=\"1f772bfe5abd4fa28ff738df3a5e76a2\" data-ratio=\"1.77777777777778\" src=\"//speakerdeck.com/assets/embed.js\"\u003e\u003c/script\u003e\n\n\n\u003ch2\u003e勉強会の感想コメント\u003c/h2\u003e\n\n\u003cblockquote\u003e\u003cp\u003e なんのためにふりかえりやってるの？\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003e明日の自分やチームを1歩でも楽しくなるためにやってほしいですね！\n連続したサイクルの中にふりかえりを組み込むことで、安全に転んで、次の1歩を早く出せるようになると思います！\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003eオンラインセミナーは当日参加が多い\n結構人数集まったようなので準備とか大変そう\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003e場所の制約がなくなったのが非常に大きいですね〜！\n国内・国外関係なく、どこでもいけるのが本当に便利！\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003e振り返り手法ってあんなにたくさんあるのだなぁ\n振り返りの手法も多いようなのでどのタイミングで何を使うのが適切かを考えるの難しそう\n会社やチームよって向き不向きがありそうだけど、選ぶには知らないといけないので専門的な人がいる意味がよく分かる\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eそーなんですよね。\n次の Action を決めたい時や、関係構築したい時など、用途に合わせてやるのがいいと思います！\nもちろん KPT も素晴らしい手法なので、たまに気分を変えてみるみたいな感じでどうぞ！\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003e振り返りとの因果関係を感じられる強い人やチームの実例を見たら、もう少しイメージが付くのかな\nと思っていたが、21卒の方の日報をザッピングしていたら、振り返りが役に立った、楽しいという風に書かれていた\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003e今年は特に楽しいにフォーカスしてふりかえりをしているのもあると思います！\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003eオンラインカンファレンスのスタッフの話って結構レアな気がするので興味深かった\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003e楽しいのでぜひぜひ！\u003c/p\u003e\n\n\u003ch2\u003e感想\u003c/h2\u003e\n\n\u003cp\u003e私は、初めてカンファレンスのスタッフをやらせてもらったのですが、非常に楽しかったです！\n他の人の感想やブログレポートを見るのも、それそれ！その言葉待ってた！という感じでいつもの一般参加とは違う感覚で聞くことができました！\u003c/p\u003e\n\n\u003cp\u003e今回のスタッフを経験したことで、「楽しくふりかえる」の意味を体で感じることができたと思います。もちろん当日の発表もどれも素晴らしくてそれも含みで楽しかったところではありましたが ☺️\n気軽に試す、実験してみるを最近のふりかえりでも挑戦中です。\u003c/p\u003e\n\n\u003cp\u003eまた、オンラインカンファレンスということもあり、夜の2次会が3時ぐらいまで盛り上がっていたのも楽しかったポイントでした。\n新しいつながりも持てたので、社内の知見をどんどん外に発信して自分の魅力を高めていければと思います。\u003c/p\u003e\n\n\u003cp\u003e改めて、スタッフに誘っていただいた \u003ca href=\"https://twitter.com/viva_tweet_x\"\u003e@viva_tweet_x\u003c/a\u003e さんに改めて感謝です！ありがとうございました！これからもよろしくおねがいします！\u003c/p\u003e\n","contentSnippet":"こんにちは id:pokotyamu です！最近は、モンハンライズにハマっています！ハンマー担いでブンブンしてます！4月16日(土)に行われた「ふりかえりカンファレンス」のスタッフをやりました！今回はそこでの学びや感じたことを社内勉強会で発表したので、スライドとコメントをまとめます。FFTT 発表資料勉強会の感想コメント なんのためにふりかえりやってるの？明日の自分やチームを1歩でも楽しくなるためにやってほしいですね！連続したサイクルの中にふりかえりを組み込むことで、安全に転んで、次の1歩を早く出せるようになると思います！オンラインセミナーは当日参加が多い結構人数集まったようなので準備とか大変そう場所の制約がなくなったのが非常に大きいですね〜！国内・国外関係なく、どこでもいけるのが本当に便利！振り返り手法ってあんなにたくさんあるのだなぁ振り返りの手法も多いようなのでどのタイミングで何を使うのが適切かを考えるの難しそう会社やチームよって向き不向きがありそうだけど、選ぶには知らないといけないので専門的な人がいる意味がよく分かるそーなんですよね。次の Action を決めたい時や、関係構築したい時など、用途に合わせてやるのがいいと思います！もちろん KPT も素晴らしい手法なので、たまに気分を変えてみるみたいな感じでどうぞ！振り返りとの因果関係を感じられる強い人やチームの実例を見たら、もう少しイメージが付くのかなと思っていたが、21卒の方の日報をザッピングしていたら、振り返りが役に立った、楽しいという風に書かれていた今年は特に楽しいにフォーカスしてふりかえりをしているのもあると思います！オンラインカンファレンスのスタッフの話って結構レアな気がするので興味深かった楽しいのでぜひぜひ！感想私は、初めてカンファレンスのスタッフをやらせてもらったのですが、非常に楽しかったです！他の人の感想やブログレポートを見るのも、それそれ！その言葉待ってた！という感じでいつもの一般参加とは違う感覚で聞くことができました！今回のスタッフを経験したことで、「楽しくふりかえる」の意味を体で感じることができたと思います。もちろん当日の発表もどれも素晴らしくてそれも含みで楽しかったところではありましたが ☺️気軽に試す、実験してみるを最近のふりかえりでも挑戦中です。また、オンラインカンファレンスということもあり、夜の2次会が3時ぐらいまで盛り上がっていたのも楽しかったポイントでした。新しいつながりも持てたので、社内の知見をどんどん外に発信して自分の魅力を高めていければと思います。改めて、スタッフに誘っていただいた @viva_tweet_x さんに改めて感謝です！ありがとうございました！これからもよろしくおねがいします！","link":"https://developer.feedforce.jp/entry/2021/04/19/141153","isoDate":"2021-04-19T05:11:53.000Z","dateMiliSeconds":1618809113000,"imageUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/p/pokotyamu/20210416/20210416155303.png","authorName":"feedforce"},{"title":" 夜間光データから土地価格を予測 コンペの参加記録","content":"\u003cp\u003eこんにちは\n株式会社フィードフォース2020年入社の機械学習エンジニア\n\u003ca href=\"https://twitter.com/feed_yao\"\u003e八百　俊哉\u003c/a\u003eと申します。\u003c/p\u003e\n\n\u003cp\u003e今回は、solafuneで開催された「\u003ca href=\"https://solafune.com/#/competitions/f03f39cc-597b-4819-b1a5-41479d4b73d6\"\u003e夜間光データから土地価格を予測\u003c/a\u003e」という機械学習コンペに参加したので工夫した点や反省点などを紹介します。\u003c/p\u003e\n\n\u003cp\u003eコンペ参加の目標設定としては、「賞金獲得！！（4位以内）」を設定していましたが、36位/201人中と目標達成できませんでした。残念な結果に終わってしまいましたが、多くのことを学ぶことができました。\u003c/p\u003e\n\n\u003ch1\u003e参加経緯\u003c/h1\u003e\n\n\u003cp\u003e私は、2020年10月から2021年2月ごろまで顧客の課題解決のために機械学習を応用する方法を学ぶためにAI Questというイベントに参加していました。そのイベントをきっかけに私は精度の高いモデルや良い特徴量を作成することに興味を持ちました。\u003c/p\u003e\n\n\u003cp\u003eそこでより多くのコンペに参加することで精度を上げるためのノウハウを身に付けたいと思ったことが今回のコンペに参加したきっかけです。\u003c/p\u003e\n\n\u003cp\u003eまた、今回参加したコンペは与えられている特徴量が4つしかないので、初心者が参加しやすいコンペだったということも魅力的なポイントでした。\u003c/p\u003e\n\n\u003ch1\u003e課題と与えられているデータ\u003c/h1\u003e\n\n\u003cp\u003e課題としては、「夜間光データを元に土地価格を予測するアルゴリズムを開発する」というものです。\n使用可能なデータとしては、以下のものが与えられました。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e地域ごとのデータ・・・地域固有のID\u003c/li\u003e\n\u003cli\u003e年代・・・1992~2013年まで\u003c/li\u003e\n\u003cli\u003e土地の平均価格（目的変数）・・・1992~2013年まで\u003c/li\u003e\n\u003cli\u003e夜間光量の平均値・・・0~63までのレンジでその地域の平均光量\u003c/li\u003e\n\u003cli\u003e夜間光量の合計値・・・その地域の合計光量\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003ch1\u003e全体構成\u003c/h1\u003e\n\n\u003cp\u003e今回最終submitとして選択したモデルの全体構成は以下です。\n\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/n/newton800/20210409/20210409155716.png\" alt=\"f:id:newton800:20210409155716p:plain\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003ch1\u003e前処理に関して\u003c/h1\u003e\n\n\u003ch2\u003e集約的特徴量について\u003c/h2\u003e\n\n\u003cp\u003e集約的特徴量の作成にあたっては\u003ca href=\"https://twitter.com/mst_8823\"\u003emasato8823 (@mst_8823) | Twitter\u003c/a\u003eさんがBaseLineとして公開されていた以下のものを使用しました。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fzenn.dev%2Fmst8823%2Farticles%2Fcd40cb971f702e\" title=\"[solafune] 夜間光データから土地価格を予測 BaseLine\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://zenn.dev/mst8823/articles/cd40cb971f702e\"\u003ezenn.dev\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003e作成した特徴量としては以下です。\u003c/p\u003e\n\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e    \u003c/th\u003e\n\u003cth\u003e    \u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e  面積  \u003c/td\u003e\n\u003ctd\u003e  夜間光量の合計値/夜間光量の平均値を行い面積を算出した \u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e   PlaceID,Yearごとの統計情報 \u003c/td\u003e\n\u003ctd\u003e  PlaceID,Yearをキーとして平均光量、合計光量、面積のmin,max,median,mean,std,max-min,q75-q25を算出した  \u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e PlaceID をキーにしたグループ内差分\u003c/td\u003e\n\u003ctd\u003e  平均光量、合計光量の年ごとの差分を算出した\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ePlaceID をキーにしたグループ内シフト \u003c/td\u003e\n\u003ctd\u003e 平均光量、合計光量の年ごとの値をシフトした\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eピボットテーブルを用いた特徴量\u003c/td\u003e\n\u003ctd\u003eindex=PlaceID,columns=Yearとして平均光量、合計光量、面積のピボットテーブルを作成し、PCAで次元削減したものを算出した\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ePlaceIDをキーにしたグループ内相関係数\u003c/td\u003e\n\u003ctd\u003ePlaceIDごとにデータを集約しYearと平均光量、合計光量、面積との相関係数を算出した\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e平均光量が63であった回数\u003c/td\u003e\n\u003ctd\u003e平均光量の最大値が63であることから平均光量が63である数を追加した\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\n\n\u003ch2\u003eArea特徴量について\u003c/h2\u003e\n\n\u003cp\u003e先ほど\u003ci\u003e集約的特徴量について\u003c/i\u003eで面積の求め方について書きました。面積=合計光量/平均光量で算出しています。ここで求められる\u003cb\u003e土地の面積は、年が変化しようと変化しないと思われますが、実際のデータを確認すると年が変化すると面積も変化していました。\u003c/b\u003e\u003c/p\u003e\n\n\u003cp\u003eそこで\u003cb\u003e合計光量/平均光量より算出された面積をPlaceIDをキーとして平均を取ったものを新たな面積としました。\u003c/b\u003e\n新たな面積が求まると \u003cb\u003e新たな合計光量 =  平均光量×新たな面積,新たな平均面積 = 合計光量/新たな面積\u003c/b\u003e が求まります。\u003c/p\u003e\n\n\u003cp\u003eこれらより求まる新たな合計光量、新たな平均光量、新たな面積を元々の合計光量、平均光量、面積と置き換えて集約的特徴量の作成を行いました。\u003c/p\u003e\n\n\u003ch2\u003egplearnについて\u003c/h2\u003e\n\n\u003cp\u003e上で紹介した集約的特徴量とArea特徴量のそれぞれに対して\u003ca href=\"https://gplearn.readthedocs.io/en/stable/\"\u003egplearn\u003c/a\u003eというライブラリを用いて新たな特徴量を作成しました。このライブラリは遺伝的アルゴリズムにより目的変数をよく表している変数を作成してくれるものです。\u003c/p\u003e\n\n\u003cp\u003eこのライブラリを用いて新しい特徴量を10個,25個,50個作成し、元々の集約的特徴量、Area特徴量と組み合わせてそれぞれに対して予測を行いました。\u003c/p\u003e\n\n\u003cp\u003egplearnでの特徴量作成については以下のサイトが参考になります。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fqiita.com%2FHatomugi%2Fitems%2F3bb16ed9c6bdc15f1e00\" title=\"遺伝的アルゴリズムを使って特徴量エンジニアリングしてみた - Qiita\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://qiita.com/Hatomugi/items/3bb16ed9c6bdc15f1e00\"\u003eqiita.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003ch1\u003eモデル構築に関して\u003c/h1\u003e\n\n\u003cp\u003eモデルの構築としてはgroup k fold(fold=5)でStackingのモデルを採用しました。\u003c/p\u003e\n\n\u003cp\u003e1層目はrandom forest,lgb,multi regression,catboost,xgboostに加えてAutoMLの\u003ca href=\"https://auto.gluon.ai/stable/index.html\"\u003eAutogluon\u003c/a\u003eを採用しました。\u003c/p\u003e\n\n\u003cp\u003eAutogluonは以下のようにデータを渡すだけで、11個のモデルを検証し最後に出力結果を重量平均で作成してくれます。\u003c/p\u003e\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003e\npredictor = TabularPredictor(\n                                label=\u003cspan class=\"synConstant\"\u003e'label'\u003c/span\u003e,\n                                problem_type=\u003cspan class=\"synConstant\"\u003e'regression'\u003c/span\u003e, \n                                eval_metric=\u003cspan class=\"synConstant\"\u003e'root_mean_squared_error'\u003c/span\u003e, \u003cspan class=\"synComment\"\u003e# 評価指標\u003c/span\u003e\n)\n\nX_train[\u003cspan class=\"synConstant\"\u003e'label'\u003c/span\u003e] = y_train\nX_test[\u003cspan class=\"synConstant\"\u003e'label'\u003c/span\u003e] = y_test\n\npredictor.fit(\n            train_data=X_train,\n            tuning_data=X_test, \u003cspan class=\"synComment\"\u003e# これを渡さない場合はランダムスプリット\u003c/span\u003e\n            time_limit=\u003cspan class=\"synIdentifier\"\u003eNone\u003c/span\u003e, \u003cspan class=\"synComment\"\u003e# おおよその時間制限を設けられる\u003c/span\u003e\n)\n\u003c/pre\u003e\n\n\n\u003cp\u003eそして2層目は1層目でも採用しているAutogluonで出力を作成しました。\u003c/p\u003e\n\n\u003ch1\u003e感想・反省点\u003c/h1\u003e\n\n\u003cp\u003ePublic Scoreの時点では6位と賞金獲得の可能性が十分にありましたが、Private Scoreでは36位と大幅にshake downしてしまいました。今回目標達成できなかった理由としては以下の2つが考えられます。\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003e1 CVの値とPublic ScoreからPrivate Scoreについて考えられなかった\n\u003c/b\u003e\u003c/p\u003e\n\n\u003cp\u003e1つ目の要因としては、Public Scoreが下がることのみを考えてモデルの改善・特徴量の作成を行っていたということです。その時CVの値とPublic Scoreをどこかに記録しておけばよかったのですが、どこにも保存せずPublic Scoreが下がることが最も良いことであると捉えていました。実際は、CVが下がったモデル・特徴量においてPublic Scoreも同じように下がることが望ましく、その記録を取っておくべきでした。\u003c/p\u003e\n\n\u003cp\u003e実際これまで提出していたファイルの中にPrivate Scoreが0.48774というものがあり、このファイルを最終提出としておけば3位に入ることができていました。しっかりとPrivate Scoreに効いているであろう提出ファイルが選べるようにCVとPublic Scoreに着目できるようにならないといけないと感じました。\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003e2 gplearnを行う位置が悪かった\n\u003c/b\u003e\u003c/p\u003e\n\n\u003cp\u003e2つめは、group k foldを行う前にgplearnを行ったことによって、validationの目的変数が確認できる状態でgplearnが特徴量作成を行ってたことです。これは本来見ることができないデータを確認しながらデータ生成を行っていることになるので過学習を引き起こす可能性がありました。\n　\n　\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/n/newton800/20210413/20210413095008.png\" alt=\"f:id:newton800:20210413095008p:plain\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003eあるべき姿としては、group k foldでtrainをtrain,validationに分割した後にtrainのみのデータを用いてgplearnをfitさせるべきだったと思います。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/n/newton800/20210413/20210413112402.png\" alt=\"f:id:newton800:20210413112402p:plain\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003ch1\u003e次回コンペでは\u003c/h1\u003e\n\n\u003cp\u003e今回のコンペを通じて集約的特徴量の作成方法、Stackingの実装方法、gplearnの実行位置、CVとPublic Scoreの関係性の重要度について学ぶことができました。\nテーブルコンペ において有効な手法を多く学ぶことができたので、次回参加するコンペでは賞金獲得を目標に頑張ります！！\u003c/p\u003e\n","contentSnippet":"こんにちは株式会社フィードフォース2020年入社の機械学習エンジニア八百　俊哉と申します。今回は、solafuneで開催された「夜間光データから土地価格を予測」という機械学習コンペに参加したので工夫した点や反省点などを紹介します。コンペ参加の目標設定としては、「賞金獲得！！（4位以内）」を設定していましたが、36位/201人中と目標達成できませんでした。残念な結果に終わってしまいましたが、多くのことを学ぶことができました。参加経緯私は、2020年10月から2021年2月ごろまで顧客の課題解決のために機械学習を応用する方法を学ぶためにAI Questというイベントに参加していました。そのイベントをきっかけに私は精度の高いモデルや良い特徴量を作成することに興味を持ちました。そこでより多くのコンペに参加することで精度を上げるためのノウハウを身に付けたいと思ったことが今回のコンペに参加したきっかけです。また、今回参加したコンペは与えられている特徴量が4つしかないので、初心者が参加しやすいコンペだったということも魅力的なポイントでした。課題と与えられているデータ課題としては、「夜間光データを元に土地価格を予測するアルゴリズムを開発する」というものです。使用可能なデータとしては、以下のものが与えられました。地域ごとのデータ・・・地域固有のID年代・・・1992~2013年まで土地の平均価格（目的変数）・・・1992~2013年まで夜間光量の平均値・・・0~63までのレンジでその地域の平均光量夜間光量の合計値・・・その地域の合計光量全体構成今回最終submitとして選択したモデルの全体構成は以下です。前処理に関して集約的特徴量について集約的特徴量の作成にあたってはmasato8823 (@mst_8823) | TwitterさんがBaseLineとして公開されていた以下のものを使用しました。zenn.dev作成した特徴量としては以下です。          面積    夜間光量の合計値/夜間光量の平均値を行い面積を算出した    PlaceID,Yearごとの統計情報   PlaceID,Yearをキーとして平均光量、合計光量、面積のmin,max,median,mean,std,max-min,q75-q25を算出した   PlaceID をキーにしたグループ内差分  平均光量、合計光量の年ごとの差分を算出したPlaceID をキーにしたグループ内シフト  平均光量、合計光量の年ごとの値をシフトしたピボットテーブルを用いた特徴量index=PlaceID,columns=Yearとして平均光量、合計光量、面積のピボットテーブルを作成し、PCAで次元削減したものを算出したPlaceIDをキーにしたグループ内相関係数PlaceIDごとにデータを集約しYearと平均光量、合計光量、面積との相関係数を算出した平均光量が63であった回数平均光量の最大値が63であることから平均光量が63である数を追加したArea特徴量について先ほど集約的特徴量についてで面積の求め方について書きました。面積=合計光量/平均光量で算出しています。ここで求められる土地の面積は、年が変化しようと変化しないと思われますが、実際のデータを確認すると年が変化すると面積も変化していました。そこで合計光量/平均光量より算出された面積をPlaceIDをキーとして平均を取ったものを新たな面積としました。新たな面積が求まると 新たな合計光量 =  平均光量×新たな面積,新たな平均面積 = 合計光量/新たな面積 が求まります。これらより求まる新たな合計光量、新たな平均光量、新たな面積を元々の合計光量、平均光量、面積と置き換えて集約的特徴量の作成を行いました。gplearnについて上で紹介した集約的特徴量とArea特徴量のそれぞれに対してgplearnというライブラリを用いて新たな特徴量を作成しました。このライブラリは遺伝的アルゴリズムにより目的変数をよく表している変数を作成してくれるものです。このライブラリを用いて新しい特徴量を10個,25個,50個作成し、元々の集約的特徴量、Area特徴量と組み合わせてそれぞれに対して予測を行いました。gplearnでの特徴量作成については以下のサイトが参考になります。qiita.comモデル構築に関してモデルの構築としてはgroup k fold(fold=5)でStackingのモデルを採用しました。1層目はrandom forest,lgb,multi regression,catboost,xgboostに加えてAutoMLのAutogluonを採用しました。Autogluonは以下のようにデータを渡すだけで、11個のモデルを検証し最後に出力結果を重量平均で作成してくれます。'label',                                problem_type='regression',                                 eval_metric='root_mean_squared_error', # 評価指標)X_train['label'] = y_trainX_test['label'] = y_testpredictor.fit(            train_data=X_train,            tuning_data=X_test, # これを渡さない場合はランダムスプリット            time_limit=None, # おおよその時間制限を設けられる)そして2層目は1層目でも採用しているAutogluonで出力を作成しました。感想・反省点Public Scoreの時点では6位と賞金獲得の可能性が十分にありましたが、Private Scoreでは36位と大幅にshake downしてしまいました。今回目標達成できなかった理由としては以下の2つが考えられます。1 CVの値とPublic ScoreからPrivate Scoreについて考えられなかった1つ目の要因としては、Public Scoreが下がることのみを考えてモデルの改善・特徴量の作成を行っていたということです。その時CVの値とPublic Scoreをどこかに記録しておけばよかったのですが、どこにも保存せずPublic Scoreが下がることが最も良いことであると捉えていました。実際は、CVが下がったモデル・特徴量においてPublic Scoreも同じように下がることが望ましく、その記録を取っておくべきでした。実際これまで提出していたファイルの中にPrivate Scoreが0.48774というものがあり、このファイルを最終提出としておけば3位に入ることができていました。しっかりとPrivate Scoreに効いているであろう提出ファイルが選べるようにCVとPublic Scoreに着目できるようにならないといけないと感じました。2 gplearnを行う位置が悪かった2つめは、group k foldを行う前にgplearnを行ったことによって、validationの目的変数が確認できる状態でgplearnが特徴量作成を行ってたことです。これは本来見ることができないデータを確認しながらデータ生成を行っていることになるので過学習を引き起こす可能性がありました。　　あるべき姿としては、group k foldでtrainをtrain,validationに分割した後にtrainのみのデータを用いてgplearnをfitさせるべきだったと思います。次回コンペでは今回のコンペを通じて集約的特徴量の作成方法、Stackingの実装方法、gplearnの実行位置、CVとPublic Scoreの関係性の重要度について学ぶことができました。テーブルコンペ において有効な手法を多く学ぶことができたので、次回参加するコンペでは賞金獲得を目標に頑張ります！！","link":"https://developer.feedforce.jp/entry/2021/04/13/174808","isoDate":"2021-04-13T08:48:08.000Z","dateMiliSeconds":1618303688000,"imageUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/n/newton800/20210409/20210409155716.png","authorName":"feedforce"},{"title":"エンジニア向けミートアップを開催します！","content":"\u003cp\u003eこんにちは。人事チームからエンジニアミートアップについてお知らせです。\u003c/p\u003e\n\n\u003cp\u003e3月26日（金）19：00から、エンジニア向けのミートアップを開催することになりました！\n選考とは関係ないので、純粋に「どんなエンジニアがいるかみてみたい」「会社の雰囲気を知りたい」\nという方もぜひご参加いただけたら嬉しいです。\u003c/p\u003e\n\n\u003cp\u003e初回のLT登壇者は \u003ca href=\"https://twitter.com/daido1976\"\u003e@daido1976\u003c/a\u003eです！\u003c/br\u003e\n詳しくは下記記事をご覧ください。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fmedia.feedforce.jp%2Fn%2Fn53b8be5eae4a\" title=\"現場エンジニアと気軽に話せる！エンジニアミートアップを開催します｜フィードフォースのnote\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://media.feedforce.jp/n/n53b8be5eae4a\"\u003emedia.feedforce.jp\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eご参加お待ちしています！\u003c/p\u003e\n","contentSnippet":"こんにちは。人事チームからエンジニアミートアップについてお知らせです。3月26日（金）19：00から、エンジニア向けのミートアップを開催することになりました！選考とは関係ないので、純粋に「どんなエンジニアがいるかみてみたい」「会社の雰囲気を知りたい」という方もぜひご参加いただけたら嬉しいです。初回のLT登壇者は @daido1976です！media.feedforce.jpご参加お待ちしています！","link":"https://developer.feedforce.jp/entry/2021/03/15/113230","isoDate":"2021-03-15T02:32:30.000Z","dateMiliSeconds":1615775550000,"imageUrl":"https://cdn.user.blog.st-hatena.com/default_entry_og_image/4268819/1588226000876991","authorName":"feedforce"},{"title":"Self-Attentionを用いてGoogle 無料リスティングの「拡張リスティングの不承認」に挑んだ話","content":"\u003cp\u003eこんにちは\n株式会社フィードフォース2020年入社の機械学習エンジニア\n\u003ca href=\"https://twitter.com/feed_yao\"\u003e\u0026#x516B;\u0026#x767E;\u0026#x4FCA;\u0026#x54C9;@Feedforce (@feed_yao) | Twitter\u003c/a\u003eと申します。\u003c/p\u003e\n\n\u003cp\u003e最近はロードバイク にはまっており、ロードバイク購入後一ヶ月で一日100km走行に成功しました。\u003c/p\u003e\n\n\u003cp\u003e今回、\u003cb\u003eGoogle無料リスティングで不承認アカウントが発生する要因を調査する分析\u003c/b\u003eを行いました。\u003c/p\u003e\n\n\u003cul class=\"table-of-contents\"\u003e\n    \u003cli\u003e\u003ca href=\"#Google-無料リスティングとは\"\u003eGoogle 無料リスティングとは？\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#なぜ今回分析が必要とされたのか\"\u003eなぜ今回分析が必要とされたのか？\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#結果と考察\"\u003e結果と考察\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#Self-Attentionを採用した理由\"\u003eSelf-Attentionを採用した理由\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#実装手順\"\u003e実装手順\u003c/a\u003e\u003cul\u003e\n            \u003cli\u003e\u003ca href=\"#使用データのフォーマット\"\u003e使用データのフォーマット\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#必要ライブラリのインストールインポート\"\u003e必要ライブラリのインストール・インポート\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#データの前処理\"\u003eデータの前処理\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#学習\"\u003e学習\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#評価出力\"\u003e評価・出力\u003c/a\u003e\u003c/li\u003e\n        \u003c/ul\u003e\n    \u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#まとめ\"\u003eまとめ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch1 id=\"Google-無料リスティングとは\"\u003eGoogle 無料リスティングとは？\u003c/h1\u003e\n\n\u003cp\u003e2020年10月にGoogleから公開された\u003cb\u003eGoogleショッピングタブに無料で商品掲載ができる「無料リスティング」のことです。\u003c/b\u003e\u003c/p\u003e\n\n\u003cp\u003eGoogle 検索にサイトがインデックス登録されても料金が発生しないのと同様に、EC事業者は無料で利用可能になりました。\nGoogle 無料リスティングについての詳細は以下のサイトが参考になります。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Flab.ecbooster.jp%2Fabout-google-free-listings%2F\" title=\"Googleに無料で自社商品が掲載できる「無料リスティング」とは？\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://lab.ecbooster.jp/about-google-free-listings/\"\u003elab.ecbooster.jp\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003ch1 id=\"なぜ今回分析が必要とされたのか\"\u003eなぜ今回分析が必要とされたのか？\u003c/h1\u003e\n\n\u003cp\u003e無料リスティングでは自社製品を無料でGoogleに掲載できます。\nしかしながら、課題として\u003cb\u003e一部商品掲載が不承認となるケースが見受けられました。\u003c/b\u003e\u003c/p\u003e\n\n\u003cp\u003e不承認となってしまうと自社商品の掲載ができていない状況が発生しています。不承認となる理由としては、「Googleが定める基準に対して、登録している商品データの属性数が足りない、内容が仕様に沿っていない場合、商品データの品質が低いため不承認になり、Googleの検索結果に表示させることができません。」とされています。\u003c/p\u003e\n\n\u003cp\u003eこれらを\u003cb\u003e定量的に分析することで不承認となる理由を見つけ出す試み\u003c/b\u003eが始まりました。\u003c/p\u003e\n\n\u003cp\u003eそのため今回の分析の目的は、\u003cb\u003e商品の属性情報（title,description）から承認・不承認の要因を見つけ出し、不承認の商品を承認へと改善するための施策を考案する\u003c/b\u003eことです。\u003c/p\u003e\n\n\u003ch1 id=\"結果と考察\"\u003e結果と考察\u003c/h1\u003e\n\n\u003cp\u003e今回の目的である「商品の属性情報（title,description）から承認・不承認の要因を見つけ出し、不承認の商品を承認へと改善するための施策を考案する」は、\u003cb\u003e達成できませんでした。\u003c/b\u003e\u003c/p\u003e\n\n\u003cp\u003e目的が達成できなかった理由として考えられる要因は、\u003cb\u003e承認・不承認は商品のtitle,descriptionだけでは判断されていない\u003c/b\u003eということです。商品ごとのtitle,descriptionのみで承認・不承認が判断されているのではなく、商品データ全体またはアカウント全体のデータを総合的に見て、判断されている可能性が高いということがわかりました。\u003c/p\u003e\n\n\u003cp\u003e承認・不承認予測のAccuracyとしては5割〜６割ほどで、承認・不承認を予測するという点でも低い精度となってしまいました。\u003c/p\u003e\n\n\u003ch1 id=\"Self-Attentionを採用した理由\"\u003eSelf-Attentionを採用した理由\u003c/h1\u003e\n\n\u003cp\u003e今回はSelf-Attentionという手法を用いてこの課題解決を試みました。\u003c/p\u003e\n\n\u003cp\u003eSelf-Attentionとは、\u003cb\u003e文章全体で重要とされるキーワードが予測結果と一緒に確認できるようになる\u003c/b\u003e手法です。\u003c/p\u003e\n\n\u003cp\u003eSelf-Attentionの仕組みについては詳しく書かれている方が多くいますので、ここでは割愛します。\u003c/p\u003e\n\n\u003cp\u003e最初は、word2vecを用いて文章特徴量を作成し、承認・不承認を予測して終了という一連の流れを想定していました。\u003c/p\u003e\n\n\u003cp\u003eしかし、\u003cb\u003e今回の目的は\u003c/b\u003e承認・不承認を予測したいわけではなく、\u003cb\u003eどの単語が承認・不承認と関わっているのかを確認し、不承認となっているアカウントを承認にすること\u003c/b\u003eです。\nもし仮にword2vecを用いた手法を採用すると予測結果の要因や理由が明確にならないので、不承認のアカウントを承認に改善する施策を考えることはできません。\u003c/p\u003e\n\n\u003cp\u003eそのため今回は、\u003cb\u003eSelf-Attentionを用いて分類モデルを構築することで、承認・不承認の要因が文章内のどこにあるのかを分析する\u003c/b\u003eために、この手法を選択しました。\u003c/p\u003e\n\n\u003ch1 id=\"実装手順\"\u003e実装手順\u003c/h1\u003e\n\n\u003cp\u003e本来の目的は達成できませんでしたが、Self-Attentionでの分類モデルの実装はできましたので、実装方法を記載します。\n今回はkerasを用いてSelf-Attention + LSTMで予測を行いました。\n検証環境はGoogle Colaboratoryを想定しています。\u003c/p\u003e\n\n\u003ch2 id=\"使用データのフォーマット\"\u003e使用データのフォーマット\u003c/h2\u003e\n\n\u003cp\u003e今回使用できるデータとしては以下のようなデータになっています。\u003c/p\u003e\n\n\u003cp\u003e各アカウント・各商品ごとに商品IDが割り振られており、それぞれの商品にtitle,descriptionが割り振られています。\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003e承認・不承認のラベルは、アカウントごとに付加されています。\n\u003c/b\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/n/newton800/20210224/20210224172435.png\" alt=\"f:id:newton800:20210224172435p:plain\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003ch2 id=\"必要ライブラリのインストールインポート\"\u003e必要ライブラリのインストール・インポート\u003c/h2\u003e\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003e!pip install text_vectorian\n!pip install mojimoji\n!apt install aptitude\n!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils \u003cspan class=\"synIdentifier\"\u003efile\u003c/span\u003e -y\n!pip install mecab-python3==\u003cspan class=\"synConstant\"\u003e0.7\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003e\u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"synStatement\"\u003eas\u003c/span\u003e pd\n\u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"synStatement\"\u003eas\u003c/span\u003e np\n\u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e keras\n\u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e os\n\u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e warnings\nwarnings.simplefilter(\u003cspan class=\"synConstant\"\u003e'ignore'\u003c/span\u003e)\n\u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e subprocess\n\u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e mojimoji\n\u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e re\n\u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e MeCab\n\u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e matplotlib.pyplot \u003cspan class=\"synStatement\"\u003eas\u003c/span\u003e plt\n\n\u003cspan class=\"synPreProc\"\u003efrom\u003c/span\u003e keras.layers \u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e Dense, Dropout, LSTM, Embedding, BatchNormalization\n\u003cspan class=\"synPreProc\"\u003efrom\u003c/span\u003e keras.layers.wrappers \u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e Bidirectional\n\u003cspan class=\"synPreProc\"\u003efrom\u003c/span\u003e keras.callbacks \u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e EarlyStopping, ModelCheckpoint\n\u003cspan class=\"synPreProc\"\u003efrom\u003c/span\u003e keras \u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e Input, Model, utils\n\u003cspan class=\"synPreProc\"\u003efrom\u003c/span\u003e keras.preprocessing.sequence \u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e pad_sequences\n\u003cspan class=\"synPreProc\"\u003efrom\u003c/span\u003e keras.callbacks \u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e EarlyStopping\n\n\u003cspan class=\"synPreProc\"\u003efrom\u003c/span\u003e text_vectorian \u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e SentencePieceVectorian\n\u003cspan class=\"synPreProc\"\u003efrom\u003c/span\u003e keras_self_attention \u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e SeqSelfAttention\n\u003cspan class=\"synPreProc\"\u003efrom\u003c/span\u003e sklearn.model_selection \u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e train_test_split\n\u003cspan class=\"synPreProc\"\u003efrom\u003c/span\u003e sklearn.metrics \u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e classification_report\n\u003c/pre\u003e\n\n\n\u003ch2 id=\"データの前処理\"\u003eデータの前処理\u003c/h2\u003e\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e# データの読み込み\u003c/span\u003e\napp = pd.read_csv(\u003cspan class=\"synConstant\"\u003e'data/app.csv'\u003c/span\u003e) \u003cspan class=\"synComment\"\u003e# 承認データ\u003c/span\u003e\ndisapp = pd.read_csv(\u003cspan class=\"synConstant\"\u003e'data/disapp.csv'\u003c/span\u003e) \u003cspan class=\"synComment\"\u003e# 不承認データ\u003c/span\u003e\n\napp[\u003cspan class=\"synConstant\"\u003e'target'\u003c/span\u003e] = \u003cspan class=\"synConstant\"\u003e'app'\u003c/span\u003e \u003cspan class=\"synComment\"\u003e# targetにlabelを代入する\u003c/span\u003e\ndisapp[\u003cspan class=\"synConstant\"\u003e'target'\u003c/span\u003e] = \u003cspan class=\"synConstant\"\u003e'disapp'\u003c/span\u003e\n\n\u003cspan class=\"synComment\"\u003e# 今回は、titleとdescriptionを用いて予測するので、それら二つの変数を一つにまとめる\u003c/span\u003e\napp[\u003cspan class=\"synConstant\"\u003e'sentence'\u003c/span\u003e] = app[\u003cspan class=\"synConstant\"\u003e'title'\u003c/span\u003e] + app[\u003cspan class=\"synConstant\"\u003e'description'\u003c/span\u003e] \ndisapp[\u003cspan class=\"synConstant\"\u003e'sentence'\u003c/span\u003e] = disapp[\u003cspan class=\"synConstant\"\u003e'title'\u003c/span\u003e] + disapp[\u003cspan class=\"synConstant\"\u003e'description'\u003c/span\u003e]\n\n\u003cspan class=\"synComment\"\u003e# これまで別々に処理していたappとdisappをまとめてdfとする\u003c/span\u003e\ndf = app.append(disapp)\n\u003c/pre\u003e\n\n\n\u003cp\u003e今回のデータは特殊で、承認・不承認は商品ごとについているラベルではなくアカウントと紐づいたラベルとなっています。それらを各商品と承認・不承認が紐づいているとして各商品ごとに予測することを行ってます。\u003c/p\u003e\n\n\u003cp\u003eここで注意が必要なのは、データの分割方法です。\u003cb\u003eアカウントを無視してデータを分割してしまうとリークを起こす可能性があります\u003c/b\u003e（リークとは、本来予測では使用できないデータが学習時に入ってしまっていることです）。\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eそのため同じアカウントのデータが訓練データ、検証データ、テストデータに渡って存在しないようにしなければなりません\u003c/b\u003e。\u003c/p\u003e\n\n\u003cp\u003e例えば、アカウントAの商品データは全て訓練データとする,アカウントBの商品データは全てテストデータにするといったようなことを意味しています。\u003c/p\u003e\n\n\u003cp\u003eアカウントごとにデータを分割するには、各アカウントごとの商品数がある程度同じである方がlabelが不均衡にならないと考え、データ数を揃える処理を施しました。\n（これらはGroupKFoldを使用すれば解決できると考えられますが、分析実施時はGroupKFoldを知らなかった）\u003c/p\u003e\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003e\u003cspan class=\"synComment\"\u003e# アカウントごとに商品数が異なるので50以上商品数がある場合は50までの商品を使用する\u003c/span\u003e\n\u003cspan class=\"synComment\"\u003e# アカウントごとに商品数を揃えることで、labelが不均衡になることを緩和している\u003c/span\u003e\n\u003cspan class=\"synComment\"\u003e# アカウントごとにlabelがふられるが、商品ごとに予測結果を出す時のみ実施\u003c/span\u003e\ncutted_df = pd.DataFrame([])\n\u003cspan class=\"synStatement\"\u003efor\u003c/span\u003e acc \u003cspan class=\"synStatement\"\u003ein\u003c/span\u003e df.account_name.unique():\n  data = df[df.account_name == acc]\n  \u003cspan class=\"synStatement\"\u003eif\u003c/span\u003e data.shape[\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e] \u0026gt; \u003cspan class=\"synConstant\"\u003e50\u003c/span\u003e: \n    data = data[:\u003cspan class=\"synConstant\"\u003e50\u003c/span\u003e]\n  cutted_df = pd.concat([cutted_df,data],\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e)  \n\ndf = cutted_df.sample(frac=\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e,random_state=\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e).reset_index(drop=\u003cspan class=\"synIdentifier\"\u003eTrue\u003c/span\u003e)\n\u003c/pre\u003e\n\n\n\u003cp\u003e次は、データの前処理についてです。\u003c/p\u003e\n\n\u003cp\u003e自然言語処理の前処理で有効と言われている半角-\u003e全角、数字は全て0にする、スペース文字の消去を行いました。\nまた、これまでlabelが'app'または'disapp'だったのでそれらを入力できる形式に変換しています。\u003c/p\u003e\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003e\n\u003cspan class=\"synStatement\"\u003edef\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003ePreprocessData\u003c/span\u003e(df,dirname):\n  \u003cspan class=\"synComment\"\u003e# データの前処理関数\u003c/span\u003e\n  \u003cspan class=\"synComment\"\u003e# 辞書型を返す\u003c/span\u003e\n\n  mecab = MeCab.Tagger(\u003cspan class=\"synConstant\"\u003e'-Ochasen'\u003c/span\u003e)\n\n  \u003cspan class=\"synComment\"\u003e# textデータの前処理\u003c/span\u003e\n  df = TextPreprocess(df)\n\n  label2index = {k: i \u003cspan class=\"synStatement\"\u003efor\u003c/span\u003e i, k \u003cspan class=\"synStatement\"\u003ein\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003eenumerate\u003c/span\u003e(df.target.unique())}\n  index2label = {i: k \u003cspan class=\"synStatement\"\u003efor\u003c/span\u003e i, k \u003cspan class=\"synStatement\"\u003ein\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003eenumerate\u003c/span\u003e(df.target.unique())}\n\n  class_count = \u003cspan class=\"synIdentifier\"\u003elen\u003c/span\u003e(label2index)\n  labels = utils.to_categorical([label2index[label] \u003cspan class=\"synStatement\"\u003efor\u003c/span\u003e label \u003cspan class=\"synStatement\"\u003ein\u003c/span\u003e df.target], num_classes=class_count)\n\n  features,sentences,vectorian,account = MakeFeatures(df)\n\n  \u003cspan class=\"synStatement\"\u003ereturn\u003c/span\u003e {\n      \u003cspan class=\"synConstant\"\u003e'class_count'\u003c/span\u003e: class_count,\n      \u003cspan class=\"synConstant\"\u003e'label2index'\u003c/span\u003e: label2index,\n      \u003cspan class=\"synConstant\"\u003e'index2label'\u003c/span\u003e: index2label,\n      \u003cspan class=\"synConstant\"\u003e'labels'\u003c/span\u003e: labels,\n      \u003cspan class=\"synConstant\"\u003e'features'\u003c/span\u003e: features,\n      \u003cspan class=\"synConstant\"\u003e'sentences'\u003c/span\u003e:sentences,\n      \u003cspan class=\"synConstant\"\u003e'input_len'\u003c/span\u003e: vectorian.max_tokens_len,\n      \u003cspan class=\"synConstant\"\u003e'vectorian'\u003c/span\u003e:vectorian,\n      \u003cspan class=\"synConstant\"\u003e'account'\u003c/span\u003e:account\n  }\n\n\u003cspan class=\"synStatement\"\u003edef\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003eTextPreprocess\u003c/span\u003e(df):\n  \u003cspan class=\"synStatement\"\u003efor\u003c/span\u003e i \u003cspan class=\"synStatement\"\u003ein\u003c/span\u003e df.index:\n    sen = df.loc[i,\u003cspan class=\"synConstant\"\u003e'sentence'\u003c/span\u003e]\n    sen = mojimoji.han_to_zen(sen)\n    sen = re.sub(\u003cspan class=\"synConstant\"\u003er'\\d+'\u003c/span\u003e,\u003cspan class=\"synConstant\"\u003e'0'\u003c/span\u003e,sen)\n    df.loc[i,\u003cspan class=\"synConstant\"\u003e'sentence'\u003c/span\u003e] = sen.replace(\u003cspan class=\"synConstant\"\u003e'\u003c/span\u003e\u003cspan class=\"synSpecial\"\u003e\\u3000\u003c/span\u003e\u003cspan class=\"synConstant\"\u003e'\u003c/span\u003e,\u003cspan class=\"synConstant\"\u003e''\u003c/span\u003e)\n  \u003cspan class=\"synStatement\"\u003ereturn\u003c/span\u003e df\n\n\u003cspan class=\"synStatement\"\u003edef\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003eMakeFeatures\u003c/span\u003e(df):\n  vectorian = SentencePieceVectorian()\n\n  features = []\n  sentences = []\n  accounts = []\n  \u003cspan class=\"synStatement\"\u003efor\u003c/span\u003e feature,account \u003cspan class=\"synStatement\"\u003ein\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003ezip\u003c/span\u003e(df[\u003cspan class=\"synConstant\"\u003e'sentence'\u003c/span\u003e],df[\u003cspan class=\"synConstant\"\u003e'account_name'\u003c/span\u003e]):\n    f = vectorian.fit(feature).indices\n    features.append(f)\n    sentences.append(feature)\n    accounts.append(account)\n\n  features = pad_sequences(features, maxlen=vectorian.max_tokens_len)\n\n  \u003cspan class=\"synStatement\"\u003ereturn\u003c/span\u003e features,sentences,vectorian,accounts\n\u003c/pre\u003e\n\n\n\u003cp\u003eでは、ここまでの前処理を流します。\u003c/p\u003e\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003edata = PreprocessData(df,dirname) \u003cspan class=\"synComment\"\u003e# dirnameは、出力結果などを入れたいpath入れてください\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003e次はtrain_test_splitを行いますが、先ほども記述した通り通常の手法ではリークするので、以下のようにしました。\n（上述の通りGroupKFoldの実施で回避できる）\u003c/p\u003e\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003e\u003cspan class=\"synStatement\"\u003edef\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003eCollectData\u003c/span\u003e(data,account):\n  features = []\n  sentences = []\n  labels = []\n  \n  \u003cspan class=\"synStatement\"\u003efor\u003c/span\u003e ac \u003cspan class=\"synStatement\"\u003ein\u003c/span\u003e account:\n    where_ = np.where(np.array(data[\u003cspan class=\"synConstant\"\u003e'account'\u003c/span\u003e]) == ac)\n    features.extend(np.array(data[\u003cspan class=\"synConstant\"\u003e'features'\u003c/span\u003e])[where_])\n    sentences.extend(np.array(data[\u003cspan class=\"synConstant\"\u003e'sentences'\u003c/span\u003e])[where_])\n    labels.extend(np.array(data[\u003cspan class=\"synConstant\"\u003e'labels'\u003c/span\u003e])[where_])\n  \u003cspan class=\"synStatement\"\u003ereturn\u003c/span\u003e np.array(features),np.array(sentences),np.array(labels)\n\ntrain_account,test_account = train_test_split(\u003cspan class=\"synIdentifier\"\u003elist\u003c/span\u003e(\u003cspan class=\"synIdentifier\"\u003eset\u003c/span\u003e(data[\u003cspan class=\"synConstant\"\u003e'account'\u003c/span\u003e])),test_size=\u003cspan class=\"synConstant\"\u003e0.2\u003c/span\u003e,random_state=\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e)\ntrain_account,val_account = train_test_split(train_account,test_size=\u003cspan class=\"synConstant\"\u003e0.25\u003c/span\u003e,random_state=\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e)\n\ntrain_features,train_sen,train_labels = CollectData(data,train_account)\nval_features,val_sen,val_labels = CollectData(data,val_account)\ntest_features,test_sen,test_labels = CollectData(data,test_account)\n\u003c/pre\u003e\n\n\n\u003cp\u003e通常のデータセットであれば、以下のようにすることでデータの分割が行えます。\u003c/p\u003e\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003e(train_features,val_features,\n train_labels,val_labels,\n train_sen,val_sen) = train_test_split(data[\u003cspan class=\"synConstant\"\u003e'features'\u003c/span\u003e], data[\u003cspan class=\"synConstant\"\u003e'labels'\u003c/span\u003e], data[\u003cspan class=\"synConstant\"\u003e'sentences'\u003c/span\u003e], test_size=\u003cspan class=\"synConstant\"\u003e0.2\u003c/span\u003e, random_state=\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e)\n\n(train_features,test_features,\n train_labels,test_labels,\n train_sen,test_sen) = train_test_split(train_features, train_labels, train_sen, test_size=\u003cspan class=\"synConstant\"\u003e0.25\u003c/span\u003e, random_state=\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e)\n\u003c/pre\u003e\n\n\n\u003cp\u003eここまででデータの整形が完了です。\u003c/p\u003e\n\n\u003ch2 id=\"学習\"\u003e学習\u003c/h2\u003e\n\n\u003cp\u003e次は、モデルの定義を行います。\u003c/p\u003e\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003e\u003cspan class=\"synStatement\"\u003edef\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003e_create_model\u003c/span\u003e(input_shape, hidden, class_count,vectorian):\n    input_tensor = Input(input_shape)\n    common_input = vectorian.get_keras_layer(trainable=\u003cspan class=\"synIdentifier\"\u003eTrue\u003c/span\u003e)(input_tensor)\n    x1 = SeqSelfAttention(name=\u003cspan class=\"synConstant\"\u003e'attention'\u003c/span\u003e)(common_input)\n    x1 = Bidirectional(LSTM(hidden))(x1)\n    x1 = Dropout(\u003cspan class=\"synConstant\"\u003e0.5\u003c/span\u003e)(x1)\n    x1 = Dense(\u003cspan class=\"synConstant\"\u003e32\u003c/span\u003e)(x1)\n    x1 = Dropout(\u003cspan class=\"synConstant\"\u003e0.5\u003c/span\u003e)(x1)\n    x1 = Dense(\u003cspan class=\"synConstant\"\u003e16\u003c/span\u003e)(x1)\n    x1 = Dropout(\u003cspan class=\"synConstant\"\u003e0.5\u003c/span\u003e)(x1)\n    output_tensor = Dense(class_count, activation=\u003cspan class=\"synConstant\"\u003e'softmax'\u003c/span\u003e, name=\u003cspan class=\"synConstant\"\u003e'class'\u003c/span\u003e)(x1)\n\n    model = Model(input_tensor, output_tensor)\n    model.compile(loss=\u003cspan class=\"synConstant\"\u003e'categorical_crossentropy'\u003c/span\u003e, optimizer=\u003cspan class=\"synConstant\"\u003e'nadam'\u003c/span\u003e, metrics=[\u003cspan class=\"synConstant\"\u003e'acc'\u003c/span\u003e])\n\n    \u003cspan class=\"synStatement\"\u003ereturn\u003c/span\u003e model\n\nhidden = \u003cspan class=\"synConstant\"\u003e356\u003c/span\u003e\nmodel = _create_model(train_features[\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e].shape, hidden, data[\u003cspan class=\"synConstant\"\u003e'class_count'\u003c/span\u003e],data[\u003cspan class=\"synConstant\"\u003e'vectorian'\u003c/span\u003e])\nmodel.summary()\n\u003c/pre\u003e\n\n\n\u003cp\u003e作成したモデルにデータを流して学習を進めます。\u003c/p\u003e\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003emodel_filename=\u003cspan class=\"synConstant\"\u003e'{0}/model.h5'\u003c/span\u003e.format(dirname)\n\nhistory = model.fit(train_features, train_labels,\n                    epochs=\u003cspan class=\"synConstant\"\u003e50\u003c/span\u003e,\n                    batch_size=\u003cspan class=\"synConstant\"\u003e32\u003c/span\u003e,\n                    validation_data=(val_features, val_labels),\n                    shuffle=\u003cspan class=\"synIdentifier\"\u003eFalse\u003c/span\u003e,\n                    callbacks = [\n                        EarlyStopping(patience=\u003cspan class=\"synConstant\"\u003e5\u003c/span\u003e, monitor=\u003cspan class=\"synConstant\"\u003e'val_acc'\u003c/span\u003e, mode=\u003cspan class=\"synConstant\"\u003e'max'\u003c/span\u003e),\n                        ModelCheckpoint(filepath=model_filename, monitor=\u003cspan class=\"synConstant\"\u003e'val_acc'\u003c/span\u003e, mode=\u003cspan class=\"synConstant\"\u003e'max'\u003c/span\u003e, save_best_only=\u003cspan class=\"synIdentifier\"\u003eTrue\u003c/span\u003e)\n                    ])\n\u003c/pre\u003e\n\n\n\u003ch2 id=\"評価出力\"\u003e評価・出力\u003c/h2\u003e\n\n\u003cp\u003eModelCheckpointで保存したmodelを読み取り、さらにSelf-Attentionの結果を得られるようにします。\u003c/p\u003e\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003e\u003cspan class=\"synPreProc\"\u003efrom\u003c/span\u003e keras.models \u003cspan class=\"synPreProc\"\u003eimport\u003c/span\u003e load_model\nmodel = load_model(model_filename, custom_objects=SeqSelfAttention.get_custom_objects())\nmodel = Model(inputs=model.input, outputs=[model.output, model.get_layer(\u003cspan class=\"synConstant\"\u003e'attention'\u003c/span\u003e).output])\n\u003c/pre\u003e\n\n\n\u003cp\u003emodelにtest dataを入れて結果を取得します。\u003c/p\u003e\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003eout = model.predict(test_features)\n\ny = out[\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e] \u003cspan class=\"synComment\"\u003e# 予測labelのsoftmaxが入っている\u003c/span\u003e\nweight = out[\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e] \u003cspan class=\"synComment\"\u003e# Self-Attentionのweighが入っている\u003c/span\u003e\n\npred = np.argmax(y,\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e) \u003cspan class=\"synComment\"\u003e# 予測値\u003c/span\u003e\n\u003cspan class=\"synIdentifier\"\u003emax\u003c/span\u003e = np.max(y,\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e) \u003cspan class=\"synComment\"\u003e# 信頼値\u003c/span\u003e\n\ndf_y = pd.DataFrame(np.array([np.argmax(test_labels,\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e),pred,\u003cspan class=\"synIdentifier\"\u003emax\u003c/span\u003e*\u003cspan class=\"synConstant\"\u003e100\u003c/span\u003e]).T,columns=[\u003cspan class=\"synConstant\"\u003e'true'\u003c/span\u003e,\u003cspan class=\"synConstant\"\u003e'pred'\u003c/span\u003e,\u003cspan class=\"synConstant\"\u003e'trust'\u003c/span\u003e]) \u003cspan class=\"synComment\"\u003e# 結果をまとめておくと精度確認に使える\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003e精度の確認を行います。\u003c/p\u003e\n\n\u003cp\u003eただ、testを入力し得られた結果を出力するだけでは精度が得られなかったので、信頼値が高いものだけを選別し、出力するようにしました。\n信頼値を90~55の間で出力し、\u003cb\u003e最もAccuracyが高い時の信頼値以上のものを出力\u003c/b\u003eとしました。\u003c/p\u003e\n\n\u003cp\u003e 一方で信頼値を上げすぎるとわずかな出力しか得られないので、元のtestデータ数の1/3はデータ数が出力として確保できるような条件を加えました。\u003c/p\u003e\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003ereport = classification_report(pred, np.argmax(test_labels,\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e),output_dict=\u003cspan class=\"synIdentifier\"\u003eTrue\u003c/span\u003e,target_names=[data[\u003cspan class=\"synConstant\"\u003e'index2label'\u003c/span\u003e][i] \u003cspan class=\"synStatement\"\u003efor\u003c/span\u003e i \u003cspan class=\"synStatement\"\u003ein\u003c/span\u003e [\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e,\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e]])\nFirstReport_df = pd.DataFrame(report).T\n\n\u003cspan class=\"synIdentifier\"\u003eprint\u003c/span\u003e(FirstReport_df)\nFirstReport_df.to_csv(dirname+\u003cspan class=\"synConstant\"\u003e'NotCutReport.csv'\u003c/span\u003e)\n\n\u003cspan class=\"synComment\"\u003e# 信頼値が高い予測だけを出力とすることで確からしいものだけをみる\u003c/span\u003e\nAppSupport = FirstReport_df.loc[\u003cspan class=\"synConstant\"\u003e'app'\u003c/span\u003e,\u003cspan class=\"synConstant\"\u003e'support'\u003c/span\u003e] \u003cspan class=\"synComment\"\u003e# 予測した数を取得\u003c/span\u003e\nDisappSupport = FirstReport_df.loc[\u003cspan class=\"synConstant\"\u003e'disapp'\u003c/span\u003e,\u003cspan class=\"synConstant\"\u003e'support'\u003c/span\u003e]\n\n\u003cspan class=\"synStatement\"\u003efor\u003c/span\u003e UpperLimit \u003cspan class=\"synStatement\"\u003ein\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003erange\u003c/span\u003e(\u003cspan class=\"synConstant\"\u003e90\u003c/span\u003e,\u003cspan class=\"synConstant\"\u003e55\u003c/span\u003e,-\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e):\n  max_acc = \u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e\n  \u003cspan class=\"synStatement\"\u003efor\u003c/span\u003e i \u003cspan class=\"synStatement\"\u003ein\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003erange\u003c/span\u003e(\u003cspan class=\"synConstant\"\u003e50\u003c/span\u003e,UpperLimit,\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e):\n    df_y_cut = df_y[df_y.trust \u0026gt; i]\n    report = classification_report(df_y_cut.pred, df_y_cut.true ,output_dict=\u003cspan class=\"synIdentifier\"\u003eTrue\u003c/span\u003e)\n    report_df = pd.DataFrame(report).T\n    acc = report_df.loc[\u003cspan class=\"synConstant\"\u003e'accuracy'\u003c/span\u003e,\u003cspan class=\"synConstant\"\u003e'precision'\u003c/span\u003e]\n    \u003cspan class=\"synStatement\"\u003eif\u003c/span\u003e max_acc \u0026lt; acc:\n      max_acc = acc\n      max_i = i\n  df_y_cut = df_y[df_y.trust \u0026gt; max_i]\n  report = classification_report(df_y_cut.pred, df_y_cut.true ,output_dict=\u003cspan class=\"synIdentifier\"\u003eTrue\u003c/span\u003e,target_names=[data[\u003cspan class=\"synConstant\"\u003e'index2label'\u003c/span\u003e][i] \u003cspan class=\"synStatement\"\u003efor\u003c/span\u003e i \u003cspan class=\"synStatement\"\u003ein\u003c/span\u003e [\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e,\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e]])\n  report_df = pd.DataFrame(report).T\n  \u003cspan class=\"synStatement\"\u003eif\u003c/span\u003e (report_df.loc[\u003cspan class=\"synConstant\"\u003e'app'\u003c/span\u003e,\u003cspan class=\"synConstant\"\u003e'support'\u003c/span\u003e] \u0026gt; HighSupport/\u003cspan class=\"synConstant\"\u003e3\u003c/span\u003e) \u003cspan class=\"synStatement\"\u003eand\u003c/span\u003e (report_df.loc[\u003cspan class=\"synConstant\"\u003e'disapp'\u003c/span\u003e,\u003cspan class=\"synConstant\"\u003e'support'\u003c/span\u003e] \u0026gt; LowSupport/\u003cspan class=\"synConstant\"\u003e3\u003c/span\u003e):\n    \u003cspan class=\"synComment\"\u003e# 元の予測値の1/3のデータ数が確保できていればクリア\u003c/span\u003e\n    \u003cspan class=\"synIdentifier\"\u003eprint\u003c/span\u003e(\u003cspan class=\"synConstant\"\u003e'UpperLimit:'\u003c/span\u003e + \u003cspan class=\"synIdentifier\"\u003estr\u003c/span\u003e(UpperLimit))\n    \u003cspan class=\"synIdentifier\"\u003eprint\u003c/span\u003e(\u003cspan class=\"synConstant\"\u003e'max_i:'\u003c/span\u003e + \u003cspan class=\"synIdentifier\"\u003estr\u003c/span\u003e(max_i))\n    \u003cspan class=\"synIdentifier\"\u003eprint\u003c/span\u003e(report_df)\n    report_df.to_csv(dirname+\u003cspan class=\"synConstant\"\u003e'Report.csv'\u003c/span\u003e)\n    \u003cspan class=\"synStatement\"\u003ebreak\u003c/span\u003e\n\u003c/pre\u003e\n\n\n\u003cp\u003e最後にSelf-AttentionのWeightをcsvで出力します。\u003c/p\u003e\n\n\u003cp\u003e得られた出力結果は、予測値-承認と真値-承認、予測値-承認と真値-不承認、予測値-不承認と真値-承認、予測値-不承認と真値-不承認のように予測値と真値の結果に応じて4つに分けてcsvで出力するようになっています。\u003c/p\u003e\n\n\u003cpre class=\"code lang-python\" data-lang=\"python\" data-unlink\u003eapp_app = pd.DataFrame([])\napp_disapp = pd.DataFrame([])\ndisapp_app = pd.DataFrame([])\ndisapp_disapp = pd.DataFrame([])\n\n\u003cspan class=\"synStatement\"\u003efor\u003c/span\u003e i \u003cspan class=\"synStatement\"\u003ein\u003c/span\u003e \u003cspan class=\"synIdentifier\"\u003erange\u003c/span\u003e(\u003cspan class=\"synIdentifier\"\u003elen\u003c/span\u003e(test_features)):\n  input_text = test_sen[i]\n  tokens = data[\u003cspan class=\"synConstant\"\u003e'vectorian'\u003c/span\u003e].tokenizer._tokenizer.encode_as_pieces(input_text)\n\n  conf = out[\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e][i] * \u003cspan class=\"synConstant\"\u003e100\u003c/span\u003e\n  wei = out[\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e][i]\n\n  \u003cspan class=\"synStatement\"\u003eif\u003c/span\u003e np.max(conf) \u0026lt;= max_i:\n    \u003cspan class=\"synStatement\"\u003econtinue\u003c/span\u003e\n\n  pred = [data[\u003cspan class=\"synConstant\"\u003e'index2label'\u003c/span\u003e][np.argmax(conf)]]\n  labels = [data[\u003cspan class=\"synConstant\"\u003e'index2label'\u003c/span\u003e][np.argmax(test_labels[i])]]\n\n  weights = [w.max() \u003cspan class=\"synStatement\"\u003efor\u003c/span\u003e w \u003cspan class=\"synStatement\"\u003ein\u003c/span\u003e wei[-\u003cspan class=\"synIdentifier\"\u003elen\u003c/span\u003e(tokens):]]\n\n  df = pd.DataFrame([tokens, weights], index=[\u003cspan class=\"synConstant\"\u003e'token'\u003c/span\u003e, \u003cspan class=\"synConstant\"\u003e'weight'\u003c/span\u003e]).T\n\n  mean = np.asarray(weights).mean()\n  \u003cspan class=\"synStatement\"\u003efor\u003c/span\u003e j \u003cspan class=\"synStatement\"\u003ein\u003c/span\u003e df.index:\n    \u003cspan class=\"synStatement\"\u003eif\u003c/span\u003e df.loc[j,\u003cspan class=\"synConstant\"\u003e'weight'\u003c/span\u003e] - mean \u0026lt;= \u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e:\n      df.loc[j,\u003cspan class=\"synConstant\"\u003e'weight'\u003c/span\u003e] = \u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e\n    \u003cspan class=\"synStatement\"\u003eelse\u003c/span\u003e:\n      df.loc[j,\u003cspan class=\"synConstant\"\u003e'weight'\u003c/span\u003e] = df.loc[j,\u003cspan class=\"synConstant\"\u003e'weight'\u003c/span\u003e] - mean\n  \n  pred += df.token.values.tolist()\n  labels += df.weight.values.tolist()\n\n  final = pd.DataFrame(np.array([pred,labels]).T,columns=[\u003cspan class=\"synConstant\"\u003e'pred'\u003c/span\u003e,input_text])\n\n  \u003cspan class=\"synStatement\"\u003eif\u003c/span\u003e (pred[\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e] == \u003cspan class=\"synConstant\"\u003e'app'\u003c/span\u003e) \u0026amp; (labels[\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e] == \u003cspan class=\"synConstant\"\u003e'app'\u003c/span\u003e):\n    app_app = pd.concat([app_app,final],\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e)\n  \u003cspan class=\"synStatement\"\u003eelif\u003c/span\u003e (pred[\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e]  == \u003cspan class=\"synConstant\"\u003e'app'\u003c/span\u003e) \u0026amp; (labels[\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e] == \u003cspan class=\"synConstant\"\u003e'disapp'\u003c/span\u003e):\n    app_disapp = pd.concat([app_disapp,final],\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e)\n  \u003cspan class=\"synStatement\"\u003eelif\u003c/span\u003e (pred[\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e]  == \u003cspan class=\"synConstant\"\u003e'disapp'\u003c/span\u003e) \u0026amp; (labels[\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e] == \u003cspan class=\"synConstant\"\u003e'app'\u003c/span\u003e):\n    disapp_app = pd.concat([disapp_app,final],\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e)\n  \u003cspan class=\"synStatement\"\u003eelif\u003c/span\u003e (pred[\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e]  == \u003cspan class=\"synConstant\"\u003e'disapp'\u003c/span\u003e) \u0026amp; (labels[\u003cspan class=\"synConstant\"\u003e0\u003c/span\u003e] == \u003cspan class=\"synConstant\"\u003e'diaspp'\u003c/span\u003e):\n    disapp_disapp = pd.concat([disapp_disapp,final],\u003cspan class=\"synConstant\"\u003e1\u003c/span\u003e)\n\napp_app.to_csv(dirname+\u003cspan class=\"synConstant\"\u003e'app_app.csv'\u003c/span\u003e,index=\u003cspan class=\"synIdentifier\"\u003eFalse\u003c/span\u003e)\napp_disapp.to_csv(dirname+\u003cspan class=\"synConstant\"\u003e'app_disapp.csv'\u003c/span\u003e,index=\u003cspan class=\"synIdentifier\"\u003eFalse\u003c/span\u003e)\ndisapp_app.to_csv(dirname+\u003cspan class=\"synConstant\"\u003e'disapp_app.csv'\u003c/span\u003e,index=\u003cspan class=\"synIdentifier\"\u003eFalse\u003c/span\u003e)\ndisapp_disapp.to_csv(dirname+\u003cspan class=\"synConstant\"\u003e'disapp_disapp.csv'\u003c/span\u003e,index=\u003cspan class=\"synIdentifier\"\u003eFalse\u003c/span\u003e)\n\u003c/pre\u003e\n\n\n\u003ch1 id=\"まとめ\"\u003eまとめ\u003c/h1\u003e\n\n\u003cp\u003eSelf-Attentionを用いて無料リスティングの不承認理由を解き明かそうと分析しました。\nしかし、\u003cb\u003etitle,descriptionのみからは承認と不承認を分類することができず、不承認理由の解明には貢献できせんでした。\u003c/b\u003e\u003c/p\u003e\n\n\u003cp\u003eSelf-Attentionとデータセットの相性が悪いという可能性も考えられるので、tfidf+lgbも試みましたが、こちらもうまくいきませんでした。やはりこちらの結果からもtitle,descriptionのみからは承認と不承認を分類することができないということが考えられます。\u003c/p\u003e\n","contentSnippet":"こんにちは株式会社フィードフォース2020年入社の機械学習エンジニア八百俊哉@Feedforce (@feed_yao) | Twitterと申します。最近はロードバイク にはまっており、ロードバイク購入後一ヶ月で一日100km走行に成功しました。今回、Google無料リスティングで不承認アカウントが発生する要因を調査する分析を行いました。Google 無料リスティングとは？なぜ今回分析が必要とされたのか？結果と考察Self-Attentionを採用した理由実装手順使用データのフォーマット必要ライブラリのインストール・インポートデータの前処理学習評価・出力まとめGoogle 無料リスティングとは？2020年10月にGoogleから公開されたGoogleショッピングタブに無料で商品掲載ができる「無料リスティング」のことです。Google 検索にサイトがインデックス登録されても料金が発生しないのと同様に、EC事業者は無料で利用可能になりました。Google 無料リスティングについての詳細は以下のサイトが参考になります。lab.ecbooster.jpなぜ今回分析が必要とされたのか？無料リスティングでは自社製品を無料でGoogleに掲載できます。しかしながら、課題として一部商品掲載が不承認となるケースが見受けられました。不承認となってしまうと自社商品の掲載ができていない状況が発生しています。不承認となる理由としては、「Googleが定める基準に対して、登録している商品データの属性数が足りない、内容が仕様に沿っていない場合、商品データの品質が低いため不承認になり、Googleの検索結果に表示させることができません。」とされています。これらを定量的に分析することで不承認となる理由を見つけ出す試みが始まりました。そのため今回の分析の目的は、商品の属性情報（title,description）から承認・不承認の要因を見つけ出し、不承認の商品を承認へと改善するための施策を考案することです。結果と考察今回の目的である「商品の属性情報（title,description）から承認・不承認の要因を見つけ出し、不承認の商品を承認へと改善するための施策を考案する」は、達成できませんでした。目的が達成できなかった理由として考えられる要因は、承認・不承認は商品のtitle,descriptionだけでは判断されていないということです。商品ごとのtitle,descriptionのみで承認・不承認が判断されているのではなく、商品データ全体またはアカウント全体のデータを総合的に見て、判断されている可能性が高いということがわかりました。承認・不承認予測のAccuracyとしては5割〜６割ほどで、承認・不承認を予測するという点でも低い精度となってしまいました。Self-Attentionを採用した理由今回はSelf-Attentionという手法を用いてこの課題解決を試みました。Self-Attentionとは、文章全体で重要とされるキーワードが予測結果と一緒に確認できるようになる手法です。Self-Attentionの仕組みについては詳しく書かれている方が多くいますので、ここでは割愛します。最初は、word2vecを用いて文章特徴量を作成し、承認・不承認を予測して終了という一連の流れを想定していました。しかし、今回の目的は承認・不承認を予測したいわけではなく、どの単語が承認・不承認と関わっているのかを確認し、不承認となっているアカウントを承認にすることです。もし仮にword2vecを用いた手法を採用すると予測結果の要因や理由が明確にならないので、不承認のアカウントを承認に改善する施策を考えることはできません。そのため今回は、Self-Attentionを用いて分類モデルを構築することで、承認・不承認の要因が文章内のどこにあるのかを分析するために、この手法を選択しました。実装手順本来の目的は達成できませんでしたが、Self-Attentionでの分類モデルの実装はできましたので、実装方法を記載します。今回はkerasを用いてSelf-Attention + LSTMで予測を行いました。検証環境はGoogle Colaboratoryを想定しています。使用データのフォーマット今回使用できるデータとしては以下のようなデータになっています。各アカウント・各商品ごとに商品IDが割り振られており、それぞれの商品にtitle,descriptionが割り振られています。承認・不承認のラベルは、アカウントごとに付加されています。必要ライブラリのインストール・インポート!pip install text_vectorian!pip install mojimoji!apt install aptitude!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y!pip install mecab-python3==0.7import pandas as pdimport numpy as npimport kerasimport osimport warningswarnings.simplefilter('ignore')import subprocessimport mojimojiimport reimport MeCabimport matplotlib.pyplot as pltfrom keras.layers import Dense, Dropout, LSTM, Embedding, BatchNormalizationfrom keras.layers.wrappers import Bidirectionalfrom keras.callbacks import EarlyStopping, ModelCheckpointfrom keras import Input, Model, utilsfrom keras.preprocessing.sequence import pad_sequencesfrom keras.callbacks import EarlyStoppingfrom text_vectorian import SentencePieceVectorianfrom keras_self_attention import SeqSelfAttentionfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import classification_reportデータの前処理# データの読み込みapp = pd.read_csv('data/app.csv') # 承認データdisapp = pd.read_csv('data/disapp.csv') # 不承認データapp['target'] = 'app' # targetにlabelを代入するdisapp['target'] = 'disapp'# 今回は、titleとdescriptionを用いて予測するので、それら二つの変数を一つにまとめるapp['sentence'] = app['title'] + app['description'] disapp['sentence'] = disapp['title'] + disapp['description']# これまで別々に処理していたappとdisappをまとめてdfとするdf = app.append(disapp)今回のデータは特殊で、承認・不承認は商品ごとについているラベルではなくアカウントと紐づいたラベルとなっています。それらを各商品と承認・不承認が紐づいているとして各商品ごとに予測することを行ってます。ここで注意が必要なのは、データの分割方法です。アカウントを無視してデータを分割してしまうとリークを起こす可能性があります（リークとは、本来予測では使用できないデータが学習時に入ってしまっていることです）。そのため同じアカウントのデータが訓練データ、検証データ、テストデータに渡って存在しないようにしなければなりません。例えば、アカウントAの商品データは全て訓練データとする,アカウントBの商品データは全てテストデータにするといったようなことを意味しています。アカウントごとにデータを分割するには、各アカウントごとの商品数がある程度同じである方がlabelが不均衡にならないと考え、データ数を揃える処理を施しました。（これらはGroupKFoldを使用すれば解決できると考えられますが、分析実施時はGroupKFoldを知らなかった）# アカウントごとに商品数が異なるので50以上商品数がある場合は50までの商品を使用する# アカウントごとに商品数を揃えることで、labelが不均衡になることを緩和している# アカウントごとにlabelがふられるが、商品ごとに予測結果を出す時のみ実施cutted_df = pd.DataFrame([])for acc in df.account_name.unique():  data = df[df.account_name == acc]  if data.shape[0] \u003e 50:     data = data[:50]  cutted_df = pd.concat([cutted_df,data],0)  df = cutted_df.sample(frac=1,random_state=1).reset_index(drop=True)次は、データの前処理についてです。自然言語処理の前処理で有効と言われている半角-\u003e全角、数字は全て0にする、スペース文字の消去を行いました。また、これまでlabelが'app'または'disapp'だったのでそれらを入力できる形式に変換しています。def PreprocessData(df,dirname):  # データの前処理関数  # 辞書型を返す  mecab = MeCab.Tagger('-Ochasen')  # textデータの前処理  df = TextPreprocess(df)  label2index = {k: i for i, k in enumerate(df.target.unique())}  index2label = {i: k for i, k in enumerate(df.target.unique())}  class_count = len(label2index)  labels = utils.to_categorical([label2index[label] for label in df.target], num_classes=class_count)  features,sentences,vectorian,account = MakeFeatures(df)  return {      'class_count': class_count,      'label2index': label2index,      'index2label': index2label,      'labels': labels,      'features': features,      'sentences':sentences,      'input_len': vectorian.max_tokens_len,      'vectorian':vectorian,      'account':account  }def TextPreprocess(df):  for i in df.index:    sen = df.loc[i,'sentence']    sen = mojimoji.han_to_zen(sen)    sen = re.sub(r'\\d+','0',sen)    df.loc[i,'sentence'] = sen.replace('\\u3000','')  return dfdef MakeFeatures(df):  vectorian = SentencePieceVectorian()  features = []  sentences = []  accounts = []  for feature,account in zip(df['sentence'],df['account_name']):    f = vectorian.fit(feature).indices    features.append(f)    sentences.append(feature)    accounts.append(account)  features = pad_sequences(features, maxlen=vectorian.max_tokens_len)  return features,sentences,vectorian,accountsでは、ここまでの前処理を流します。data = PreprocessData(df,dirname) # dirnameは、出力結果などを入れたいpath入れてください次はtrain_test_splitを行いますが、先ほども記述した通り通常の手法ではリークするので、以下のようにしました。（上述の通りGroupKFoldの実施で回避できる）def CollectData(data,account):  features = []  sentences = []  labels = []    for ac in account:    where_ = np.where(np.array(data['account']) == ac)    features.extend(np.array(data['features'])[where_])    sentences.extend(np.array(data['sentences'])[where_])    labels.extend(np.array(data['labels'])[where_])  return np.array(features),np.array(sentences),np.array(labels)train_account,test_account = train_test_split(list(set(data['account'])),test_size=0.2,random_state=1)train_account,val_account = train_test_split(train_account,test_size=0.25,random_state=1)train_features,train_sen,train_labels = CollectData(data,train_account)val_features,val_sen,val_labels = CollectData(data,val_account)test_features,test_sen,test_labels = CollectData(data,test_account)通常のデータセットであれば、以下のようにすることでデータの分割が行えます。(train_features,val_features, train_labels,val_labels, train_sen,val_sen) = train_test_split(data['features'], data['labels'], data['sentences'], test_size=0.2, random_state=1)(train_features,test_features, train_labels,test_labels, train_sen,test_sen) = train_test_split(train_features, train_labels, train_sen, test_size=0.25, random_state=1)ここまででデータの整形が完了です。学習次は、モデルの定義を行います。def _create_model(input_shape, hidden, class_count,vectorian):    input_tensor = Input(input_shape)    common_input = vectorian.get_keras_layer(trainable=True)(input_tensor)    x1 = SeqSelfAttention(name='attention')(common_input)    x1 = Bidirectional(LSTM(hidden))(x1)    x1 = Dropout(0.5)(x1)    x1 = Dense(32)(x1)    x1 = Dropout(0.5)(x1)    x1 = Dense(16)(x1)    x1 = Dropout(0.5)(x1)    output_tensor = Dense(class_count, activation='softmax', name='class')(x1)    model = Model(input_tensor, output_tensor)    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['acc'])    return modelhidden = 356model = _create_model(train_features[0].shape, hidden, data['class_count'],data['vectorian'])model.summary()作成したモデルにデータを流して学習を進めます。model_filename='{0}/model.h5'.format(dirname)history = model.fit(train_features, train_labels,                    epochs=50,                    batch_size=32,                    validation_data=(val_features, val_labels),                    shuffle=False,                    callbacks = [                        EarlyStopping(patience=5, monitor='val_acc', mode='max'),                        ModelCheckpoint(filepath=model_filename, monitor='val_acc', mode='max', save_best_only=True)                    ])評価・出力ModelCheckpointで保存したmodelを読み取り、さらにSelf-Attentionの結果を得られるようにします。from keras.models import load_modelmodel = load_model(model_filename, custom_objects=SeqSelfAttention.get_custom_objects())model = Model(inputs=model.input, outputs=[model.output, model.get_layer('attention').output])modelにtest dataを入れて結果を取得します。out = model.predict(test_features)y = out[0] # 予測labelのsoftmaxが入っているweight = out[1] # Self-Attentionのweighが入っているpred = np.argmax(y,1) # 予測値max = np.max(y,1) # 信頼値df_y = pd.DataFrame(np.array([np.argmax(test_labels,1),pred,max*100]).T,columns=['true','pred','trust']) # 結果をまとめておくと精度確認に使える精度の確認を行います。ただ、testを入力し得られた結果を出力するだけでは精度が得られなかったので、信頼値が高いものだけを選別し、出力するようにしました。信頼値を90~55の間で出力し、最もAccuracyが高い時の信頼値以上のものを出力としました。 一方で信頼値を上げすぎるとわずかな出力しか得られないので、元のtestデータ数の1/3はデータ数が出力として確保できるような条件を加えました。report = classification_report(pred, np.argmax(test_labels,1),output_dict=True,target_names=[data['index2label'][i] for i in [0,1]])FirstReport_df = pd.DataFrame(report).Tprint(FirstReport_df)FirstReport_df.to_csv(dirname+'NotCutReport.csv')# 信頼値が高い予測だけを出力とすることで確からしいものだけをみるAppSupport = FirstReport_df.loc['app','support'] # 予測した数を取得DisappSupport = FirstReport_df.loc['disapp','support']for UpperLimit in range(90,55,-1):  max_acc = 0  for i in range(50,UpperLimit,1):    df_y_cut = df_y[df_y.trust \u003e i]    report = classification_report(df_y_cut.pred, df_y_cut.true ,output_dict=True)    report_df = pd.DataFrame(report).T    acc = report_df.loc['accuracy','precision']    if max_acc \u003c acc:      max_acc = acc      max_i = i  df_y_cut = df_y[df_y.trust \u003e max_i]  report = classification_report(df_y_cut.pred, df_y_cut.true ,output_dict=True,target_names=[data['index2label'][i] for i in [0,1]])  report_df = pd.DataFrame(report).T  if (report_df.loc['app','support'] \u003e HighSupport/3) and (report_df.loc['disapp','support'] \u003e LowSupport/3):    # 元の予測値の1/3のデータ数が確保できていればクリア    print('UpperLimit:' + str(UpperLimit))    print('max_i:' + str(max_i))    print(report_df)    report_df.to_csv(dirname+'Report.csv')    break最後にSelf-AttentionのWeightをcsvで出力します。得られた出力結果は、予測値-承認と真値-承認、予測値-承認と真値-不承認、予測値-不承認と真値-承認、予測値-不承認と真値-不承認のように予測値と真値の結果に応じて4つに分けてcsvで出力するようになっています。app_app = pd.DataFrame([])app_disapp = pd.DataFrame([])disapp_app = pd.DataFrame([])disapp_disapp = pd.DataFrame([])for i in range(len(test_features)):  input_text = test_sen[i]  tokens = data['vectorian'].tokenizer._tokenizer.encode_as_pieces(input_text)  conf = out[0][i] * 100  wei = out[1][i]  if np.max(conf) \u003c= max_i:    continue  pred = [data['index2label'][np.argmax(conf)]]  labels = [data['index2label'][np.argmax(test_labels[i])]]  weights = [w.max() for w in wei[-len(tokens):]]  df = pd.DataFrame([tokens, weights], index=['token', 'weight']).T  mean = np.asarray(weights).mean()  for j in df.index:    if df.loc[j,'weight'] - mean \u003c= 0:      df.loc[j,'weight'] = 0    else:      df.loc[j,'weight'] = df.loc[j,'weight'] - mean    pred += df.token.values.tolist()  labels += df.weight.values.tolist()  final = pd.DataFrame(np.array([pred,labels]).T,columns=['pred',input_text])  if (pred[0] == 'app') \u0026 (labels[0] == 'app'):    app_app = pd.concat([app_app,final],1)  elif (pred[0]  == 'app') \u0026 (labels[0] == 'disapp'):    app_disapp = pd.concat([app_disapp,final],1)  elif (pred[0]  == 'disapp') \u0026 (labels[0] == 'app'):    disapp_app = pd.concat([disapp_app,final],1)  elif (pred[0]  == 'disapp') \u0026 (labels[0] == 'diaspp'):    disapp_disapp = pd.concat([disapp_disapp,final],1)app_app.to_csv(dirname+'app_app.csv',index=False)app_disapp.to_csv(dirname+'app_disapp.csv',index=False)disapp_app.to_csv(dirname+'disapp_app.csv',index=False)disapp_disapp.to_csv(dirname+'disapp_disapp.csv',index=False)まとめSelf-Attentionを用いて無料リスティングの不承認理由を解き明かそうと分析しました。しかし、title,descriptionのみからは承認と不承認を分類することができず、不承認理由の解明には貢献できせんでした。Self-Attentionとデータセットの相性が悪いという可能性も考えられるので、tfidf+lgbも試みましたが、こちらもうまくいきませんでした。やはりこちらの結果からもtitle,descriptionのみからは承認と不承認を分類することができないということが考えられます。","link":"https://developer.feedforce.jp/entry/2021/03/11/101244","isoDate":"2021-03-11T01:12:44.000Z","dateMiliSeconds":1615425164000,"imageUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/n/newton800/20210224/20210224172435.png","authorName":"feedforce"},{"title":"データ指向アプリケーションデザイン 第三章 旅行記","content":"\u003cp\u003eこんにちは。\u003ca href=\"http://blog.hatena.ne.jp/kano-e/\" class=\"hatena-id-icon\"\u003e\u003cimg src=\"https://cdn.profile-image.st-hatena.com/users/kano-e/profile.png\" width=\"16\" height=\"16\" alt=\"\" class=\"hatena-id-icon\"\u003eid:kano-e\u003c/a\u003e です。\u003c/p\u003e\n\n\u003cp\u003e先日 \u003ca href=\"https://developer.feedforce.jp/entry/2021/03/02/172959\"\u003eデータ指向アプリケーションデザイン 第二章 旅行記\u003c/a\u003e という記事を公開しました。\u003cbr /\u003e\n今日はその続き、第三章です。\u003c/p\u003e\n\n\u003cp\u003e第三章も第二章と同じく、地図への書き込みという形で読書記録を作りました。\u003c/p\u003e\n\n\u003cp\u003e第三章の章題は「ストレージと抽出」です。\u003cbr /\u003e\nその旅路は以下の画像の通り。\u003c/p\u003e\n\n\u003cp\u003e\u003cfigure class=\"figure-image figure-image-fotolife\" title=\"データ指向アプリケーションデザイン 第三章 旅行記\"\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/k/kano-e/20191216/20191216212951.jpg\" alt=\"f:id:kano-e:20191216212951j:plain\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003cfigcaption\u003eデータ指向アプリケーションデザイン 第三章 旅行記\u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e\n\n\u003cp\u003e第三章では分散データ洋に浮かぶ島を舞台に、トランザクション共和国のログストラクチャ、B-Tree領、そして分析王国のデータウェアハウス領まで旅をしました。\u003c/p\u003e\n\n\u003cp\u003eこの旅の記録が、ツールの選定やチューニングの際の道標になるのでは、と思います。\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"hatena-asin-detail\"\u003e\u003ca href=\"https://www.amazon.co.jp/exec/obidos/ASIN/4873118700/hatena-blog-22/\"\u003e\u003cimg src=\"https://m.media-amazon.com/images/I/51T+k4VRzpL.jpg\" class=\"hatena-asin-detail-image\" alt=\"データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理\" title=\"データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理\"\u003e\u003c/a\u003e\u003cdiv class=\"hatena-asin-detail-info\"\u003e\u003cp class=\"hatena-asin-detail-title\"\u003e\u003ca href=\"https://www.amazon.co.jp/exec/obidos/ASIN/4873118700/hatena-blog-22/\"\u003eデータ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理\u003c/a\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cspan class=\"hatena-asin-detail-label\"\u003e作者:\u003c/span\u003e\u003ca href=\"http://d.hatena.ne.jp/keyword/Martin%20Kleppmann\" class=\"keyword\"\u003eMartin Kleppmann\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003cspan class=\"hatena-asin-detail-label\"\u003e発売日:\u003c/span\u003e 2019/07/18\u003c/li\u003e\u003cli\u003e\u003cspan class=\"hatena-asin-detail-label\"\u003eメディア:\u003c/span\u003e 単行本（ソフトカバー）\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003cdiv class=\"hatena-asin-detail-foot\"\u003e\u003c/div\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cp\u003eよろしければ第二章の記録もどうぞ。\u003c/p\u003e\n\n\u003cp\u003e\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fdeveloper.feedforce.jp%2Fentry%2F2021%2F03%2F02%2F172959\" title=\"データ指向アプリケーションデザイン 第二章 旅行記 - Feedforce Developer Blog\" class=\"embed-card embed-blogcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 190px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://developer.feedforce.jp/entry/2021/03/02/172959\"\u003edeveloper.feedforce.jp\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eそれでは、みなさま、良い旅を！\u003c/p\u003e\n","contentSnippet":"こんにちは。id:kano-e です。先日 データ指向アプリケーションデザイン 第二章 旅行記 という記事を公開しました。第三章も第二章と同じく、地図への書き込みという形で読書記録を作りました。第三章の章題は「ストレージと抽出」です。データ指向アプリケーションデザイン 第三章 旅行記第三章では分散データ洋に浮かぶ島を舞台に、トランザクション共和国のログストラクチャ、B-Tree領、そして分析王国のデータウェアハウス領まで旅をしました。この旅の記録が、ツールの選定やチューニングの際の道標になるのでは、と思います。データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理作者:Martin Kleppmann発売日: 2019/07/18メディア: 単行本（ソフトカバー）よろしければ第二章の記録もどうぞ。developer.feedforce.jpそれでは、みなさま、良い旅を！","link":"https://developer.feedforce.jp/entry/2021/03/04/180304","isoDate":"2021-03-04T09:03:04.000Z","dateMiliSeconds":1614848584000,"imageUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/k/kano-e/20191216/20191216212951.jpg","authorName":"feedforce"},{"title":"データ指向アプリケーションデザイン 第二章 旅行記","content":"\u003cp\u003eこんにちは！\n\u003ca href=\"http://blog.hatena.ne.jp/kano-e/\" class=\"hatena-id-icon\"\u003e\u003cimg src=\"https://cdn.profile-image.st-hatena.com/users/kano-e/profile.png\" width=\"16\" height=\"16\" alt=\"\" class=\"hatena-id-icon\"\u003eid:kano-e\u003c/a\u003e です。\u003c/p\u003e\n\n\u003cp\u003e今日は『データ指向アプリケーションデザイン』という本の読書記録を公開しにきました。\u003c/p\u003e\n\n\u003cp\u003eこちらの本、章毎にその章を象徴するような地図が挿絵として挿入されています。\u003cbr /\u003e\n地図が描かれている本て良いですよね。主人公たちの物語が進む旅に、地図を眺めに戻って「今この辺りかな」なんて思いを馳せたりするのが楽しくて、好きです。\u003c/p\u003e\n\n\u003cp\u003eというわけで、この『データ指向アプリケーションデザイン』でも、そのように「今はこの地図のこの辺りだなあ」なんて思いながら読み進めていました。\u003c/p\u003e\n\n\u003cp\u003eその読書記録、あるいは旅の記録が以下の画像です。\u003c/p\u003e\n\n\u003cp\u003e\u003cfigure class=\"figure-image figure-image-fotolife\" title=\"データ指向アプリケーションデザイン 第二章 旅行記\"\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/k/kano-e/20191210/20191210215742.jpg\" alt=\"f:id:kano-e:20191210215742j:plain\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003cfigcaption\u003eデータ指向アプリケーションデザイン 第二章 旅行記\u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e\n\n\u003cp\u003e第二章の章題は「データモデルとクエリ言語」。\u003cbr /\u003e\n様々なデータモデルを俯瞰して眺めるような旅になりました。\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"hatena-asin-detail\"\u003e\u003ca href=\"https://www.amazon.co.jp/exec/obidos/ASIN/4873118700/hatena-blog-22/\"\u003e\u003cimg src=\"https://m.media-amazon.com/images/I/51T+k4VRzpL.jpg\" class=\"hatena-asin-detail-image\" alt=\"データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理\" title=\"データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理\"\u003e\u003c/a\u003e\u003cdiv class=\"hatena-asin-detail-info\"\u003e\u003cp class=\"hatena-asin-detail-title\"\u003e\u003ca href=\"https://www.amazon.co.jp/exec/obidos/ASIN/4873118700/hatena-blog-22/\"\u003eデータ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理\u003c/a\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cspan class=\"hatena-asin-detail-label\"\u003e作者:\u003c/span\u003e\u003ca href=\"http://d.hatena.ne.jp/keyword/Martin%20Kleppmann\" class=\"keyword\"\u003eMartin Kleppmann\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003cspan class=\"hatena-asin-detail-label\"\u003e発売日:\u003c/span\u003e 2019/07/18\u003c/li\u003e\u003cli\u003e\u003cspan class=\"hatena-asin-detail-label\"\u003eメディア:\u003c/span\u003e 単行本（ソフトカバー）\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003cdiv class=\"hatena-asin-detail-foot\"\u003e\u003c/div\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cp\u003eアプリケーションは常に変化し続けます。その中で、どのようにデータというものと向き合ってゆくのか。そんな内容が書かれている面白い本です。\u003cbr /\u003e\nぜひ一緒にこの本を旅しましょう。\u003c/p\u003e\n\n\u003cp\u003e旅の記録を書きとめるのに使ったホワイトボードはこちら。\u003c/p\u003e\n\n\u003cp\u003e\u003cdiv class=\"hatena-asin-detail\"\u003e\u003ca href=\"https://www.amazon.co.jp/exec/obidos/ASIN/B00V47UVK2/hatena-blog-22/\"\u003e\u003cimg src=\"https://m.media-amazon.com/images/I/41AGC8LpKML.jpg\" class=\"hatena-asin-detail-image\" alt=\"nu board (ヌーボード) A4判 NGA403FN08\" title=\"nu board (ヌーボード) A4判 NGA403FN08\"\u003e\u003c/a\u003e\u003cdiv class=\"hatena-asin-detail-info\"\u003e\u003cp class=\"hatena-asin-detail-title\"\u003e\u003ca href=\"https://www.amazon.co.jp/exec/obidos/ASIN/B00V47UVK2/hatena-blog-22/\"\u003enu board (ヌーボード) A4判 NGA403FN08\u003c/a\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cspan class=\"hatena-asin-detail-label\"\u003e発売日:\u003c/span\u003e 2015/04/01\u003c/li\u003e\u003cli\u003e\u003cspan class=\"hatena-asin-detail-label\"\u003eメディア:\u003c/span\u003e オフィス用品\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003cdiv class=\"hatena-asin-detail-foot\"\u003e\u003c/div\u003e\u003c/div\u003e\u003c/p\u003e\n\n\u003cp\u003eこのタイプの nu board には透明シートがあるので、そのシートの下に地図のコピーを置いて、文字や旅路を辿った線は透明シートの上に書いています。\u003cbr /\u003e\n大きくてのびのび書き込めて便利です。\u003c/p\u003e\n\n\u003cp\u003eそれではみなさん、良い旅を！\u003c/p\u003e\n","contentSnippet":"こんにちは！id:kano-e です。今日は『データ指向アプリケーションデザイン』という本の読書記録を公開しにきました。こちらの本、章毎にその章を象徴するような地図が挿絵として挿入されています。というわけで、この『データ指向アプリケーションデザイン』でも、そのように「今はこの地図のこの辺りだなあ」なんて思いながら読み進めていました。その読書記録、あるいは旅の記録が以下の画像です。データ指向アプリケーションデザイン 第二章 旅行記第二章の章題は「データモデルとクエリ言語」。データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理作者:Martin Kleppmann発売日: 2019/07/18メディア: 単行本（ソフトカバー）アプリケーションは常に変化し続けます。その中で、どのようにデータというものと向き合ってゆくのか。そんな内容が書かれている面白い本です。旅の記録を書きとめるのに使ったホワイトボードはこちら。nu board (ヌーボード) A4判 NGA403FN08発売日: 2015/04/01メディア: オフィス用品このタイプの nu board には透明シートがあるので、そのシートの下に地図のコピーを置いて、文字や旅路を辿った線は透明シートの上に書いています。それではみなさん、良い旅を！","link":"https://developer.feedforce.jp/entry/2021/03/02/172959","isoDate":"2021-03-02T08:29:59.000Z","dateMiliSeconds":1614673799000,"imageUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/k/kano-e/20191210/20191210215742.jpg","authorName":"feedforce"},{"title":"Terraform の terraform-provider-datadog で古い source から新しい source に更新する際の Warning を解消する方法","content":"\u003cp\u003eソーシャルPLUS の開発チーム でインフラエンジニア をしている \u003ca href=\"http://blog.hatena.ne.jp/mayuki123/\" class=\"hatena-id-icon\"\u003e\u003cimg src=\"https://cdn.profile-image.st-hatena.com/users/mayuki123/profile.png\" width=\"16\" height=\"16\" alt=\"\" class=\"hatena-id-icon\"\u003eid:mayuki123\u003c/a\u003e です。\u003c/p\u003e\n\n\u003cp\u003eソーシャルPLUS のインフラ環境は基本的に Terraform を利用して管理をしています。今回は、Terraform の \u003ca href=\"https://github.com/DataDog/terraform-provider-datadog\"\u003eterraform-provider-datadog\u003c/a\u003e で \u003ccode\u003eterraform init\u003c/code\u003e を実行時の Warning を解消するのに頭を悩ませたので書き残しておきます。\u003c/p\u003e\n\n\u003ch2\u003e発生していた事象\u003c/h2\u003e\n\n\u003cp\u003eDatadog Provider を利用している所で \u003ccode\u003eterraform init\u003c/code\u003e を実行すると、下記のWarning が表示されるようになりました。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003eWarning: Additional provider information from registry\n\nThe remote registry returned warnings for\nregistry.terraform.io/terraform-providers/datadog:\n- For users on Terraform 0.13 or greater, this provider has moved to\nDataDog/datadog. Please update your source in required_providers.\u003c/pre\u003e\n\n\n\u003cp\u003eDatadog Provider を導入した時は、 Source に \u003ccode\u003eterraform-providers/datadog\u003c/code\u003e を指定する必要がありましたが、現在は \u003ccode\u003eDataDog/datadog\u003c/code\u003e が推奨との事で変更する必要があるようです。Terraform のコードで Source を変更すればいとも簡単に解決するだろうとこの時の私は思っていました。\u003c/p\u003e\n\n\u003cp\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/m/mayuki123/20210208/20210208175250.png\" alt=\"f:id:mayuki123:20210208175250p:plain\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003eTerraform の コードを修正後に \u003ccode\u003eterraform init\u003c/code\u003e を実行して Provider を更新した後に、 \u003ccode\u003eterraform providers\u003c/code\u003e を実行してみると State では \u003ccode\u003eregistry.terraform.io/terraform-providers/datadog\u003c/code\u003e を使い続ける事象に陥りました。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e% terraform providers\nProviders required by configuration:\n.\n├── provider[registry.terraform.io/hashicorp/aws] 3.27.0\n├── provider[registry.terraform.io/datadog/datadog] 2.20.0\n\n/// 中略 ///\n\nProviders required by state:\n\n    provider[registry.terraform.io/hashicorp/aws]\n\n    provider[registry.terraform.io/terraform-providers/datadog]\n\n    provider[terraform.io/builtin/terraform]\u003c/pre\u003e\n\n\n\u003cp\u003e Terraform v0.14.x で追加されるようになった \u003ccode\u003e.terraform.lock.hcl\u003c/code\u003e には Provider として \u003ccode\u003eregistry.terraform.io/datadog/datadog\u003c/code\u003e が新しく追加はされますが、 \u003ccode\u003eregistry.terraform.io/terraform-providers/datadog\u003c/code\u003e が残り続けていました。亡霊なのでしょうか。\u003c/p\u003e\n\n\u003ch2\u003e解決方法\u003c/h2\u003e\n\n\u003cp\u003e\u003ccode\u003eterraform state replace-provider\u003c/code\u003e コマンドを実行する事で、State 上の既存のリソースに対して Terraform の Datadog provider の Source として \u003ccode\u003eDataDog/datadog\u003c/code\u003e を利用するように変更する必要がありました。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003eterraform state replace-provider \\\n\u0026#39;registry.terraform.io/terraform-providers/datadog\u0026#39; \\\n\u0026#39;registry.terraform.io/datadog/datadog\u0026#39;\u003c/pre\u003e\n\n\n\u003cp\u003e実行すると下記のような確認が表示されるので、 \u003ccode\u003eyes\u003c/code\u003e を入力すると更新されます。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e% terraform state replace-provider \u0026#39;registry.terraform.io/terraform-providers/datadog\u0026#39; \u0026#39;registry.terraform.io/datadog/datadog\u0026#39; \nTerraform will perform the following actions:\n\n  ~ Updating provider:\n    - registry.terraform.io/terraform-providers/datadog\n    + registry.terraform.io/datadog/datadog\n\nChanging 1 resources:\n\n  datadog_integration_aws.xxxx\n\nDo you want to make these changes?\nOnly \u0026#39;yes\u0026#39; will be accepted to continue.\n\nEnter a value: yes\u003c/pre\u003e\n\n\n\u003cp\u003e\u003ccode\u003eterraform state replace-provider\u003c/code\u003e コマンドを実行後に \u003ccode\u003eterraform init\u003c/code\u003e を実行すると Warning は解消されました。Terraform provider の Source の変更はあまり発生しない気はしますが、同じような事象にハマった時にはご参考になればと思います。\u003c/p\u003e\n","contentSnippet":"ソーシャルPLUS の開発チーム でインフラエンジニア をしている id:mayuki123 です。ソーシャルPLUS のインフラ環境は基本的に Terraform を利用して管理をしています。今回は、Terraform の terraform-provider-datadog で terraform init を実行時の Warning を解消するのに頭を悩ませたので書き残しておきます。発生していた事象Datadog Provider を利用している所で terraform init を実行すると、下記のWarning が表示されるようになりました。Warning: Additional provider information from registryThe remote registry returned warnings forregistry.terraform.io/terraform-providers/datadog:- For users on Terraform 0.13 or greater, this provider has moved toDataDog/datadog. Please update your source in required_providers.Datadog Provider を導入した時は、 Source に terraform-providers/datadog を指定する必要がありましたが、現在は DataDog/datadog が推奨との事で変更する必要があるようです。Terraform のコードで Source を変更すればいとも簡単に解決するだろうとこの時の私は思っていました。Terraform の コードを修正後に terraform init を実行して Provider を更新した後に、 terraform providers を実行してみると State では registry.terraform.io/terraform-providers/datadog を使い続ける事象に陥りました。% terraform providersProviders required by configuration:.├── provider[registry.terraform.io/hashicorp/aws] 3.27.0├── provider[registry.terraform.io/datadog/datadog] 2.20.0/// 中略 ///Providers required by state:    provider[registry.terraform.io/hashicorp/aws]    provider[registry.terraform.io/terraform-providers/datadog]    provider[terraform.io/builtin/terraform] Terraform v0.14.x で追加されるようになった .terraform.lock.hcl には Provider として registry.terraform.io/datadog/datadog が新しく追加はされますが、 registry.terraform.io/terraform-providers/datadog が残り続けていました。亡霊なのでしょうか。解決方法terraform state replace-provider コマンドを実行する事で、State 上の既存のリソースに対して Terraform の Datadog provider の Source として DataDog/datadog を利用するように変更する必要がありました。terraform state replace-provider \\'registry.terraform.io/terraform-providers/datadog' \\'registry.terraform.io/datadog/datadog'実行すると下記のような確認が表示されるので、 yes を入力すると更新されます。% terraform state replace-provider 'registry.terraform.io/terraform-providers/datadog' 'registry.terraform.io/datadog/datadog' Terraform will perform the following actions:  ~ Updating provider:    - registry.terraform.io/terraform-providers/datadog    + registry.terraform.io/datadog/datadogChanging 1 resources:  datadog_integration_aws.xxxxDo you want to make these changes?Only 'yes' will be accepted to continue.Enter a value: yesterraform state replace-provider コマンドを実行後に terraform init を実行すると Warning は解消されました。Terraform provider の Source の変更はあまり発生しない気はしますが、同じような事象にハマった時にはご参考になればと思います。","link":"https://developer.feedforce.jp/entry/2021/02/09/114110","isoDate":"2021-02-09T02:41:10.000Z","dateMiliSeconds":1612838470000,"imageUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/m/mayuki123/20210208/20210208175250.png","authorName":"feedforce"},{"title":"Google MyBusiness APIのGoクライアントを生成する","content":"\u003cp\u003eこんにちは、 \u003ca href=\"http://blog.hatena.ne.jp/kogainotdan/\"\u003eid:kogainotdan\u003c/a\u003e です。\u003c/p\u003e\n\n\u003cp\u003e現在私は新規事業開発のチームで、飲食店支援のサービスの可能性を探索しています。\u003c/p\u003e\n\n\u003cp\u003e飲食店、ひいてはローカルビジネスの運営において、\u003ca href=\"https://blog.feedmatic.net/2019-04-01-134512\"\u003e集客施策として重要\u003c/a\u003eとされるのがGoogleマイビジネスの活用です。\u003c/p\u003e\n\n\u003cp\u003eナレッジパネルやローカル検索において表示されている情報は、ユーザーとしても見たことがある方が多いと思います。\u003c/p\u003e\n\n\u003cp\u003e喫緊の話題としては、緊急事態宣言の前後における営業時間や営業形態の変更の正確な反映が、見込み顧客の取りこぼしを防ぐと共に店舗自体への信頼感の醸成にも役立つものと考えられます。\u003c/p\u003e\n\n\u003cp\u003eそんなGoogleマイビジネスですが、Googleの他のサービス同様にAPIが存在します。\u003c/p\u003e\n\n\u003cp\u003eただし、まだGeneral Availableではない様子で、\u003ca href=\"https://developers.google.com/my-business/content/prereqs\"\u003eフォームによる利用申請\u003c/a\u003eが必要となるのですが、\nGoogleマイビジネスの管理画面で出来る操作の多くをサポートしており、ローカルビジネス関連のサービスを開発する際に重要なパーツとなり得ると思われます。\u003c/p\u003e\n\n\u003cp\u003eさて、そんなGoogle MyBusiness APIですが、公式に提供されているクライアントライブラリが\u003ca href=\"https://developers.google.com/my-business/samples\"\u003eJava, PHP, C#\u003c/a\u003eの3種となっています。\u003c/p\u003e\n\n\u003cp\u003e他のGoogleのサービスと同様にDiscoveryドキュメントが提供されていますので、この3種以外の任意の言語のクライアントライブラリを生成することは可能と思われます。\u003c/p\u003e\n\n\u003cp\u003eそこで本稿では、Google MyBusiness APIのGolangクライアントライブラリの生成までのステップを記録したいと思います。\u003c/p\u003e\n\n\u003ch2\u003eGoogle API Discovery Service\u003c/h2\u003e\n\n\u003cp\u003e\u003ca href=\"https://developers.google.com/my-business/content/prereqs\"\u003e公式ガイドの導入ドキュメント\u003c/a\u003eに沿ってAPIを有効化し、\u003ccode\u003eOAuth 2.0\u003c/code\u003e の認証情報を取得すると、APIリクエストが発行出来るようになります。\n(認証情報の取得は他のサービスと同様なので割愛します)\u003c/p\u003e\n\n\u003cp\u003eなお、APIの利用申請は\u003ccode\u003eorganization\u003c/code\u003e毎に1つだけ許可されるようですのでご注意ください。\u003c/p\u003e\n\n\u003cp\u003eさて、前述のようにGoogle MyBusiness APIのクライアントライブラリは、\u003ca href=\"https://developers.google.com/my-business/samples\"\u003eJava, PHP, C#\u003c/a\u003eの3種のみ提供されています。\u003c/p\u003e\n\n\u003cp\u003eこの3種のいずれかでアプリケーションを開発する手も無くはないですが、すでに稼働している別の言語のコードがある場合など、APIの利用のためだけに別の言語のランタイムを導入するのは大仰に過ぎるというケースもあるかと思います。\n(白状すると、私はこの3種のどれも書いたことがありません)\u003c/p\u003e\n\n\u003cp\u003eところで上記のクライアントライブラリの紹介ページには、以下のようなことも書かれています。\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003eGoogle My Business API Discovery ドキュメントは、この API の個々のバージョンのインターフェースについて解説しています。このドキュメントは Google API Discovery Service とともにご利用ください。\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eSwagger/Open API SpecificationやGraphQLなど、Web APIのクライアントは形式化された仕様から生成するのが一般的になっています。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://developers.google.com/discovery\"\u003eGoogle API Discovery Serviceのサイト\u003c/a\u003eに飛ぶと、\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003eUse the Google API Discovery Service to build client libraries\u003c/p\u003e\n\n\u003cp\u003eThe Discovery API provides a list of Google APIs and a machine-readable \"Discovery Document\" for each API.\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eとあり、これもそういった仕様の一つであることが伺えます。\u003c/p\u003e\n\n\u003ch2\u003eGoogle関連のAPIクライアントライブラリ\u003c/h2\u003e\n\n\u003cp\u003eここでGoogleが提供する\u003ca href=\"https://github.com/googleapis/google-api-go-client\"\u003e各種サービスのAPIクライアントライブラリが集積されたレポジトリ\u003c/a\u003eを見てみましょう。\u003c/p\u003e\n\n\u003cp\u003e何らかの形でこのDiscoveryドキュメントが利用されていることが\u003ca href=\"https://github.com/googleapis/google-api-go-client/search?l=JSON\u0026amp;q=discovery\"\u003e見て取れます\u003c/a\u003e。\nGoほど分かりやすい形ではないですが、\u003ca href=\"https://github.com/googleapis/google-api-ruby-client/search?l=YAML\u0026amp;q=discovery\"\u003eRuby\u003c/a\u003eや\u003ca href=\"https://github.com/googleapis/google-api-dotnet-client/search?q=discovery\"\u003e.NET\u003c/a\u003eでも、同様に利用されていることが伺われます。\u003c/p\u003e\n\n\u003cp\u003eGoogle MyBusiness APIのドキュメントに示されている通り、このレポジトリにはGoogle MyBusiness APIのクライアントライブラリは置かれていません。\u003c/p\u003e\n\n\u003cp\u003eただし\u003ca href=\"https://github.com/googleapis/google-api-go-client/issues/597\"\u003eSupport for Bussiness Messaging private API? #597\u003c/a\u003eに\u003c/p\u003e\n\n\u003cblockquote\u003e\u003cp\u003eIf you want to try out the generator and see if it works for you can.\u003c/p\u003e\n\n\u003cp\u003eYou would need to clone this repo and generate from within it as the code it generates will rely upon some internal packages here.\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eという回答が付いています。\u003c/p\u003e\n\n\u003cp\u003einternal packageを利用する必要があるものの、Discoveryドキュメントさえあれば、個々の開発者がクライアントライブラリを生成する道はありそうです。\u003c/p\u003e\n\n\u003ch2\u003eGoogle MyBusiness API クライアントライブラリの生成\u003c/h2\u003e\n\n\u003cp\u003e上述のIssueから参照されている\u003ca href=\"https://github.com/googleapis/google-api-go-client/issues/283\"\u003eAdd instructions to generate services yourself #283\u003c/a\u003eにあるように、同じレポジトリにコードジェネレータも置いてあるようです。\u003c/p\u003e\n\n\u003cp\u003e実態としては\u003ca href=\"https://github.com/googleapis/google-api-go-client/blob/39bc9cc19fcd620129ddffe34a7531784d1dd793/google-api-go-generator/gen.go#L130-L183\"\u003eGoのmain package\u003c/a\u003eのようですので、forkしてGoogle MyBusiness APIのDiscoveryドキュメントを食わせて上げれば良さそうです。\n公式に公開されたツールというわけではないようなので、ドキュメントなどは見当たりませんが、\u003ccode\u003e--help\u003c/code\u003eオプションで実行してあげるとサポートされているオプションが確認出来ます。\u003c/p\u003e\n\n\u003cpre class=\"code\" data-lang=\"\" data-unlink\u003e  -api string\n        The API ID to generate, like \u0026#39;tasks:v1\u0026#39;. A value of \u0026#39;*\u0026#39; means all. (default \u0026#34;*\u0026#34;)\n  -api_json_file string\n        If non-empty, the path to a local file on disk containing the API to generate. Exclusive with setting --api.\n  -api_pkg_base string\n        Go package prefix to use for all generated APIs. (default \u0026#34;google.golang.org/api\u0026#34;)\n  -base_url string\n        (optional) Override the default service API URL. If empty, the service\u0026#39;s root URL will be used.\n  -build\n        Compile generated packages.\n  -cache\n        Use cache of discovered Google API discovery documents. (default true)\n  -copyright_year string\n        Year for copyright. (default \u0026#34;2021\u0026#34;)\n  -discoveryurl string\n        URL to root discovery document (default \u0026#34;https://www.googleapis.com/discovery/v1/apis\u0026#34;)\n  -gendir string\n        Directory to use to write out generated Go files (default \u0026#34;/Users/kogai/.gvm/pkgsets/go1.14/global/src/google.golang.org/api\u0026#34;)\n  -gensupport_pkg string\n        Go package path of the \u0026#39;api/internal/gensupport\u0026#39; support package. (default \u0026#34;google.golang.org/api/internal/gensupport\u0026#34;)\n  -googleapi_pkg string\n        Go package path of the \u0026#39;api/googleapi\u0026#39; support package. (default \u0026#34;google.golang.org/api/googleapi\u0026#34;)\n  -header_path string\n        If non-empty, prepend the contents of this file to generated services.\n  -htransport_pkg string\n        Go package path of the \u0026#39;api/transport/http\u0026#39; support package. (default \u0026#34;google.golang.org/api/transport/http\u0026#34;)\n  -install\n        Install generated packages.\n  -internaloption_pkg string\n        Go package path of the \u0026#39;api/option/internaloption\u0026#39; support package. (default \u0026#34;google.golang.org/api/option/internaloption\u0026#34;)\n  -option_pkg string\n        Go package path of the \u0026#39;api/option\u0026#39; support package. (default \u0026#34;google.golang.org/api/option\u0026#34;)\n  -output string\n        (optional) Path to source output file. If not specified, the API name and version are used to construct an output path (e.g. tasks/v1).\n  -publiconly\n        Only build public, released APIs. Only applicable for Google employees. (default true)\u003c/pre\u003e\n\n\n\u003cp\u003e\u003ca href=\"https://github.com/googleapis/google-api-go-client/issues/283\"\u003eAdd instructions to generate services yourself #283\u003c/a\u003eで指摘されている\u003ccode\u003eapi_json\u003c/code\u003eなどのオプションも確認出来ます。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://developer.feedforce.jp/entry/2020/12/04/100000\"\u003eGitHub Actionsを使ったShopify テーマの自動デプロイ環境構築\u003c/a\u003eという記事でも触れたのですが、私の管理しているmonorepoレポジトリはBazelでビルドターゲットを管理していますので、\nGoogle MyBusiness APIのクライアントライブラリも、ビルド単位の一つとして扱っています。\u003c/p\u003e\n\n\u003cpre class=\"code bazel\" data-lang=\"bazel\" data-unlink\u003e# WORKSPACE\n\n# Discoveryドキュメントを取得する\nhttp_file(\n    name = \u0026#34;mybusiness_api_go_schema\u0026#34;,\n    downloaded_file_path = \u0026#34;mybusiness.json\u0026#34;,\n    sha256 = \u0026#34;084e68d0fc746fe9d0ba105f6878b8eb208181f5ee1288e79c35a11684ec4a13\u0026#34;,\n    urls = [\u0026#34;https://developers.google.com/my-business/samples/mybusiness_google_rest_v4p7.json\u0026#34;],\n)\n\n# forkしてくる代わりにcloneしておく\nnew_git_repository(\n    name = \u0026#34;google_api_go_client\u0026#34;,\n    # non-bazelレポジトリなので、カスタムのビルドファイルを作っておく\n    build_file = \u0026#34;//:google_api_go_client.bazel\u0026#34;,\n    commit = \u0026#34;074c16e73361434fc3d1f6ef62585d57b70a9d1b\u0026#34;,\n    remote = \u0026#34;https://github.com/googleapis/google-api-go-client.git\u0026#34;,\n    shallow_since = \u0026#34;1608641643 +0000\u0026#34;,\n)\u003c/pre\u003e\n\n\n\n\n\u003cpre class=\"code bazel\" data-lang=\"bazel\" data-unlink\u003e# google_api_go_client.bazel\n# ビルドに必要なのはinternal packageだけ\nexports_files(\n    [] + glob([\u0026#34;internal/**/*.go\u0026#34;]),\n)\u003c/pre\u003e\n\n\n\n\n\u003cpre class=\"code bazel\" data-lang=\"bazel\" data-unlink\u003eload(\u0026#34;@io_bazel_rules_go//go:def.bzl\u0026#34;, \u0026#34;go_binary\u0026#34;)\nload(\u0026#34;@build_bazel_rules_nodejs//:index.bzl\u0026#34;, \u0026#34;generated_file_test\u0026#34;)\n\nfilegroup(\n    name = \u0026#34;gensupport\u0026#34;,\n    srcs = [\n        \u0026#34;@google_api_go_client//:internal/gensupport/buffer.go\u0026#34;,\n        \u0026#34;@google_api_go_client//:internal/gensupport/doc.go\u0026#34;,\n        \u0026#34;@google_api_go_client//:internal/gensupport/json.go\u0026#34;,\n        \u0026#34;@google_api_go_client//:internal/gensupport/jsonfloat.go\u0026#34;,\n        \u0026#34;@google_api_go_client//:internal/gensupport/media.go\u0026#34;,\n        \u0026#34;@google_api_go_client//:internal/gensupport/params.go\u0026#34;,\n        \u0026#34;@google_api_go_client//:internal/gensupport/resumable.go\u0026#34;,\n        \u0026#34;@google_api_go_client//:internal/gensupport/retryable_linux.go\u0026#34;,\n        \u0026#34;@google_api_go_client//:internal/gensupport/send.go\u0026#34;,\n        \u0026#34;@google_api_go_client//:internal/gensupport/version.go\u0026#34;,\n    ],\n)\n\n# gazelle:ignore\ngo_binary(\n    name = \u0026#34;codegen\u0026#34;,\n    args = [\u0026#34;-api_json_file=$(location @mybusiness_api_go_schema//file:mybusiness.json)\u0026#34;],\n    data = [\n        \u0026#34;:gensupport\u0026#34;,\n        \u0026#34;@mybusiness_api_go_schema//file:mybusiness.json\u0026#34;,\n    ],\n    embed = [\n        \u0026#34;@org_golang_google_api//google-api-go-generator\u0026#34;,\n    ],\n    visibility = [\u0026#34;//visibility:public\u0026#34;],\n)\n\ngenerated_file_test(\n    name = \u0026#34;json\u0026#34;,\n    src = \u0026#34;//packages/google-mybusiness-api-go/mybusiness/v4:mybusiness-api.json\u0026#34;,\n    generated = \u0026#34;@mybusiness_api_go_schema//file:mybusiness.json\u0026#34;,\n)\u003c/pre\u003e\n\n\n\u003cp\u003e当初は単純にMakefileにcurlの実行などを書いていたのですが、Discoveryドキュメントを都度取得・クライアントライブラリを生成しているとCIが重くなるので、で適宜キャッシュさせるためにもBazelが効いています。\u003c/p\u003e\n\n\u003cpre class=\"code makefile\" data-lang=\"makefile\" data-unlink\u003emybusiness/v4:\n    npx bazelisk run -- //google-mybusiness-api-go:codegen \\\n        -gendir=\u0026#34;$(CURDIR)\u0026#34; \\\n                # internal以下に置かれたpackageではなく、手元に移したpackageを使う\n        -gensupport_pkg=\u0026#34;github.com/your-organization/your-repository/packages/google-mybusiness-api-go/mybusiness/gensupport\u0026#34;\n    cp -r $(BZL_BIN)/$(PKG)/codegen_/codegen.runfiles/google_api_go_client_internal/internal/gensupport $(CURDIR)/mybusiness\u003c/pre\u003e\n\n\n\u003cp\u003e最後の\u003ccode\u003egenerated_file_test\u003c/code\u003eはクライアントライブラリの生成には直接関係しないのですが、同じレポジトリでTypeScriptのコードも管理している関係でJavaScript関係のBazel Ruleが導入されています。\nついでだったので、Discoveryドキュメントのスナップショットテストのようなこともしています。\u003c/p\u003e\n\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\n\u003cp\u003eGoogle MyBusiness APIのGoクライアントライブラリの生成について書いてみました。\n何かの参考になれば幸いです。\u003c/p\u003e\n","contentSnippet":"こんにちは、 id:kogainotdan です。現在私は新規事業開発のチームで、飲食店支援のサービスの可能性を探索しています。飲食店、ひいてはローカルビジネスの運営において、集客施策として重要とされるのがGoogleマイビジネスの活用です。ナレッジパネルやローカル検索において表示されている情報は、ユーザーとしても見たことがある方が多いと思います。喫緊の話題としては、緊急事態宣言の前後における営業時間や営業形態の変更の正確な反映が、見込み顧客の取りこぼしを防ぐと共に店舗自体への信頼感の醸成にも役立つものと考えられます。そんなGoogleマイビジネスですが、Googleの他のサービス同様にAPIが存在します。ただし、まだGeneral Availableではない様子で、フォームによる利用申請が必要となるのですが、Googleマイビジネスの管理画面で出来る操作の多くをサポートしており、ローカルビジネス関連のサービスを開発する際に重要なパーツとなり得ると思われます。さて、そんなGoogle MyBusiness APIですが、公式に提供されているクライアントライブラリがJava, PHP, C#の3種となっています。他のGoogleのサービスと同様にDiscoveryドキュメントが提供されていますので、この3種以外の任意の言語のクライアントライブラリを生成することは可能と思われます。そこで本稿では、Google MyBusiness APIのGolangクライアントライブラリの生成までのステップを記録したいと思います。Google API Discovery Service公式ガイドの導入ドキュメントに沿ってAPIを有効化し、OAuth 2.0 の認証情報を取得すると、APIリクエストが発行出来るようになります。(認証情報の取得は他のサービスと同様なので割愛します)なお、APIの利用申請はorganization毎に1つだけ許可されるようですのでご注意ください。さて、前述のようにGoogle MyBusiness APIのクライアントライブラリは、Java, PHP, C#の3種のみ提供されています。この3種のいずれかでアプリケーションを開発する手も無くはないですが、すでに稼働している別の言語のコードがある場合など、APIの利用のためだけに別の言語のランタイムを導入するのは大仰に過ぎるというケースもあるかと思います。(白状すると、私はこの3種のどれも書いたことがありません)ところで上記のクライアントライブラリの紹介ページには、以下のようなことも書かれています。Google My Business API Discovery ドキュメントは、この API の個々のバージョンのインターフェースについて解説しています。このドキュメントは Google API Discovery Service とともにご利用ください。Swagger/Open API SpecificationやGraphQLなど、Web APIのクライアントは形式化された仕様から生成するのが一般的になっています。Google API Discovery Serviceのサイトに飛ぶと、Use the Google API Discovery Service to build client librariesThe Discovery API provides a list of Google APIs and a machine-readable \"Discovery Document\" for each API.とあり、これもそういった仕様の一つであることが伺えます。Google関連のAPIクライアントライブラリここでGoogleが提供する各種サービスのAPIクライアントライブラリが集積されたレポジトリを見てみましょう。何らかの形でこのDiscoveryドキュメントが利用されていることが見て取れます。Goほど分かりやすい形ではないですが、Rubyや.NETでも、同様に利用されていることが伺われます。Google MyBusiness APIのドキュメントに示されている通り、このレポジトリにはGoogle MyBusiness APIのクライアントライブラリは置かれていません。ただしSupport for Bussiness Messaging private API? #597にIf you want to try out the generator and see if it works for you can.You would need to clone this repo and generate from within it as the code it generates will rely upon some internal packages here.という回答が付いています。internal packageを利用する必要があるものの、Discoveryドキュメントさえあれば、個々の開発者がクライアントライブラリを生成する道はありそうです。Google MyBusiness API クライアントライブラリの生成上述のIssueから参照されているAdd instructions to generate services yourself #283にあるように、同じレポジトリにコードジェネレータも置いてあるようです。実態としてはGoのmain packageのようですので、forkしてGoogle MyBusiness APIのDiscoveryドキュメントを食わせて上げれば良さそうです。公式に公開されたツールというわけではないようなので、ドキュメントなどは見当たりませんが、--helpオプションで実行してあげるとサポートされているオプションが確認出来ます。  -api string        The API ID to generate, like 'tasks:v1'. A value of '*' means all. (default \"*\")  -api_json_file string        If non-empty, the path to a local file on disk containing the API to generate. Exclusive with setting --api.  -api_pkg_base string        Go package prefix to use for all generated APIs. (default \"google.golang.org/api\")  -base_url string        (optional) Override the default service API URL. If empty, the service's root URL will be used.  -build        Compile generated packages.  -cache        Use cache of discovered Google API discovery documents. (default true)  -copyright_year string        Year for copyright. (default \"2021\")  -discoveryurl string        URL to root discovery document (default \"https://www.googleapis.com/discovery/v1/apis\")  -gendir string        Directory to use to write out generated Go files (default \"/Users/kogai/.gvm/pkgsets/go1.14/global/src/google.golang.org/api\")  -gensupport_pkg string        Go package path of the 'api/internal/gensupport' support package. (default \"google.golang.org/api/internal/gensupport\")  -googleapi_pkg string        Go package path of the 'api/googleapi' support package. (default \"google.golang.org/api/googleapi\")  -header_path string        If non-empty, prepend the contents of this file to generated services.  -htransport_pkg string        Go package path of the 'api/transport/http' support package. (default \"google.golang.org/api/transport/http\")  -install        Install generated packages.  -internaloption_pkg string        Go package path of the 'api/option/internaloption' support package. (default \"google.golang.org/api/option/internaloption\")  -option_pkg string        Go package path of the 'api/option' support package. (default \"google.golang.org/api/option\")  -output string        (optional) Path to source output file. If not specified, the API name and version are used to construct an output path (e.g. tasks/v1).  -publiconly        Only build public, released APIs. Only applicable for Google employees. (default true)Add instructions to generate services yourself #283で指摘されているapi_jsonなどのオプションも確認出来ます。GitHub Actionsを使ったShopify テーマの自動デプロイ環境構築という記事でも触れたのですが、私の管理しているmonorepoレポジトリはBazelでビルドターゲットを管理していますので、Google MyBusiness APIのクライアントライブラリも、ビルド単位の一つとして扱っています。# WORKSPACE# Discoveryドキュメントを取得するhttp_file(    name = \"mybusiness_api_go_schema\",    downloaded_file_path = \"mybusiness.json\",    sha256 = \"084e68d0fc746fe9d0ba105f6878b8eb208181f5ee1288e79c35a11684ec4a13\",    urls = [\"https://developers.google.com/my-business/samples/mybusiness_google_rest_v4p7.json\"],)# forkしてくる代わりにcloneしておくnew_git_repository(    name = \"google_api_go_client\",    # non-bazelレポジトリなので、カスタムのビルドファイルを作っておく    build_file = \"//:google_api_go_client.bazel\",    commit = \"074c16e73361434fc3d1f6ef62585d57b70a9d1b\",    remote = \"https://github.com/googleapis/google-api-go-client.git\",    shallow_since = \"1608641643 +0000\",)# google_api_go_client.bazel# ビルドに必要なのはinternal packageだけexports_files(    [] + glob([\"internal/**/*.go\"]),)load(\"@io_bazel_rules_go//go:def.bzl\", \"go_binary\")load(\"@build_bazel_rules_nodejs//:index.bzl\", \"generated_file_test\")filegroup(    name = \"gensupport\",    srcs = [        \"@google_api_go_client//:internal/gensupport/buffer.go\",        \"@google_api_go_client//:internal/gensupport/doc.go\",        \"@google_api_go_client//:internal/gensupport/json.go\",        \"@google_api_go_client//:internal/gensupport/jsonfloat.go\",        \"@google_api_go_client//:internal/gensupport/media.go\",        \"@google_api_go_client//:internal/gensupport/params.go\",        \"@google_api_go_client//:internal/gensupport/resumable.go\",        \"@google_api_go_client//:internal/gensupport/retryable_linux.go\",        \"@google_api_go_client//:internal/gensupport/send.go\",        \"@google_api_go_client//:internal/gensupport/version.go\",    ],)# gazelle:ignorego_binary(    name = \"codegen\",    args = [\"-api_json_file=$(location @mybusiness_api_go_schema//file:mybusiness.json)\"],    data = [        \":gensupport\",        \"@mybusiness_api_go_schema//file:mybusiness.json\",    ],    embed = [        \"@org_golang_google_api//google-api-go-generator\",    ],    visibility = [\"//visibility:public\"],)generated_file_test(    name = \"json\",    src = \"//packages/google-mybusiness-api-go/mybusiness/v4:mybusiness-api.json\",    generated = \"@mybusiness_api_go_schema//file:mybusiness.json\",)当初は単純にMakefileにcurlの実行などを書いていたのですが、Discoveryドキュメントを都度取得・クライアントライブラリを生成しているとCIが重くなるので、で適宜キャッシュさせるためにもBazelが効いています。mybusiness/v4:    npx bazelisk run -- //google-mybusiness-api-go:codegen \\        -gendir=\"$(CURDIR)\" \\                # internal以下に置かれたpackageではなく、手元に移したpackageを使う        -gensupport_pkg=\"github.com/your-organization/your-repository/packages/google-mybusiness-api-go/mybusiness/gensupport\"    cp -r $(BZL_BIN)/$(PKG)/codegen_/codegen.runfiles/google_api_go_client_internal/internal/gensupport $(CURDIR)/mybusiness最後のgenerated_file_testはクライアントライブラリの生成には直接関係しないのですが、同じレポジトリでTypeScriptのコードも管理している関係でJavaScript関係のBazel Ruleが導入されています。ついでだったので、Discoveryドキュメントのスナップショットテストのようなこともしています。まとめGoogle MyBusiness APIのGoクライアントライブラリの生成について書いてみました。何かの参考になれば幸いです。","link":"https://developer.feedforce.jp/entry/2021/01/12/120000","isoDate":"2021-01-12T03:00:00.000Z","dateMiliSeconds":1610420400000,"imageUrl":"https://cdn.user.blog.st-hatena.com/default_entry_og_image/4268819/1588226000876991","authorName":"feedforce"},{"title":"半期に1度の Engineer’s Principles Award 受賞者を紹介します","content":"\u003cp\u003eこんにちは。人事の今岡と申します。Developer Blog への投稿は初めてで若干緊張しています。\u003c/p\u003e\n\n\u003cp\u003e先日行われたオンライン忘年会にて、半期に一度の「Engineer’s Principles Award 2020 Winter」の受賞者が発表されました。\u003c/p\u003e\n\n\u003cp\u003eアワードが始まって3回目となり、そろそろ社外にも発信していきたいなと思いまして、せっかくなのでこちらのブログでアワードを受賞したメンバーと表彰内容をご紹介しようと思います。\u003c/p\u003e\n\n\u003ch2\u003eEngineer’s Principles Award とは\u003c/h2\u003e\n\n\u003cp\u003eEngineer’s Principles とは、フィードフォースの開発メンバー向けに現場が主体となって設定した、5つの行動指針です。半期に一度、開発メンバー同士で投票を行い、行動指針の項目ごとに最も体現しているメンバーが選ばれ、開発本部長から表彰者が発表されます。\u003c/p\u003e\n\n\u003cp\u003eちなみに、下記の5項目はつい先日アップデートされたばかりで、今年導入されたフルリモートワークという働き方も考慮した内容になりました。この話はまた別の機会に改めて発信しようと思います。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cb\u003eStay Humble\u003c/b\u003e; 常に謙虚であるべし\u003c/li\u003e\n\u003cli\u003e\u003cb\u003eBe Positive \u0026amp; Proactive\u003c/b\u003e; 常に肯定的・主体的であるべし\u003c/li\u003e\n\u003cli\u003e\u003cb\u003eBe Prepared\u003c/b\u003e; 常に来るべき機会に備えるべし\u003c/li\u003e\n\u003cli\u003e\u003cb\u003eShare All\u003c/b\u003e; 己の知見、試行、失敗、遍く共有すべし\u003c/li\u003e\n\u003cli\u003e\u003cb\u003eJust Do It\u003c/b\u003e; 全力でやりきるべし\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003ch2\u003e受賞者紹介\u003c/h2\u003e\n\n\u003cp\u003e※表彰コメントは本来社内向けのものであるため一部変更させていただいています。人によって各種アカウントを載せています。\u003c/p\u003e\n\n\u003ch3\u003e🏆「Stay Humble; 常に謙虚であるべし」受賞者\u003c/h3\u003e\n\n\u003ch4\u003e\u003ca href=\"https://developer.feedforce.jp/archive/author/tmd45\"\u003e@tmd45\u003c/a\u003e さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\n顧客への価値を最大化する中でエンジニアとしてカスタマーサクセスに関わるという会社としても新しいポジションを自分で選択し、サービスやチーム、それぞれの顧客の状況を客観的に捉え、自分が何を求められているか、顧客価値の最大化のために自分は何ができるかを考え抜いている姿勢は素敵です。\u003c/p\u003e\n\n\u003ch4\u003e\u003ca href=\"https://twitter.com/Azmin\"\u003e＠azmin\u003c/a\u003e さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\nDF PLUSという、これまでの歴史や文脈が積み重なった、会社の売上の支えとなるプロダクトチームで日ごろから様々な課題を次々と解決しているなかで、難しい状況にあるときも全方位に対して物腰柔らかく一緒に課題解決していってもらっています。会社にとってとても貴重なメンバーです。\u003c/p\u003e\n\n\u003ch3\u003e🏆「Be Positive \u0026amp; Proactive; 常に肯定的・主体的であるべし」受賞者\u003c/h3\u003e\n\n\u003ch4\u003e\u003ca href=\"https://github.com/kogai\"\u003e@kogai\u003c/a\u003e さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\n新規事業において、顧客価値の最大化を常に見据えつつ、エンジニアとしてのみならず営業やマネージャーの課題も解決するために動くのは、新規事業のプロトタイピング段階では必須です。そういったアクションにハードルの高さを感じるエンジニアも多い中で、率先して全方位的に対応している姿は、まさにプロダクト立ち上げ期にあるべきエンジニアの行動指針そのものです。\u003cbr\u003e\n\u003ci class=\"blogicon-twitter\"\u003e\u003c/i\u003e \u003ca href=\"https://twitter.com/iamchawan\"\u003e\u0026#x8336;\u0026#x7897; (@iamchawan) | Twitter\u003c/a\u003e, \u003ci class=\"blogicon-entry\"\u003e\u003c/i\u003e \u003ca href=\"https://k9bookshelf.com/blogs/development\"\u003eBlog\u003c/a\u003e\u003c/p\u003e\n\n\u003ch4\u003e\u003ca href=\"https://github.com/sukechannnn\"\u003e@sukechannnn\u003c/a\u003e さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\n転換期を迎え、変化が激しいプロダクトチームで、どうすればプロダクトのみならずチームが前進できるかを考え抜いています。この先サービスを大きくする展望を持ちつつ、顧客価値を最大化するために今やるべきことを考える姿は、いかなるときも積極的・主体的に動くという行動指針の見本です。\u003cbr\u003e\n\u003ci class=\"blogicon-twitter\"\u003e\u003c/i\u003e \u003ca href=\"https://twitter.com/sukechannnn\"\u003esukechannnn (@sukechannnn) | Twitter\u003c/a\u003e\u003c/p\u003e\n\n\u003ch3\u003e🏆「Be Prepared; 常に来るべき機会に備えるべし」受賞者\u003c/h3\u003e\n\n\u003ch4\u003e\u003ca href=\"https://github.com/kogai\"\u003e@kogai\u003c/a\u003e さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\nこれまでフィードフォースでは取り組んでこなかった業態にチャレンジするプロジェクトにおいて、着々と開発を進めている点はまさに必要な準備をしてきた証拠だと思います。単純にコードを書くに留まらず、実際に Shopify でのショップ立ち上げなど、プロジェクト開始後の積み上げも他を圧倒する勢いで、まさに Be Prepared を継続しているのは小飼さんです。\u003cbr\u003e\n\u003ci class=\"blogicon-twitter\"\u003e\u003c/i\u003e \u003ca href=\"https://twitter.com/iamchawan\"\u003e\u0026#x8336;\u0026#x7897; (@iamchawan) | Twitter\u003c/a\u003e, \u003ci class=\"blogicon-entry\"\u003e\u003c/i\u003e \u003ca href=\"https://k9bookshelf.com/blogs/development\"\u003eBlog\u003c/a\u003e\u003c/p\u003e\n\n\u003ch4\u003e\u003ca href=\"https://github.com/namikingsoft\"\u003e@namikingsoft\u003c/a\u003eさん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\n常に技術検証してよりよい解を追求するというエンジニアとしての本質はもちろん、「タイムキーパーアプリ」や「マンネリ化しないモブプロ担当割当の仕組み化」など、チーム活動に関する課題への解も即座に実現し続ける姿は他のエンジニアのあるべき姿を体現していると思います。\u003c/p\u003e\n\n\u003ch3\u003e🏆「Share All; 己の知見、試行、失敗、遍く共有すべし」受賞者\u003c/h3\u003e\n\n\u003ch4\u003e\u003ca href=\"https://github.com/masutaka\"\u003e@masutaka\u003c/a\u003e さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\n自身の知見や持っている情報を分かりやすく社内に共有するだけでなく、「今ボールを持っているのは誰か」といった次のアクションに繋がる部分についても責任を持って管理している姿が印象的でした。\n加えて、自分のみならず会社全体での情報共有を促進するには何をすればいいか、といった観点からもTipsを発信し続けています。まさに、本当の意味での「情報の共有」という観点で全社的なアクションを続けていただいています。\u003cbr\u003e\n\u003ci class=\"blogicon-twitter\"\u003e\u003c/i\u003e \u003ca href=\"https://twitter.com/masutaka\"\u003eTakashi Masuda (@masutaka) | Twitter\u003c/a\u003e, \u003ci class=\"blogicon-entry\"\u003e\u003c/i\u003e \u003ca href=\"https://masutaka.net/\"\u003eBlog\u003c/a\u003e\u003c/p\u003e\n\n\u003ch4\u003e\u003ca href=\"https://github.com/kogai\"\u003e@kogai\u003c/a\u003e さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\n自身の職能に閉じない、幅広い情報を集めているのに加え、新規事業の検証を通して学んだ知識・技術を様々な機会を通してエンジニア全体に広く共有してもらっています。また、全社的にShopifyにフォーカスしている現状で、先行して蓄積したShopifyに関する知見を全社的に展開することで、後進のキャッチアップに大きく資している点は、社内でも大きなインパクトを与えています。\u003cbr\u003e\n\u003ci class=\"blogicon-twitter\"\u003e\u003c/i\u003e \u003ca href=\"https://twitter.com/iamchawan\"\u003e\u0026#x8336;\u0026#x7897; (@iamchawan) | Twitter\u003c/a\u003e, \u003ci class=\"blogicon-entry\"\u003e\u003c/i\u003e \u003ca href=\"https://k9bookshelf.com/blogs/development\"\u003eBlog\u003c/a\u003e\u003c/p\u003e\n\n\u003ch3\u003e🏆「Just Do It; 全力でやりきるべし」受賞者\u003c/h3\u003e\n\n\u003ch4\u003e\u003ca href=\"https://github.com/ryz310\"\u003e@ryz310\u003c/a\u003eさん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\nチーム内でこれまではどうしても不足していた決定力・実行力という点で、自身が強力に牽引することで改善させるために努力しています。そのために様々な施策を高速で試し、実行力のあるチームを作り上げるために試行錯誤していた姿は、自分だけでなくチーム全体の実行力の向上を目指す、チームファーストな姿だと思います。\u003cbr\u003e\n\u003ci class=\"blogicon-twitter\"\u003e\u003c/i\u003e \u003ca href=\"https://twitter.com/ryosuke_sato\"\u003e\u0026#x30B5;\u0026#x30C8;\u0026#x30A6;\u0026#x30EA;\u0026#x30E7;\u0026#x30A6;\u0026#x30B9;\u0026#x30B1; (@ryosuke_sato) | Twitter\u003c/a\u003e, \u003ci class=\"blogicon-entry\"\u003e\u003c/i\u003e \u003ca href=\"https://ryz310.hateblo.jp/\"\u003eBlog\u003c/a\u003e\u003c/p\u003e\n\n\u003ch4\u003e\u003ca href=\"https://github.com/koshigoe\"\u003e@koshigoe\u003c/a\u003e さん\u003c/h4\u003e\n\n\u003cp\u003e表彰コメント：\u003cbr /\u003e\n最初に合意したリリース日を常に念頭に置き、都度状況の確認・共有をしつつも、何があってもリリース日は絶対に守る姿は、基本とはいえなかなか継続できることではありません。また、dfplus.io 内のみならず社内の別プロジェクトも並行して検証をされており、実行力という意味では社内でもトップクラスです。\u003c/p\u003e\n\n\u003ch2\u003e周囲の賞賛・承認を共有するよい機会に\u003c/h2\u003e\n\n\u003cp\u003e以上、延べ10名の受賞者でした。なんと3つの項目で表彰されている人もいましたね！\u003c/p\u003e\n\n\u003cp\u003e表彰コメントは、開発メンバー同士の投票時に自由記述できるコメントがもとになっているので、周囲からの賞賛・承認の声を全社で共有できるよい機会となっています。なかなか近くで仕事ぶりを見ることがないビジネスサイドのメンバーにとっても開発メンバーの活躍を知ることができ、よい刺激をもらうことができました。このような形で開発チームメンバーの活躍や勉強会の様子なども発信していきたいと思います。\u003c/p\u003e\n\n\u003cp\u003e気づけば2020年もあと3日ほど。今年も1年間ありがとうございました。\u003c/p\u003e\n\n\u003cp\u003eそして受賞者のみなさん、おめでとうございました！\u003c/p\u003e\n","contentSnippet":"こんにちは。人事の今岡と申します。Developer Blog への投稿は初めてで若干緊張しています。先日行われたオンライン忘年会にて、半期に一度の「Engineer’s Principles Award 2020 Winter」の受賞者が発表されました。アワードが始まって3回目となり、そろそろ社外にも発信していきたいなと思いまして、せっかくなのでこちらのブログでアワードを受賞したメンバーと表彰内容をご紹介しようと思います。Engineer’s Principles Award とはEngineer’s Principles とは、フィードフォースの開発メンバー向けに現場が主体となって設定した、5つの行動指針です。半期に一度、開発メンバー同士で投票を行い、行動指針の項目ごとに最も体現しているメンバーが選ばれ、開発本部長から表彰者が発表されます。ちなみに、下記の5項目はつい先日アップデートされたばかりで、今年導入されたフルリモートワークという働き方も考慮した内容になりました。この話はまた別の機会に改めて発信しようと思います。Stay Humble; 常に謙虚であるべしBe Positive \u0026 Proactive; 常に肯定的・主体的であるべしBe Prepared; 常に来るべき機会に備えるべしShare All; 己の知見、試行、失敗、遍く共有すべしJust Do It; 全力でやりきるべし受賞者紹介※表彰コメントは本来社内向けのものであるため一部変更させていただいています。人によって各種アカウントを載せています。🏆「Stay Humble; 常に謙虚であるべし」受賞者@tmd45 さん表彰コメント：＠azmin さん表彰コメント：🏆「Be Positive \u0026 Proactive; 常に肯定的・主体的であるべし」受賞者@kogai さん表彰コメント： 茶碗 (@iamchawan) | Twitter,  Blog@sukechannnn さん表彰コメント： sukechannnn (@sukechannnn) | Twitter🏆「Be Prepared; 常に来るべき機会に備えるべし」受賞者@kogai さん表彰コメント： 茶碗 (@iamchawan) | Twitter,  Blog@namikingsoftさん表彰コメント：🏆「Share All; 己の知見、試行、失敗、遍く共有すべし」受賞者@masutaka さん表彰コメント： Takashi Masuda (@masutaka) | Twitter,  Blog@kogai さん表彰コメント： 茶碗 (@iamchawan) | Twitter,  Blog🏆「Just Do It; 全力でやりきるべし」受賞者@ryz310さん表彰コメント： サトウリョウスケ (@ryosuke_sato) | Twitter,  Blog@koshigoe さん表彰コメント：周囲の賞賛・承認を共有するよい機会に以上、延べ10名の受賞者でした。なんと3つの項目で表彰されている人もいましたね！表彰コメントは、開発メンバー同士の投票時に自由記述できるコメントがもとになっているので、周囲からの賞賛・承認の声を全社で共有できるよい機会となっています。なかなか近くで仕事ぶりを見ることがないビジネスサイドのメンバーにとっても開発メンバーの活躍を知ることができ、よい刺激をもらうことができました。このような形で開発チームメンバーの活躍や勉強会の様子なども発信していきたいと思います。気づけば2020年もあと3日ほど。今年も1年間ありがとうございました。そして受賞者のみなさん、おめでとうございました！","link":"https://developer.feedforce.jp/entry/2020/12/28/131042","isoDate":"2020-12-28T04:10:42.000Z","dateMiliSeconds":1609128642000,"imageUrl":"https://cdn.user.blog.st-hatena.com/default_entry_og_image/4268819/1588226000876991","authorName":"feedforce"},{"title":"半年モブプロしたらチームが大きく成長した話","content":"\u003cp\u003eこんにちは！フィードフォースで \u003ca href=\"https://ecbooster.jp/\"\u003eEC Booster\u003c/a\u003e というプロダクトを作っている \u003ca href=\"https://twitter.com/sukechannnn\"\u003e@sukechannnn\u003c/a\u003e です。\u003c/p\u003e\n\n\u003cp\u003eこの記事は \u003ca href=\"https://adventar.org/calendars/5560\"\u003eFeedforce Advent Calendar 2020\u003c/a\u003e の 11日目の記事です。\u003cbr /\u003e\n昨日は kogai さんの \u003ca href=\"https://k9bookshelf.com/blogs/development/how-and-why-running-bookstore\"\u003e趣味の本屋を始めました\u003c/a\u003e でした。実際に自分でECサイトを立ち上げて運営するのって、言うは易く行うは難しですよね。すごいです。\u003c/p\u003e\n\n\u003chr /\u003e\n\n\u003cp\u003eさて、内容に入っていきます。\u003c/p\u003e\n\n\u003ch2\u003eEC Booster チームではメイン開発をモブプログラミングで行っています！\u003c/h2\u003e\n\n\u003cp\u003eEC Booster はEC事業者様の集客を支援するサービスで、主に Google ショッピング広告を扱っています。また、\u003ca href=\"https://ecbooster.jp/news/free-plan-20201109\"\u003e今年１１月にフリープランをリリース\u003c/a\u003eし、より多くのEC担当者様をご支援できるよう機能開発を進めています。\u003c/p\u003e\n\n\u003cp\u003eアプリケーションの構成は、フロントエンドが React + Flow (TypeScript 移行中)、サーバーサイドが Ruby on Rails で、API が GraphQL です。また、データフィード広告を扱う関係上、Ruby で書かれたバッチ処理がたくさん動いています。広告領域はなかなかに複雑で、深いドメイン知識が必要です。\u003c/p\u003e\n\n\u003cp\u003eそんなプロダクトですが、現在はモブプログラミング（以下モブプロ）で全員がフロントエンド/バックエンドの垣根なく開発をしています。モブプロを導入した当初は試行錯誤の連続でしたが、最近はとても良い感じです。そして、気づいたらチームそのものが成長してきた...と感じています。\u003c/p\u003e\n\n\u003cp\u003eこの記事では、僕ら開発チームがどのようにモブプロの課題を乗り越え、モブプロの利点を生かして開発できるようになったのかを共有できればと思います。少し長いですが、お付き合いください 🙏\u003c/p\u003e\n\n\u003ch2\u003eRSGT でモブプロを知る\u003c/h2\u003e\n\n\u003cp\u003e僕がモブプログラミングという概念を知ったきっかけは \u003ca href=\"https://2018.scrumgatheringtokyo.org/\"\u003eRegional Scrum Gathering Tokyo 2018 \u003c/a\u003e というスクラム開発を題材にしたカンファレンスでした。\u003c/p\u003e\n\n\u003cp\u003eモブプロは、ドライバーというコードを書く人が１人、それ以外のナビゲーターと呼ばれる複数の人で行います。ナビゲーターはドライバーに対して、実装する内容を指示します。ドライバーは支持された内容をコードに書いていく、という感じです。ドライバーは適宜交代していきます。\u003c/p\u003e\n\n\u003cp\u003eRSGT で発表を聞いた時は、話している内容には説得力があり楽しそうだったものの、「それぞれ個人で開発した方が集中できて進捗も出るんじゃないかなぁ」と半信半疑でした。まさか自分がモブプロをやることになるとは、この時は思ってもいませんでした。\u003c/p\u003e\n\n\u003ch2\u003e時は流れ〜開発チームのメンバーが入れ替わることに\u003c/h2\u003e\n\n\u003cp\u003eそれから２年くらい経ち、今年の４月に EC Booster 開発チームのメンバーが入れ替わることになりました。デザイナー含め８人いた開発メンバーは僕含め４人になり、そのうち２人（当時フロントエンド担当）は入社して日が浅いという状況でした。その時リーダー的な役割を果たせと谷垣さん（\u003ca href=\"https://media.feedforce.jp/n/n7f4f77f24733\"\u003eこの記事\u003c/a\u003eの右側の髪の長い人）に言い渡された僕は、どうしようかなと考え始めました。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eプロダクトの複雑なドメインをお二人にもしっかりキャッチアップして欲しい\n\n\u003cul\u003e\n\u003cli\u003e広告運用やデータフィードなどのドメイン知識があった方が、主体的に開発できると思ったため\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eバッチ処理が多いアプリケーションなので、どういう処理をしているかを把握してもらった方がフロントエンドの開発をするにも役立ちそう\u003c/li\u003e\n\u003cli\u003eフロントエンドだけじゃなくてバックエンドも開発してもらいたいな（彼らも意欲的だった）\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eその時ちょうど、コロナで出社できない日常がスタートし、会社で直に話ができなくなってしまいました。\u003c/p\u003e\n\n\u003ch2\u003eそうだ、モブプロしよう！\u003c/h2\u003e\n\n\u003cp\u003eそこで思い出したのがモブプロです。以下のような理由から、オフィスで話ができないならずっとZoomを繋いでいればいいのでは？と思い、提案してみました。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e都度 zoom を繋ぐのだと、どうしても会話するハードルが上がってしまう\u003c/li\u003e\n\u003cli\u003eドメインの説明は、直接話せば５分で伝えられることが文字だと３０分かかる、みたいなことが多い\n\n\u003cul\u003e\n\u003cli\u003e相手が理解してそうか？をリアクションから読み取ることで、補足説明できる（文字だとそれが分からない）\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e以前にも少しモブプロを試していたが、リモートワークとの親和性が高そうだった\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003e上記を説明したら、開発メンバーのみんなも「せやな」と同意してくれたので、やってみることになりました。\u003c/p\u003e\n\n\u003ch2\u003eモブプロを始めたら情報の非対称性がなくなっていった\u003c/h2\u003e\n\n\u003ch4\u003e最初は小さな改修をしながらドメイン知識をキャッチアップ\u003c/h4\u003e\n\n\u003cp\u003e最初は大きな開発ではなく、小さな改修を繰り返しながらドメイン知識のキャッチアップを進めていきました。\u003c/p\u003e\n\n\u003cp\u003eドメイン知識が詰まってるのが主にバックエンド（というかバッチ処理）だったので、最初はバックエンドの改修から始めました。キャッチアップして欲しい人にドライバーをお願いし、ナビゲーターが解説しながらコードを書いてもらう感じです。やってみると、実際に手を動かしてもらいながら説明できたので、口頭で説明するよりも知識が染み込んで行く感覚がありました。日々の運用作業も皆に担当してもらい、よく発生するアラートや必要な対応を、裏側の事情も含めて理解してもらうのに役立てました。\u003c/p\u003e\n\n\u003cp\u003eただ、その時はバックエンド担当⇢フロントエンド担当に教える感じが続いてしまいました。\u003c/p\u003e\n\n\u003ch4\u003eアプリケーションの全部を全員で開発しよう！\u003c/h4\u003e\n\n\u003cp\u003eしばらくやってみて、フロントエンド担当にバックエンドをやってもらうなら、バックエンド担当もフロントエンドやらなあかんやろ、ということでバックエンドとフロントエンドの垣根をなくしました。それにより、フロントエンド担当⇢バックエンド担当の説明も生まれ、お互いの話すバランスがちょうど良い感じになり、双方向のコミュニケーションになりました。\u003c/p\u003e\n\n\u003cp\u003eその結果、ドメイン知識だけでなく、技術的にも情報の非対称性が減っていきました。今では技術的な課題をフロントエンド/バックエンド横断で全員が把握してるので、議論がとてもスムーズです。\u003c/p\u003e\n\n\u003ch2\u003eメインの開発もモブプロでやってみることに\u003c/h2\u003e\n\n\u003cp\u003e最初はドメイン知識のキャッチアップがある程度できたら非同期な開発に戻ろうと思っていましたが、モブプロが予想以上に良かったので新機能のメイン開発も引き続きモブプロでやってみることにしました。その時は、以下の２つを利点と感じていました。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\"何をどう作るか\" という議論がノータイムでできることの価値が思ったより高かった（コンテキストの共有がしやすい）\u003c/li\u003e\n\u003cli\u003eプランニングでは話しきれない、実際のコードを元にした議論がしやすかった\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eその当時に実装しようとしていたのが冒頭で紹介した「フリープラン」という完全に新規の開発だったので、メンバー間の認識を合わせることが特に重要でした。それに加え、モブプロでも開発スピードが思っていたより落ちなかったのも導入を後押ししてくれました。\u003c/p\u003e\n\n\u003ch2\u003eモブプロは良いことずくめ！に感じたが...\u003c/h2\u003e\n\n\u003cp\u003eこうしてモブプロでのメイン開発がスタートしました。めっちゃええやん！と思って始めたモブプロでしたが、やっていく中でいくつか課題も見えてきました。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eめちゃくちゃ疲れる（最初は「これは本当に毎日続けられるのか？」と途方に暮れるレベルで疲れた）\u003c/li\u003e\n\u003cli\u003eずっと Zoom 繋いでるけど何を話そう...\u003c/li\u003e\n\u003cli\u003e開発の進み具合が良くない\u003c/li\u003e\n\u003cli\u003e議論を進める人に偏りが出る\u003c/li\u003e\n\u003cli\u003e個人で集中して調査したり開発したりする時間も必要では？\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003e特に課題だったのは、思っていたより \"疲れる\" ということでした。そのせいで一時期は開発スピードが落ち、朝起きるのがつらい状態になってしまいました...。このままではアカン！ということで、これらの課題を解決するために、色々な工夫をしてきました。\u003c/p\u003e\n\n\u003ch4\u003eモブプロを上手くやるための工夫\u003c/h4\u003e\n\n\u003cul\u003e\n\u003cli\u003e① 休憩する\u003c/li\u003e\n\u003cli\u003e② 雑談する\u003c/li\u003e\n\u003cli\u003e③ なるべく毎日同じ時間モブプロする\u003c/li\u003e\n\u003cli\u003e④ その日やることを朝会で話し合う\u003c/li\u003e\n\u003cli\u003e⑤ 個人タスクを用意する\u003c/li\u003e\n\u003cli\u003e⑥ プランニングと開発キックオフ\u003c/li\u003e\n\u003cli\u003e⑦ 自分から話さない人にも明示的に意見を聞く\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eこれらの工夫を繰り返した結果、モブプロが上手くできるようになっただけでなく、チームそのものが成長していきました。\u003c/p\u003e\n\n\u003cp\u003eそれぞれ詳しく説明していきます。\u003c/p\u003e\n\n\u003ch2\u003e工夫① - 休憩する\u003c/h2\u003e\n\n\u003cp\u003e休憩するって当たり前のことなんですが、集中してしまうと忘れがちになるし、モブプロをやり始めた最初はみんな探り探りなので「休憩しましょう」とか気軽に言いにくい部分もあったように思います。\u003c/p\u003e\n\n\u003cp\u003eそのため、まずは休憩する習慣を付けるために、あえて Zoom の無料プランを使って \"40分で強制的に休憩\" するようにしました。ポモドーロテクニックとか色々ありますが、これが一番確実でした。本当に強制的に切れるので、タイミングによっては笑いが起きて、和やかな雰囲気が副次的に醸成されていきました。\u003c/p\u003e\n\n\u003cp\u003e最近は zoom の有料プランを使ってますが、\"適度に休憩を取る\" という習慣が根付いているので、適当なタイミングで誰かが休憩入れてくれます。休憩が上手になったので、今は明確なルールは定めてません。ガッと60分やりたい時もあれば、30分で区切りが良い時もありますからね。それでも以前より格段に疲れなくなりました。\u003c/p\u003e\n\n\u003ch2\u003e工夫② - 雑談する\u003c/h2\u003e\n\n\u003cp\u003e一見すると業務に関係のないような雑談もして良いよ！という雰囲気作りに務めました。特別 \"雑談の時間\" を作っているわけではなく、突発的な雑談を盛り上げるイメージです。これには、発言のハードルを徹底的に下げて、ちょっとした懸念やアイディアをポンと出せるようなチームにしたいという思いがありました。また、単に \"話す\" ことで疲れないようにしたいなとも思っていました。\u003c/p\u003e\n\n\u003cp\u003e結果、チームメンバーがお互いのことを知るきっかけになり、それぞれの考え方や得手不得手を把握した上で議論ができるようになってきました。時には、エンジニアリングと全く関係ない雑談から実装のアイディアが浮かんだりして面白いです。\u003c/p\u003e\n\n\u003ch4\u003e開発メンバーが打ち解けている様子\u003c/h4\u003e\n\n\u003cp\u003eエビチリ🍤 をきっかけに、モブプロが解散するとエビのリアクションが飛び交うようになりました。良いですね。\n\u003cfigure class=\"figure-image figure-image-fotolife\" title=\"エビチリ\"\u003e\u003cspan itemscope itemtype=\"http://schema.org/Photograph\"\u003e\u003cimg src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sukechannnn/20201210/20201210211734.jpg\" alt=\"f:id:sukechannnn:20201210211734j:plain\" title=\"\" class=\"hatena-fotolife\" itemprop=\"image\"\u003e\u003c/span\u003e\u003cfigcaption\u003eエビチリ\u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e\n\n\u003ch2\u003e工夫③ - なるべく毎日同じ時間モブプロする\u003c/h2\u003e\n\n\u003cp\u003e以前は、金曜日にまとめてプランニングを行っていたので、モブプロできるのが週４日でした。１日の中で５時間モブプロをやる日と、全くやらない日が混在してる状態です。集中して作業する時間をまとめて確保するためにそうしていたのですが、モブプロは長時間やるとめちゃくちゃ疲れるんですよね。逆に言うと、クリアな脳なら短時間でもめちゃくちゃ進捗します。\u003c/p\u003e\n\n\u003cp\u003eということで、なるべく同じ時間で毎日モブプロした方が良いことが分かったので、プランニングを他の日に移動して、最低２時間はモブプロの時間を確保するようにしました。今では無理なく週の最後まで開発をすることができています。\u003c/p\u003e\n\n\u003cp\u003eまた、上記の工夫により毎日の進捗が安定するようになったので、プロジェクトマネージメントの難易度がぐっと下がりました。この半年間、ほぼ事前の見積もり通りに開発が進んでいるのは自分でもびっくりです（ガントチャートで記録してます）。\u003c/p\u003e\n\n\u003ch2\u003e余談 - モブプロではレビューが要らない\u003c/h2\u003e\n\n\u003cp\u003eモブプロを始めてから、以前よりも見積もりが正確になっていることに気づきました。これには \"モブプロではレビューがほとんど不要\" という特性も関係しているように思います。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e非同期な開発だと「開発⇢レビュー⇢ (修正⇢レビュー) * n回⇢リリース」だったので、\u003ccode\u003e(修正⇢レビュー) * n回\u003c/code\u003e の部分も見積もる必要があったが難しかった\u003c/li\u003e\n\u003cli\u003eモブプロだと「開発⇢リリース」と単純なので、正確に見積もりやすい\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eやってみて分かったことですが、モブプロだと本当にレビューが最低限で済みます。実装の時点で複数人の目が入ってますからね。今のところ大きなバグもありませんし、これに関しては \"コストが下がった\" と言って良いでしょう。\u003c/p\u003e\n\n\u003ch2\u003e工夫④ - その日やることを朝会で話し合う\u003c/h2\u003e\n\n\u003cp\u003e朝会は元々、開発メンバーがそれぞれ「昨日やったこと/今日やること」を報告するという、アジャイル開発ではオーソドックスなやり方でした。非同期な開発では、それぞれやってることが違うので報告し合う必要があったのですが、具体的な内容までは分からないので朝会で何か議論が発生することは稀でした。\u003c/p\u003e\n\n\u003cp\u003eモブプロでは、昨日やったことは全員が知っているので、個々人が別々に報告する必要がありません。とはいえ昨日やったことの確認はしたいので、日替わりで１人がやったことを振り返り、その後に今日やることを話し合う感じにしてます。\u003c/p\u003e\n\n\u003cp\u003eこの、\"今日やることを話し合う\" 時間がとても良くて、昨日の実装の不安な点を話し合ったり（寝て起きると人は閃く）、これから実装するアプリケーションの設計を話し合ったりと、お互いの認識を同期する場になっています。毎日ちょっとしたプランニングをしてる感じですね。\u003c/p\u003e\n\n\u003cp\u003e特に話すことがない日でも、すぐに区切るのではなく積極的に雑談するようにしてます。雑談することでそれぞれの体調や気持ち的な浮き沈みもなんとなく分かり、今日のモブプロの進め方とかどこまでやるかを確認できます。あと、単純に雑談は楽しいので、その日１日頑張ろう！という気持ちになります。\u003c/p\u003e\n\n\u003ch2\u003e工夫⑤ - 個人タスクを用意する\u003c/h2\u003e\n\n\u003cp\u003eモブプロが中心ではあるものの、個人で開発した方が効率的なことも多々ありますよね。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e新しい技術の調査\u003c/li\u003e\n\u003cli\u003eリファクタリング\u003c/li\u003e\n\u003cli\u003eある程度形になった後の細かい機能/テストの追加\u003c/li\u003e\n\u003cli\u003eライブラリーのアップデート\u003c/li\u003e\n\u003cli\u003eetc...\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003cp\u003eこれらは明示的に \"個人タスク\" と切り出して、個人をアサインして進めるようにしています。当たり前ですが、個人タスクをやる時間は設けていて、良い息抜きになってるみたいです。\u003c/p\u003e\n\n\u003cp\u003e何を個人タスクにするかは、モブプロの中で話し合ってサッと決まってしまうことが多いです。個人タスクをやってて詰まってしまった時にはいつでも聞いて良いし、場合によってはモブプロに戻ることもあります。\u003c/p\u003e\n\n\u003cp\u003eまた、実装していて「気になるから調べてたらできちゃった」みたいな事もエンジニアならあると思うんですが、そういう時は共有してもらった上でマージしちゃいます。ガチガチにモブプロじゃないとダメ！というルールにしているわけではなく、きちんとコンテキストが共有できているなら良いのです。\u003c/p\u003e\n\n\u003ch2\u003e工夫⑥ - プランニングと開発キックオフ\u003c/h2\u003e\n\n\u003cp\u003e以前は週次のプランニングは重たい行事でした。来週やることがよく分からないまま、各自で実装をしていたからです。プランニングでしっかり決めないと...というプレッシャーが、チーム全体の空気を重くしていたように思います。\u003c/p\u003e\n\n\u003cp\u003e今では、朝会 + モブプロにより毎日やることを確認しているので、開発タスクについて週次のプランニングで話し合うことがかなり減りました。今はビジネスサイドへの進捗状況の共有と、メインタスク以外に発生する細かいタスクについて相談することが主になっています。\u003c/p\u003e\n\n\u003cp\u003e代わり...というわけではないのですが、月曜の朝に \"プチプランニング\" と称して、その週に何をどこまで開発するか確認する場を設けています。その後にチーム全体のミーティングがあるので、プチプランニングで話したことを共有し、チーム全体での認識を合わせるようにしています。\u003c/p\u003e\n\n\u003cp\u003eそして、大きな開発を始める前には \"開発キックオフ\" を開催するようになりました。UI/UXデザインとアプリケーション設計の大まかな叩き台を僕が用意しておき、それを元に具体的な実装について話し合うミーティングです。これは１日で終わることもあるし、数日かかることもあります。今開発している機能の開発キックオフは数日かかりましたが、とても良い感じのアーキテクチャになりました。具体的な設計まで行えたので見通しが良く、楽しく開発を進めることができています。\u003c/p\u003e\n\n\u003ch2\u003e工夫⑦ - 自分から話さない人にも明示的に意見を聞く\u003c/h2\u003e\n\n\u003cp\u003e最後に、これは個人的に意識していたことですが、自分から話さない人にも積極的に意見を聞くようにしてました。\u003c/p\u003e\n\n\u003cp\u003eモブプロを始めた当初は議論を進める人に偏りが出やすかったのですが、改めて意見を聞いてみると、頭の中で別の意見を持ってることも多かったのです。\"話さない == 意見がない\" ではないんですよね。\u003c/p\u003e\n\n\u003cp\u003eなので、雑談を通じて話しやすい雰囲気を作るのとセットで、積極的に全員の意見を明示的に聞くようにしていました。その結果、見落としていた懸念点に気づけたり、実は不要な実装だったことに気づけたりして、実利を得ることができました。\u003c/p\u003e\n\n\u003cp\u003e最近は、特に僕が聞かなくてもみんな意見を言ってくれますし、大丈夫なときは「大丈夫です」って明示的に言ってくれます（リアクションだいじ）。意見を求める側も、気になる時は全員の意見を明示的に聞く流れができてきました。すごく良いことだなと思っています。\u003c/p\u003e\n\n\u003ch2\u003eモブプロを上手くやるための工夫を繰り返していたら開発チームそのものが成長した\u003c/h2\u003e\n\n\u003cp\u003eこんな感じで、モブプロを上手くやるための工夫を繰り返してしたら、チームそのものが良い感じになり、大きく成長することができました。\u003c/p\u003e\n\n\u003cp\u003eモブプロの何が良かったのでしょうか。僕は、チームメンバー全員が \"自分が考えていること/実際にやったこと\" を共有することの大切さを理解し、積極的に共有できる状態になったこと、なのかなと思っています。\u003c/p\u003e\n\n\u003cp\u003e以前は喋る前に緊張してめちゃくちゃ準備してたメンバーが、今は頭の中にあるものをそのまま話してくれるようになりました。特に取り繕うこともなく、自然とです。\u003c/p\u003e\n\n\u003cp\u003e最近では、今後のやりたいことや構想をチームメンバーと話すと、それぞれで良いやり方や設計を考えてモブプロに持ち寄ってくれます。モブプロで各自が考えたことを元に話し合う時間がとても楽しくて、結果としてめっちゃ良いアーキテクチャが生まれています。\u003c/p\u003e\n\n\u003cp\u003e今ならモブプロでなくても、非同期で開発を進めることもできると思います。実際に、開発する内容によっては、メイン開発であっても非同期で実装することもあります。それでも今、メイン開発をモブプロで進めているのは、このままモブプロで行くか？を改めて全員で確認し、その方が良いと皆が明示的に選んでいるからです。\u003c/p\u003e\n\n\u003cp\u003e全員がコンテキストを共有した状態で考え工夫することで、チームとして成長できたのかなと思っています。ここまで大変なこともありましたが、諦めずに続けてきて良かった！\u003c/p\u003e\n\n\u003cp\u003e一緒に工夫しながら開発してくれているメンバーには感謝しかありません。これからもよろしくお願いします！！！\u003c/p\u003e\n\n\u003chr /\u003e\n\n\u003cp\u003e明日は daido1976 の「好きな動画の話」です！お楽しみに！（ちなみに僕が好きなユーチューバーは \u003ca href=\"https://twitter.com/kneko__\"\u003eかねこ\u003c/a\u003e さんです。）\u003c/p\u003e\n","contentSnippet":"こんにちは！フィードフォースで EC Booster というプロダクトを作っている @sukechannnn です。この記事は Feedforce Advent Calendar 2020 の 11日目の記事です。趣味の本屋を始めました でした。実際に自分でECサイトを立ち上げて運営するのって、言うは易く行うは難しですよね。すごいです。さて、内容に入っていきます。EC Booster チームではメイン開発をモブプログラミングで行っています！EC Booster はEC事業者様の集客を支援するサービスで、主に Google ショッピング広告を扱っています。また、今年１１月にフリープランをリリースし、より多くのEC担当者様をご支援できるよう機能開発を進めています。アプリケーションの構成は、フロントエンドが React + Flow (TypeScript 移行中)、サーバーサイドが Ruby on Rails で、API が GraphQL です。また、データフィード広告を扱う関係上、Ruby で書かれたバッチ処理がたくさん動いています。広告領域はなかなかに複雑で、深いドメイン知識が必要です。そんなプロダクトですが、現在はモブプログラミング（以下モブプロ）で全員がフロントエンド/バックエンドの垣根なく開発をしています。モブプロを導入した当初は試行錯誤の連続でしたが、最近はとても良い感じです。そして、気づいたらチームそのものが成長してきた...と感じています。この記事では、僕ら開発チームがどのようにモブプロの課題を乗り越え、モブプロの利点を生かして開発できるようになったのかを共有できればと思います。少し長いですが、お付き合いください 🙏RSGT でモブプロを知る僕がモブプログラミングという概念を知ったきっかけは Regional Scrum Gathering Tokyo 2018  というスクラム開発を題材にしたカンファレンスでした。モブプロは、ドライバーというコードを書く人が１人、それ以外のナビゲーターと呼ばれる複数の人で行います。ナビゲーターはドライバーに対して、実装する内容を指示します。ドライバーは支持された内容をコードに書いていく、という感じです。ドライバーは適宜交代していきます。RSGT で発表を聞いた時は、話している内容には説得力があり楽しそうだったものの、「それぞれ個人で開発した方が集中できて進捗も出るんじゃないかなぁ」と半信半疑でした。まさか自分がモブプロをやることになるとは、この時は思ってもいませんでした。時は流れ〜開発チームのメンバーが入れ替わることにそれから２年くらい経ち、今年の４月に EC Booster 開発チームのメンバーが入れ替わることになりました。デザイナー含め８人いた開発メンバーは僕含め４人になり、そのうち２人（当時フロントエンド担当）は入社して日が浅いという状況でした。その時リーダー的な役割を果たせと谷垣さん（この記事の右側の髪の長い人）に言い渡された僕は、どうしようかなと考え始めました。プロダクトの複雑なドメインをお二人にもしっかりキャッチアップして欲しい広告運用やデータフィードなどのドメイン知識があった方が、主体的に開発できると思ったためバッチ処理が多いアプリケーションなので、どういう処理をしているかを把握してもらった方がフロントエンドの開発をするにも役立ちそうフロントエンドだけじゃなくてバックエンドも開発してもらいたいな（彼らも意欲的だった）その時ちょうど、コロナで出社できない日常がスタートし、会社で直に話ができなくなってしまいました。そうだ、モブプロしよう！そこで思い出したのがモブプロです。以下のような理由から、オフィスで話ができないならずっとZoomを繋いでいればいいのでは？と思い、提案してみました。都度 zoom を繋ぐのだと、どうしても会話するハードルが上がってしまうドメインの説明は、直接話せば５分で伝えられることが文字だと３０分かかる、みたいなことが多い相手が理解してそうか？をリアクションから読み取ることで、補足説明できる（文字だとそれが分からない）以前にも少しモブプロを試していたが、リモートワークとの親和性が高そうだった上記を説明したら、開発メンバーのみんなも「せやな」と同意してくれたので、やってみることになりました。モブプロを始めたら情報の非対称性がなくなっていった最初は小さな改修をしながらドメイン知識をキャッチアップ最初は大きな開発ではなく、小さな改修を繰り返しながらドメイン知識のキャッチアップを進めていきました。ドメイン知識が詰まってるのが主にバックエンド（というかバッチ処理）だったので、最初はバックエンドの改修から始めました。キャッチアップして欲しい人にドライバーをお願いし、ナビゲーターが解説しながらコードを書いてもらう感じです。やってみると、実際に手を動かしてもらいながら説明できたので、口頭で説明するよりも知識が染み込んで行く感覚がありました。日々の運用作業も皆に担当してもらい、よく発生するアラートや必要な対応を、裏側の事情も含めて理解してもらうのに役立てました。ただ、その時はバックエンド担当⇢フロントエンド担当に教える感じが続いてしまいました。アプリケーションの全部を全員で開発しよう！しばらくやってみて、フロントエンド担当にバックエンドをやってもらうなら、バックエンド担当もフロントエンドやらなあかんやろ、ということでバックエンドとフロントエンドの垣根をなくしました。それにより、フロントエンド担当⇢バックエンド担当の説明も生まれ、お互いの話すバランスがちょうど良い感じになり、双方向のコミュニケーションになりました。その結果、ドメイン知識だけでなく、技術的にも情報の非対称性が減っていきました。今では技術的な課題をフロントエンド/バックエンド横断で全員が把握してるので、議論がとてもスムーズです。メインの開発もモブプロでやってみることに最初はドメイン知識のキャッチアップがある程度できたら非同期な開発に戻ろうと思っていましたが、モブプロが予想以上に良かったので新機能のメイン開発も引き続きモブプロでやってみることにしました。その時は、以下の２つを利点と感じていました。\"何をどう作るか\" という議論がノータイムでできることの価値が思ったより高かった（コンテキストの共有がしやすい）プランニングでは話しきれない、実際のコードを元にした議論がしやすかったその当時に実装しようとしていたのが冒頭で紹介した「フリープラン」という完全に新規の開発だったので、メンバー間の認識を合わせることが特に重要でした。それに加え、モブプロでも開発スピードが思っていたより落ちなかったのも導入を後押ししてくれました。モブプロは良いことずくめ！に感じたが...こうしてモブプロでのメイン開発がスタートしました。めっちゃええやん！と思って始めたモブプロでしたが、やっていく中でいくつか課題も見えてきました。めちゃくちゃ疲れる（最初は「これは本当に毎日続けられるのか？」と途方に暮れるレベルで疲れた）ずっと Zoom 繋いでるけど何を話そう...開発の進み具合が良くない議論を進める人に偏りが出る個人で集中して調査したり開発したりする時間も必要では？特に課題だったのは、思っていたより \"疲れる\" ということでした。そのせいで一時期は開発スピードが落ち、朝起きるのがつらい状態になってしまいました...。このままではアカン！ということで、これらの課題を解決するために、色々な工夫をしてきました。モブプロを上手くやるための工夫① 休憩する② 雑談する③ なるべく毎日同じ時間モブプロする④ その日やることを朝会で話し合う⑤ 個人タスクを用意する⑥ プランニングと開発キックオフ⑦ 自分から話さない人にも明示的に意見を聞くこれらの工夫を繰り返した結果、モブプロが上手くできるようになっただけでなく、チームそのものが成長していきました。それぞれ詳しく説明していきます。工夫① - 休憩する休憩するって当たり前のことなんですが、集中してしまうと忘れがちになるし、モブプロをやり始めた最初はみんな探り探りなので「休憩しましょう」とか気軽に言いにくい部分もあったように思います。そのため、まずは休憩する習慣を付けるために、あえて Zoom の無料プランを使って \"40分で強制的に休憩\" するようにしました。ポモドーロテクニックとか色々ありますが、これが一番確実でした。本当に強制的に切れるので、タイミングによっては笑いが起きて、和やかな雰囲気が副次的に醸成されていきました。最近は zoom の有料プランを使ってますが、\"適度に休憩を取る\" という習慣が根付いているので、適当なタイミングで誰かが休憩入れてくれます。休憩が上手になったので、今は明確なルールは定めてません。ガッと60分やりたい時もあれば、30分で区切りが良い時もありますからね。それでも以前より格段に疲れなくなりました。工夫② - 雑談する一見すると業務に関係のないような雑談もして良いよ！という雰囲気作りに務めました。特別 \"雑談の時間\" を作っているわけではなく、突発的な雑談を盛り上げるイメージです。これには、発言のハードルを徹底的に下げて、ちょっとした懸念やアイディアをポンと出せるようなチームにしたいという思いがありました。また、単に \"話す\" ことで疲れないようにしたいなとも思っていました。結果、チームメンバーがお互いのことを知るきっかけになり、それぞれの考え方や得手不得手を把握した上で議論ができるようになってきました。時には、エンジニアリングと全く関係ない雑談から実装のアイディアが浮かんだりして面白いです。開発メンバーが打ち解けている様子エビチリ🍤 をきっかけに、モブプロが解散するとエビのリアクションが飛び交うようになりました。良いですね。エビチリ工夫③ - なるべく毎日同じ時間モブプロする以前は、金曜日にまとめてプランニングを行っていたので、モブプロできるのが週４日でした。１日の中で５時間モブプロをやる日と、全くやらない日が混在してる状態です。集中して作業する時間をまとめて確保するためにそうしていたのですが、モブプロは長時間やるとめちゃくちゃ疲れるんですよね。逆に言うと、クリアな脳なら短時間でもめちゃくちゃ進捗します。ということで、なるべく同じ時間で毎日モブプロした方が良いことが分かったので、プランニングを他の日に移動して、最低２時間はモブプロの時間を確保するようにしました。今では無理なく週の最後まで開発をすることができています。また、上記の工夫により毎日の進捗が安定するようになったので、プロジェクトマネージメントの難易度がぐっと下がりました。この半年間、ほぼ事前の見積もり通りに開発が進んでいるのは自分でもびっくりです（ガントチャートで記録してます）。余談 - モブプロではレビューが要らないモブプロを始めてから、以前よりも見積もりが正確になっていることに気づきました。これには \"モブプロではレビューがほとんど不要\" という特性も関係しているように思います。非同期な開発だと「開発⇢レビュー⇢ (修正⇢レビュー) * n回⇢リリース」だったので、(修正⇢レビュー) * n回 の部分も見積もる必要があったが難しかったモブプロだと「開発⇢リリース」と単純なので、正確に見積もりやすいやってみて分かったことですが、モブプロだと本当にレビューが最低限で済みます。実装の時点で複数人の目が入ってますからね。今のところ大きなバグもありませんし、これに関しては \"コストが下がった\" と言って良いでしょう。工夫④ - その日やることを朝会で話し合う朝会は元々、開発メンバーがそれぞれ「昨日やったこと/今日やること」を報告するという、アジャイル開発ではオーソドックスなやり方でした。非同期な開発では、それぞれやってることが違うので報告し合う必要があったのですが、具体的な内容までは分からないので朝会で何か議論が発生することは稀でした。モブプロでは、昨日やったことは全員が知っているので、個々人が別々に報告する必要がありません。とはいえ昨日やったことの確認はしたいので、日替わりで１人がやったことを振り返り、その後に今日やることを話し合う感じにしてます。この、\"今日やることを話し合う\" 時間がとても良くて、昨日の実装の不安な点を話し合ったり（寝て起きると人は閃く）、これから実装するアプリケーションの設計を話し合ったりと、お互いの認識を同期する場になっています。毎日ちょっとしたプランニングをしてる感じですね。特に話すことがない日でも、すぐに区切るのではなく積極的に雑談するようにしてます。雑談することでそれぞれの体調や気持ち的な浮き沈みもなんとなく分かり、今日のモブプロの進め方とかどこまでやるかを確認できます。あと、単純に雑談は楽しいので、その日１日頑張ろう！という気持ちになります。工夫⑤ - 個人タスクを用意するモブプロが中心ではあるものの、個人で開発した方が効率的なことも多々ありますよね。新しい技術の調査リファクタリングある程度形になった後の細かい機能/テストの追加ライブラリーのアップデートetc...これらは明示的に \"個人タスク\" と切り出して、個人をアサインして進めるようにしています。当たり前ですが、個人タスクをやる時間は設けていて、良い息抜きになってるみたいです。何を個人タスクにするかは、モブプロの中で話し合ってサッと決まってしまうことが多いです。個人タスクをやってて詰まってしまった時にはいつでも聞いて良いし、場合によってはモブプロに戻ることもあります。また、実装していて「気になるから調べてたらできちゃった」みたいな事もエンジニアならあると思うんですが、そういう時は共有してもらった上でマージしちゃいます。ガチガチにモブプロじゃないとダメ！というルールにしているわけではなく、きちんとコンテキストが共有できているなら良いのです。工夫⑥ - プランニングと開発キックオフ以前は週次のプランニングは重たい行事でした。来週やることがよく分からないまま、各自で実装をしていたからです。プランニングでしっかり決めないと...というプレッシャーが、チーム全体の空気を重くしていたように思います。今では、朝会 + モブプロにより毎日やることを確認しているので、開発タスクについて週次のプランニングで話し合うことがかなり減りました。今はビジネスサイドへの進捗状況の共有と、メインタスク以外に発生する細かいタスクについて相談することが主になっています。代わり...というわけではないのですが、月曜の朝に \"プチプランニング\" と称して、その週に何をどこまで開発するか確認する場を設けています。その後にチーム全体のミーティングがあるので、プチプランニングで話したことを共有し、チーム全体での認識を合わせるようにしています。そして、大きな開発を始める前には \"開発キックオフ\" を開催するようになりました。UI/UXデザインとアプリケーション設計の大まかな叩き台を僕が用意しておき、それを元に具体的な実装について話し合うミーティングです。これは１日で終わることもあるし、数日かかることもあります。今開発している機能の開発キックオフは数日かかりましたが、とても良い感じのアーキテクチャになりました。具体的な設計まで行えたので見通しが良く、楽しく開発を進めることができています。工夫⑦ - 自分から話さない人にも明示的に意見を聞く最後に、これは個人的に意識していたことですが、自分から話さない人にも積極的に意見を聞くようにしてました。モブプロを始めた当初は議論を進める人に偏りが出やすかったのですが、改めて意見を聞いてみると、頭の中で別の意見を持ってることも多かったのです。\"話さない == 意見がない\" ではないんですよね。なので、雑談を通じて話しやすい雰囲気を作るのとセットで、積極的に全員の意見を明示的に聞くようにしていました。その結果、見落としていた懸念点に気づけたり、実は不要な実装だったことに気づけたりして、実利を得ることができました。最近は、特に僕が聞かなくてもみんな意見を言ってくれますし、大丈夫なときは「大丈夫です」って明示的に言ってくれます（リアクションだいじ）。意見を求める側も、気になる時は全員の意見を明示的に聞く流れができてきました。すごく良いことだなと思っています。モブプロを上手くやるための工夫を繰り返していたら開発チームそのものが成長したこんな感じで、モブプロを上手くやるための工夫を繰り返してしたら、チームそのものが良い感じになり、大きく成長することができました。モブプロの何が良かったのでしょうか。僕は、チームメンバー全員が \"自分が考えていること/実際にやったこと\" を共有することの大切さを理解し、積極的に共有できる状態になったこと、なのかなと思っています。以前は喋る前に緊張してめちゃくちゃ準備してたメンバーが、今は頭の中にあるものをそのまま話してくれるようになりました。特に取り繕うこともなく、自然とです。最近では、今後のやりたいことや構想をチームメンバーと話すと、それぞれで良いやり方や設計を考えてモブプロに持ち寄ってくれます。モブプロで各自が考えたことを元に話し合う時間がとても楽しくて、結果としてめっちゃ良いアーキテクチャが生まれています。今ならモブプロでなくても、非同期で開発を進めることもできると思います。実際に、開発する内容によっては、メイン開発であっても非同期で実装することもあります。それでも今、メイン開発をモブプロで進めているのは、このままモブプロで行くか？を改めて全員で確認し、その方が良いと皆が明示的に選んでいるからです。全員がコンテキストを共有した状態で考え工夫することで、チームとして成長できたのかなと思っています。ここまで大変なこともありましたが、諦めずに続けてきて良かった！一緒に工夫しながら開発してくれているメンバーには感謝しかありません。これからもよろしくお願いします！！！明日は daido1976 の「好きな動画の話」です！お楽しみに！（ちなみに僕が好きなユーチューバーは かねこ さんです。）","link":"https://developer.feedforce.jp/entry/2020/12/11/172338","isoDate":"2020-12-11T08:23:38.000Z","dateMiliSeconds":1607675018000,"imageUrl":"https://cdn-ak.f.st-hatena.com/images/fotolife/s/sukechannnn/20201210/20201210211734.jpg","authorName":"feedforce"}]},"__N_SSG":true},"page":"/members/[name]","query":{"name":"feedforce"},"buildId":"St5w_c2xNgKLANGQYvXWT","nextExport":false,"isFallback":false,"gsp":true,"head":[["meta",{"name":"viewport","content":"width=device-width"}],["meta",{"charSet":"utf-8"}],["link",{"rel":"icon shortcut","type":"image/png","href":"https://engineers.feedforce.jp/logo.png"}],["link",{"rel":"stylesheet","href":"https://fonts.googleapis.com/css2?family=Inter:wght@400;700\u0026display=swap"}],["title",{"children":"feedforce | Feedforce Engineers' Blogs"}],["meta",{"property":"og:title","content":"feedforce"}],["meta",{"property":"og:url","content":"https://engineers.feedforce.jp/members/feedforce"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"property":"og:site","content":"Feedforce Engineers' Blogs"}],["meta",{"property":"og:image","content":"https://engineers.feedforce.jp/og.png"}],["link",{"rel":"canonical","href":"https://engineers.feedforce.jp/members/feedforce"}],["link",{"rel":"alternate","type":"application/rss+xml","title":"Feedforce Engineers' Blogs","href":"https://engineers.feedforce.jp/rss.xml"}],["link",{"rel":"alternate","type":"application/atom+xml","title":"Feedforce Engineers' Blogs","href":"https://engineers.feedforce.jp/atom.xml"}]]}</script><script nomodule="" src="/_next/static/chunks/polyfills-fa276ba060a4a8ac7eef.js"></script><script src="/_next/static/chunks/main-8a83f0fd99327c4684a8.js" async=""></script><script src="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" async=""></script><script src="/_next/static/chunks/framework.1daf1ec1ecf144ee9147.js" async=""></script><script src="/_next/static/chunks/commons.9e003f150a446b53bdd9.js" async=""></script><script src="/_next/static/chunks/pages/_app-99db904e083fc7f74e35.js" async=""></script><script src="/_next/static/chunks/588505f8033a39c9ef82bc46b1145ac9fd1db500.7f1789362bee7bf8434b.js" async=""></script><script src="/_next/static/chunks/pages/members/%5Bname%5D-42a7756adc6c0800b4dc.js" async=""></script><script src="/_next/static/St5w_c2xNgKLANGQYvXWT/_buildManifest.js" async=""></script><script src="/_next/static/St5w_c2xNgKLANGQYvXWT/_ssgManifest.js" async=""></script></body></html>